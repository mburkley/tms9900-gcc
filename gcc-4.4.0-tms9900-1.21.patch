diff -ru gcc-orig/config.sub gcc-4.4.0/config.sub
--- gcc-orig/config.sub	2023-11-09 10:22:30.183989619 +0000
+++ gcc-4.4.0/config.sub	2023-11-09 13:41:40.819744320 +0000
@@ -285,7 +285,7 @@
 	| sparc | sparc64 | sparc64b | sparc64v | sparc86x | sparclet | sparclite \
 	| sparcv8 | sparcv9 | sparcv9b | sparcv9v \
 	| spu | strongarm \
-	| tahoe | thumb | tic4x | tic80 | tron \
+	| tahoe | thumb | tic4x | tic80 | tms9900 | tron \
 	| v850 | v850e \
 	| we32k \
 	| x86 | xc16x | xscale | xscalee[bl] | xstormy16 | xtensa \
diff -ru gcc-orig/gcc/combine.c gcc-4.4.0/gcc/combine.c
--- gcc-orig/gcc/combine.c	2023-11-09 10:22:30.183989619 +0000
+++ gcc-4.4.0/gcc/combine.c	2023-11-09 19:07:20.834339171 +0000
@@ -4466,6 +4466,17 @@
 		    return gen_rtx_CLOBBER (VOIDmode, const0_rtx);
 #endif
 
+#ifdef TMS9900
+                  /* Added for TMS9900
+                     Do not assume QI value is in low part of register */
+		  if (code == SUBREG
+		      && REG_P (to)
+		      && REGNO (to) < FIRST_PSEUDO_REGISTER
+                      && ((GET_MODE(x) ==QImode && GET_MODE(to)!=QImode) ||
+                          (GET_MODE(to)==QImode && GET_MODE(x) !=QImode)))
+		    return gen_rtx_CLOBBER (VOIDmode, const0_rtx);
+#endif
+
 		  new_rtx = (unique_copy && n_occurrences ? copy_rtx (to) : to);
 		  n_occurrences++;
 		}
@@ -9934,7 +9945,16 @@
 	 generate a paradoxical subreg instead.  That will force a reload
 	 of the original memref X.  */
       if (isize < osize)
-	return gen_rtx_SUBREG (omode, x, 0);
+        {
+#ifdef TMS9900
+          /* Added for TMS9900.
+             Do not convert to subreg if source is a byte. */
+          if(isize == 1)
+            return x;
+          else
+#endif
+            return gen_rtx_SUBREG (omode, x, 0);
+        }
 
       if (WORDS_BIG_ENDIAN)
 	offset = MAX (isize, UNITS_PER_WORD) - MAX (osize, UNITS_PER_WORD);
diff -ru gcc-orig/gcc/config/tms9900/lib1funcs.asm gcc-4.4.0/gcc/config/tms9900/lib1funcs.asm
--- gcc-orig/gcc/config/tms9900/lib1funcs.asm	2023-11-09 19:22:16.503496525 +0000
+++ gcc-4.4.0/gcc/config/tms9900/lib1funcs.asm	2023-11-09 13:41:40.823744304 +0000
@@ -0,0 +1,820 @@
+/******************************************************************************
+*                               __clzM2
+*******************************************************************************
+* Return the number of leading 0-bits in a value, starting at the most
+* significant bit position.  If the value is zero, the result is undefined.
+*
+* Inputs : r1 - Value to test
+*
+* Returns: r1 - Number of zero bits
+******************************************************************************/
+
+#ifdef L_clzqi2
+/*********************************************************/
+/*                     __clzqi2                          */
+/*********************************************************/
+  def __clzqi2
+__clzqi2:
+  movb r1, r2  /* Move value into position, set condition flags */
+  clr  r1      /* Set minimum bit count, flags unchanged */
+  jgt  do_clz  /* If val==0, return undefined, if val<0, MSB set, return 0*/
+  b    *r11
+do_clz:
+  b    @__clz
+#endif
+
+
+#ifdef L_clzhi2
+/*********************************************************/
+/*                     __clzhi2                          */
+/*********************************************************/
+  def __clzhi2
+__clzhi2:
+  mov  r1, r2  /* Move value into position, set condition flags */
+  clr  r1      /* Set minimum bit count, flags unchanged */
+  jgt  do_clz  /* If val==0, return undefined, if val<0, MSB set, return 0*/
+  b *r11
+do_clz:
+  b    @__clz
+#endif
+
+
+#ifdef L_clzsi2
+/*********************************************************/
+/*                     __clzsi2                          */
+/*********************************************************/
+  def __clzsi2
+__clzsi2:
+  mov  r1, r1   /* Test MSW for set bits */
+  jlt  ret_0    /* Upper bit of MSW set, return zero */
+  jgt  clz_msw  /* Count leading zeroes in MSW */
+
+clz_lsw:
+  li   r1, 16   /* MSW was zero, initialize count to 16 */
+  mov  r2, r2   /* Test bits in LSW */
+  jlt  ret_16   /* Upper bit of LSW set, return sisxteen */
+  jgt  do_clz   /* Count leading zeroes of LSW */
+
+ret_0:
+  clr  r1
+ret_16:
+  b    *r11
+
+clz_msw:
+  mov  r1, r2  /* Move MSW into test position */
+  clr  r1      /* Initialize count to zero */
+do_clz:
+  b    @__clz
+#endif
+
+
+#ifdef L_clz
+/******************************************************************************
+*                               __clz
+*******************************************************************************
+* Return the number of leading 0-bits in a 16-bit value, starting at the most 
+* significant bit position.  If the value is zero, the result is undefined.
+*
+* Inputs : R1 - Minimum posible bit count
+*          R2 - Value to test
+*
+* Returns: R1 - Number of zero bits
+*******************************************************************************/
+  def __clz
+/*
+* We will shift left until we find a set bit
+*
+* Example 1, zero leading bits:
+*   C Val   N
+*   - ----  -
+*   . 1000  0
+*
+* Example 2, one leading bit:
+*   C Val   N
+*   - ----  -
+*   . 0100  4
+*   1 00..  2->1
+*
+* Example 3, two leading bits:
+*   C Val   N
+*   - ----  -
+*   0 0010  4
+*   0 10..  2
+*
+* If we got here, there is at least one bit set in supplied value
+*/
+__clz:
+  inct r1      /* Assume two zero bits, double count implied bit */
+  sla  r2, 2   /* Move next two bits into test position, set flags */
+  joc  bottom  /* Upper test bit set, exit */
+  jgt  __clz   /* Upper and lower test bits clear, loop */
+  
+  /* Clean up after loop */
+  inc r1       /* If we got here, negate next instruction */
+bottom:
+  dec r1       /* No cleared bits in last test set, decrement count */
+
+  /* Bit count is in R1, exit */
+  b *r11
+#endif
+
+  
+/******************************************************************************
+*                               __ctzM2
+*******************************************************************************
+* Return the number of trailing 0-bits in a 16-bit value, starting at the least
+* significant bit position.  If the value is zero, the result is undefined.
+*
+* Inputs : R1 - Value to test
+*
+* Returns: R1 - Number of zero bits
+******************************************************************************/
+
+#ifdef L_ctzqi2
+/*********************************************************/
+/*                     __ctzqi2                          */
+/*********************************************************/
+  def __ctzqi2
+__ctzqi2:
+  clr  r2
+  movb r1, r2  /* Move value to R2, clearing low bits */
+  jeq  bottom  /* If all bits clear, stop now, return zero */
+  li   r1, 8   /* Max possible zero bits */
+  b    @__ctz  /* Examine provided value */
+bottom:
+  b *r11
+#endif
+
+
+#ifdef L_ctzhi2
+/*********************************************************/
+/*                     __ctzhi2                          */
+/*********************************************************/
+  def __ctzhi2
+__ctzhi2:
+  mov r1, r2  /* Move value to R2, set condition flags */
+  jeq bottom  /* If all bits clear, stop now, return zero */
+  li  r1, 16  /* Max possible zero bits */
+  b   @__ctz  /* Examine provided value */
+bottom:
+  b *r11
+#endif
+
+
+#ifdef L_ctzsi2
+/*********************************************************/
+/*                     __ctzsi2                          */
+/*********************************************************/
+  def __ctzsi2
+__ctzsi2:
+  mov  r2, r2     /* Check low word for set bits */
+  jeq  lsw_clear 
+
+  /* There are set bits in the low word */
+  li   r1, 16     /* Maximum number of possible zero bits */
+  b    @__ctz     /* Examine provided value */
+
+  /* All bits clear in the low word, no need to test them */
+lsw_clear:
+  mov  r1, r2     /* Move high word into test position */
+  jeq  bottom     /* If all bits clear, stop now, return zero */
+  li   r1, 32     /* Maximum number of possible zero bits */
+  b    @__ctz     /* Examine provided value */
+
+bottom:
+  b *r11
+#endif
+
+
+#if L_ctz
+/******************************************************************************
+*                               __ctz
+*******************************************************************************
+* Return the number of trailing 0-bits in a 16-bit value, starting at the least 
+* significant bit position.  If the value is zero, the result is undefined.
+*
+* Inputs : R1 - Maximum posible bit count
+*          R2 - Value to test
+*
+* Returns: R1 - Number of zero bits
+******************************************************************************/
+  def __ctz
+
+/*
+* We will shift left until all leading set bits are shifted out of the value
+*
+* Exmaple 1, zero trailing bits:
+*   C Val   N
+*   - ----  -
+*   . 0001  4
+*   0 01..  2
+*   1 ....  0
+*
+* Exmaple 2, one trailing bit:
+*   C Val   N
+*   - ----  -
+*   . 0010  4
+*   0 10..  2
+*   0 ....  1
+*
+* Exmaple 3, two trailing bits:
+*   C Val   N
+*   - ----  -
+*   0 0100  4
+*   1 00..  2
+*/
+
+  /* Test loop, check two uppermost bits at a time */
+__ctz:
+  dect r1      /* Assume both bits are set */
+  sla  r2, 2   /* Shift two bits into test position */
+  jne  __ctz   /* Still have set bits, keep looping */
+
+  /* Correct for last two test bits */
+  joc  bottom  /* If carry bit set, lower test bit was set */
+  inc  r1      /* lower test bit was clear, increment bit count */
+bottom:
+  b *r11
+#endif
+
+
+/******************************************************************************
+*                               __ffsM2
+*******************************************************************************
+* Return the index of the least significant set bit in a value, or zero 
+* if the value is zero.  The least significant bit is index one.
+*
+* Inputs : R1 - Value to test
+*
+* Returns: R1 - Index to lowest set bit
+******************************************************************************/
+
+
+#ifdef L_ffsqi2
+/*********************************************************/
+/*                     __ffsqi2                          */
+/*********************************************************/
+  def __ffsqi2
+__ffsqi2:
+  movb r1, r1     /* Check for zero value */
+  jeq  done       /* If so, exit now */
+  mov  r11, r3    /* Move return pointer, it won't be affected by next call */
+  bl   @__ctzqi2  /* Count trailing zero bits */
+  inc  r1         /* Least sig. bit is in position trailing_count +1 */
+  b    *r3        /* Return to caller */
+done:
+  clr  r1         /* Return zero value */
+  b    *r11
+#endif
+
+
+#ifdef L_ffshi2
+/*********************************************************/
+/*                     __ffshi2                          */
+/*********************************************************/
+  def __ffshi2
+__ffshi2:
+  mov r11, r3     /* Move return pointer, it won't be affected by next call */
+  mov r1, r1      /* Check for zero value */
+  jeq done        /* If so, exit now */
+  bl  @__ctzhi2   /* Count trailing zero bits */
+  inc r1          /* Least sig. bit is in position trailing_count +1 */
+done:
+  b   *r3         /* Return to caller */
+#endif
+
+
+#ifdef L_ffssi2
+/*********************************************************/
+/*                     __ffssi2                          */
+/*********************************************************/
+  def __ffssi2
+__ffssi2:
+  mov r11, r3     /* Move return pointer, it won't be affected by next call */
+  mov r1, r4
+  soc r2, r4      /* Check for zero value */
+  jeq done        /* If so, exit now */
+  bl  @__ctzsi2   /* Count trailing zero bits */
+  inc r1          /* Least sig. bit is in position trailing_count +1 */
+done:
+  b   *r3         /* Return to caller */
+  def __modsi3
+#endif
+
+
+#ifdef L_parity
+/******************************************************************************
+*                               __parityM2
+*******************************************************************************
+* Return the value zero if the number of bits set in the given value is even,
+* and the value one otherwise.
+*
+* Inputs : R1 - Value to test
+*
+* Returns: R1 - Number of zero bits
+******************************************************************************/
+
+/* Test an 8-bit value */
+  def __parityqi2
+__parityqi2:
+  seto r3
+  jmp byte1
+
+/* Test a 16-bit value */
+  def __parityhi2
+__parityhi2:
+  clr r3
+  jmp byte2
+
+/* Test a 32-bit value */
+  def __paritysi2
+__paritysi2:
+  clr  r3
+  movb r2, r2
+  jop pre_byte3
+  inv r3
+pre_byte3:
+  swpb r2
+byte3:
+  movb r2, r2
+  jop byte2
+  inv r3
+byte2:
+  movb r1, r1
+  jop pre_byte1
+  inv r3
+pre_byte1:
+  swpb r1
+byte1:
+  movb r1, r1
+  jop done
+  inv r3
+done:
+  neg r3
+  mov r3, r1
+  bl *r11
+#endif
+
+
+/******************************************************************************
+*                               __popcountM2
+*******************************************************************************
+* Return the number of set bits in a value
+*
+* Inputs : R1 - Value to test
+*
+* Returns: R1 - Number of set bits
+******************************************************************************/
+
+
+#ifdef L_popcountqi2
+/*********************************************************/
+/*                   __popcountqi2                       */
+/*********************************************************/
+  def __popcountqi2
+__popcountqi2:
+  clr  r2           /* Clear lower unused bits */
+  movb r1, r2       /* Move value into test position */
+  clr  r1           /* Clear bit count */
+  b    @__popcount  /* Find set bit count */
+#endif
+
+
+#ifdef L_popcounthi2
+/*********************************************************/
+/*                   __popcounthi2                       */
+/*********************************************************/
+  def __popcounthi2
+__popcounthi2:
+  mov  r1, r2       /* Move value into test position */
+  clr  r1           /* Clear bit count */
+  b    @__popcount  /* Find set bit count */
+#endif
+
+
+#ifdef L_popcountsi2
+/*********************************************************/
+/*                   __popcountsi2                       */
+/*********************************************************/
+  def __popcountsi2
+__popcountsi2:
+  mov  r11, r4      /* Move Return value where it will be safe */
+  mov  r1, r3       /* Move MSW to safe position */
+  clr  r1           /* Clear bit count */
+  bl   @__popcount  /* Find LSW set bit count */
+  mov  r3, r2       /* Move MSW into test position */
+  bl   @__popcount  /* Find MSW set bit count */
+  b    *r4          /* Return to caller */
+#endif
+
+
+#ifdef L_popcount
+/******************************************************************************
+*                               __popcount
+*******************************************************************************
+* Return the number of set bits in a 16-bit value
+*
+* Inputs : R1 - Current bit count
+*          R2 - Value to test
+*
+* Returns: R1 - Number of set bits
+******************************************************************************/
+  def __popcount
+__popcount:
+  mov  r2,r2   /* Check for zero value */  
+  jeq  done    /* If zero, exit now */
+top:
+  inc  r1      /* Increment bit count */
+  mov  r2, r0  /* \                           */
+  neg  r0      /* | Equvilent to r2 &= (r2-1) */
+  szc  r0, r2  /* /                           */
+  jne  top     /* Keep looping until all bits counted */
+done:
+  b    *r11    /* Return to caller */
+#endif
+
+
+#ifdef L_divmodsi3
+/******************************************************************************
+*                               __divmodsi3
+*******************************************************************************
+* Calculate the signed quotient and modulus of the two values provided
+*
+* Inputs:  [R1,R2] - 32-bit numerator
+*          [R3,R4] - 32-bit denominator
+*           R5     - Address for modulus
+*
+* Returns: [R1,R2] - 32-bit quotient
+******************************************************************************/
+  def __divmodsi3
+__divmodsi3:
+  /* Save modulo addess */
+  mov  r5, @-6(r10)
+
+  /* Save return register */
+  mov  r11, @-2(r10)
+  bl   @__divmodstart
+
+  /* Caclulate result */
+calc:
+  bl   @__udivmod32
+
+  /* Negate modulus if needed */
+  mov  @-4(r10), r0
+  jlt  savemod
+  inv  r3
+  neg  r4
+  jnc  savemod
+  inc  r3
+  
+  /* Save modulus */
+savemod:
+  mov  @-6(r10), r0
+  mov  r3, *r0
+  mov  r4, *r0+
+
+  /* Complete operatons */
+  b    @__divmodend
+#endif
+
+
+#ifdef L_divsi3
+/******************************************************************************
+*                               __divsi3
+*******************************************************************************
+* Calculate the signed quotient of the two values provided
+*
+* Inputs:  [R1,R2] - 32-bit numerator
+*          [R3,R4] - 32-bit denominator
+*
+* Returns: [R1,R2] - 32-bit quotient
+******************************************************************************/
+  def __divsi3
+__divsi3:
+  /* Save return register */
+  mov  r11, @-2(r10)
+  bl   @__divmodstart
+
+  /* Caclulate result */
+calc:
+  bl   @__udivmod32
+  b    @__divmodend
+#endif
+
+
+#ifdef L_modsi3
+/******************************************************************************
+*                               __modsi3
+*******************************************************************************
+* Calculate the signed modulus of the two values provided
+*
+* Inputs:  [R1,R2] - 32-bit numerator
+*          [R3,R4] - 32-bit denominator
+*
+* Returns: [R1,R2] - 32-bit modulus
+******************************************************************************/
+  def __modsi3
+__modsi3:
+  /* Save return register */
+  mov  r11, @-2(r10)
+  bl   @__divmodstart
+
+  /* Caclulate result */
+calc:
+  bl   @__udivmod32
+  mov  r3, r1
+  mov  r4, r2
+  b    @__divmodend
+#endif
+
+
+#ifdef L_divmod_common
+/******************************************************************************
+*                               __divmodstart
+*******************************************************************************
+* Common code for the start of all signed division and modulo calculations
+*
+* Inputs:  [R1,R2] - Signed 32-bit numerator
+*          [R3,R4] - Signed 32-bit denominator
+*
+* Returns: [R1,R2] - Positive 32-bit quotient
+*          [R3,R4] - Positive 32-bit denominator
+*          sp-4    - Sign of result
+******************************************************************************/
+  def __divmodstart
+__divmodstart:
+  /* Make numerator positive */
+  mov  r1, r5
+  jlt  negnum
+  jmp  testden
+negnum:
+  inv  r1
+  neg  r2
+  jnc  testden
+  inc  r1
+
+  /* Make denominator positive */
+testden:
+  xor  r3, r5
+  mov  r5, @-4(r10)
+  mov  r3, r3
+  jlt  negden
+  jmp  done
+negden:
+  inv  r3
+  neg  r4
+  jnc  done
+  inc  r3
+done:
+  b    *r11
+
+
+/******************************************************************************
+*                               __divmodend
+*******************************************************************************
+* Common code for the end of all signed division and modulo calculations
+*
+* Inputs:  [R1,R2] - Positive 32-bit quotient
+*          [R3,R4] - Positive 32-bit denominator
+*          sp-2    - Return pointer
+*          sp-4    - Sign of result
+*          
+* Returns: [R1,R2] - Signed 32-bit result
+******************************************************************************/
+  def __divmodend
+__divmodend:
+  /* Restore return register */
+  mov  @-2(r10), r11
+
+  /* Do we need to negate the result? */
+  mov  @-4(r10), r0
+  jlt  makeneg  
+  b    *r11        # Nope, exit now
+
+  /* Negate result and return */
+makeneg:  
+  inv  r1
+  neg  r2
+  jnc  jmp1
+  inc  r1
+jmp1:
+  b    *r11
+#endif
+
+
+#ifdef L_udivmodsi3
+/******************************************************************************
+*                             __udivmodsi3
+*******************************************************************************
+* Calculate the unsigned quotient and remainder of the two values provided
+*
+* Inputs:  [R1,R2] - 32-bit numerator
+*          [R3,R4] - 32-bit denominator
+*           R5     - Address to place 32-bit remainder
+*
+* Returns: [R1,R2] - 32-bit quotient
+******************************************************************************/
+  def __udivmodsi3
+__udivmodsi3:
+  /* Save pointer and return address */
+  mov  r5,  @-2(r10)
+  mov  r11, @-4(r10)
+
+  /* Do some math */
+  bl   @__udivmodsi
+  
+  /* Save remainder */
+  mov  @-2(r10), r0
+  mov  r3, *r0+
+  mov  r4, *r0
+  mov  @-4(r10), r11
+  b    *r11
+#endif
+
+
+#ifdef L_udivsi3
+/******************************************************************************
+*                               __udivsi3
+*******************************************************************************
+* Calculate the unsigned quotient of the two values provided
+*
+* Inputs:  [R1,R2] - 32-bit numerator
+*          [R3,R4] - 32-bit denominator
+*
+* Returns: [R1,R2] - 32-bit quotient
+******************************************************************************/
+  def __udivsi3
+__udivsi3:
+  /* Fall through to next routine */
+
+
+/******************************************************************************
+*                               __udivmod32
+*******************************************************************************
+* Calculate the unsigned quotient and remainder of the two values provided.
+* This is used by all the 32-bit division and modulus functions.
+*
+* Inputs:  [R1,R2] - 32-bit numerator
+*          [R3,R4] - 32-bit denominator
+*
+* Returns: [R1,R2] - 32-bit quotient
+*          [R3,R4] - 32-bit remainder
+******************************************************************************/
+  def __udivmod32
+__udivmod32:
+  /* Check size of denominator */
+  mov  r3, r3      /* Is the upper word of denominator used? */
+  jne  den32       /* If so, jump to 32-bit code */
+
+  /* Handle 16-bit denominator */
+  /* Zero extend numerator */
+  clr  r0
+  mov  r1, r1
+  jeq  num16       /* If numerator is only 16 bits, skip the first DIV */
+
+  /* Perform calculation */
+  div  r4, r0
+num16:
+  div  r4, r1
+
+  /* Move results into return position */
+  mov  r2, r4      /* LSW of remainder */
+                   /* MSW of remainder still zero */
+  mov  r1, r2      /* LSW of result */
+  mov  r0, r1      /* MSW of result */
+  b    *r11
+
+den32:
+  /*
+  * Handle 32-bit denominator
+  *
+  *      A1*N + A1
+  * Q = ---------
+  *      B1*N + B2
+  *
+  * N = 0x10000
+  *
+  * Divide top and bottom by 2*B1 to make the denominator a 16-bit quantity
+  *
+  *        A1*N + A2
+  *       ---------
+  *          2*B1
+  * Q = ---------------
+  *        N     B2
+  *       --- + ---
+  *        2    2*B1
+  *
+  * This will result in some rounding error which must be corrected for.
+  * We will call the approximate value P, and the rounding error E. 
+  *
+  * Q - P = E
+  *
+  * Analysis of the error shows that E must be either 0 or -1. We will calculate
+  * the remainder to determine E and so correct P.
+  *
+  * R = (A1*N + A2) - P*(B1*N + B2)
+  *
+  * If R is negative, P is too large by one and we will apply the correction.
+  * Otherwise, P is correct and we can use the value directly.
+  */
+
+  /* Move arguments into test position */
+  mov  r1, r0      /* [r0,r12] <- [A1,A2] = numerator */
+  mov  r2, r12
+
+  mov  r3, r7      /* [r7,r8] <- [B1,B2] = deominator */
+  mov  r4, r8
+
+  /* Calculate V = (N/2 + B2/(2*B1)) */
+  clr  r1          /* [r1,r2] <- [C1,C2] = B2/2 */
+  mov  r8, r2
+  srl  r2, 1
+
+  div  r7, r1      /* r1 <- v = [C1,C2]/B1 */
+  ai   r1, 0x8000  /* v += 0x8000 */
+
+  /* Calculate U = (A1*N + A2)/(2*B1) */
+  mov  r0, r2      /* [r2,r3] <- [U1,U2] = [A1,A2] */
+  mov  r12, r3
+
+  srl  r2, 1       /* [U1,U2] = [A1,A2]/2 */
+  srl  r3, 1
+  jnc  jmp1
+  ori  r3, 0x8000
+jmp1:
+
+  clr  r4          /* [U1,U2] = [U1,U2]/B1 */
+  mov  r2, r5
+  div  r7, r4
+  mov  r3, r6
+  div  r7, r5
+  mov  r4, r2
+  mov  r5, r3
+
+  div  r1, r2      /* r2 <- P = [U1,U2]/V */
+
+  /* Calculate remainder  [m1,m2]=[a1,a2]-[b1,b2]*p */
+  mov  r7, r3      /* [r3,r4] <- [U1,U2] = B1*p */
+  mpy  r2, r3
+
+  mov  r8, r5      /* [r5,r6] <- [D1,D2] = B2*P */
+  mpy  r2, r5
+
+  a    r4, r5      /* [D1,D2] += [U2,0] */
+
+  mov  r0, r3      /* [M1,M2] = [A1,A2] */
+  mov  r12, r4
+
+  s    r5, r3      /* [M1,M2] -= [D1,D2] */
+  s    r6, r4
+  joc  jmp2
+  dec  r3
+jmp2:
+
+  /*
+  * Results now in return position, prepare for exit
+  *   [r1,r2] <- quotient
+  *   [r3,r4] <- remainder
+  */
+  clr  r1          /* Set upper word of quotient, we know it will be zero */
+  mov  r3, r3      /* if(remainder >= 0) P is correct */
+  jlt  jmp3
+  b    *r11
+jmp3:
+
+  /* Correct result for rounding error */
+  dec  r2          /* P -= 1 */
+
+  /* Correct remainder for rounding error */
+  a    r7, r3      /* [M1,M2] += [B1,B2] */
+  a    r8, r4
+  jnc  jmp4
+  inc  r3
+jmp4:
+
+  /* Return value */
+  b    *r11
+#endif
+
+
+#ifdef L_umodsi3
+/******************************************************************************
+*                               __umodsi3
+*******************************************************************************
+* Calculate the unsigned modulus of the two values provided
+*
+* Inputs:  [R1,R2] - 32-bit numerator
+*          [R3,R4] - 32-bit denominator
+*
+* Returns: [R1,R2] - 32-bit modulus
+******************************************************************************/
+  def __umodsi3
+__umodsi3:
+  mov  r11, @-2(r10)
+  bl   @__udivmod32
+  mov  r3, r1
+  mov  r4, r2
+  mov  @-2(r10), r11
+  b    *r11
+#endif
+
diff -ru gcc-orig/gcc/config/tms9900/tms9900.c gcc-4.4.0/gcc/config/tms9900/tms9900.c
--- gcc-orig/gcc/config/tms9900/tms9900.c	2023-11-09 19:22:21.063482048 +0000
+++ gcc-4.4.0/gcc/config/tms9900/tms9900.c	2023-11-09 19:07:20.838339158 +0000
@@ -0,0 +1,1127 @@
+#include "insn-modes.h"
+#include <stdio.h>
+#include "config.h"
+#include "system.h"
+#include "coretypes.h"
+#include "tm.h"
+#include "rtl.h"
+#include "tree.h"
+#include "tm_p.h"
+#include "regs.h"
+#include "hard-reg-set.h"
+#include "real.h"
+#include "insn-config.h"
+#include "conditions.h"
+#include "output.h"
+#include "insn-attr.h"
+#include "flags.h"
+#include "recog.h"
+#include "expr.h"
+#include "libfuncs.h"
+#include "toplev.h"
+#include "basic-block.h"
+#include "function.h"
+#include "ggc.h"
+#include "reload.h"
+#include "target.h"
+#include "target-def.h"
+#include "df.h"
+
+static bool tms9900_pass_by_reference (CUMULATIVE_ARGS *,
+                                       enum machine_mode, const_tree, bool);
+static bool tms9900_asm_integer(rtx x, unsigned int size, int aligned_p);
+
+static int tms9900_dwarf_label_counter;
+
+/* Define data types */
+#undef  TARGET_ASM_BYTE_OP
+#define TARGET_ASM_BYTE_OP "\tbyte\t"
+
+#undef  TARGET_ASM_ALIGNED_HI_OP
+#define TARGET_ASM_ALIGNED_HI_OP "\tdata\t"
+
+#undef  TARGET_PASS_BY_REFERENCE
+#define TARGET_PASS_BY_REFERENCE tms9900_pass_by_reference
+
+#undef  TARGET_ASM_INTEGER
+#define TARGET_ASM_INTEGER tms9900_asm_integer
+
+#undef  TARGET_FUNCTION_OK_FOR_SIBCALL
+#define TARGET_FUNCTION_OK_FOR_SIBCALL tms9900_ok_for_sibcall
+
+static bool
+tms9900_ok_for_sibcall (tree decl, tree exp)
+{
+  return true;
+}
+
+#define TARGET_ASM_ALIGNED_HI_OP "\tdata\t"
+#define TARGET_ASM_ALIGNED_SI_OP NULL
+#define TARGET_ASM_ALIGNED_DI_OP NULL
+#define TARGET_ASM_ALIGNED_TI_OP NULL
+
+struct gcc_target targetm = TARGET_INITIALIZER;
+
+/* Non-volatile registers to be saved across function calls */
+static int nvolregs[]={
+   HARD_LR_REGNUM,
+   HARD_R9_REGNUM,
+   HARD_LW_REGNUM,
+   HARD_LP_REGNUM,
+   HARD_LS_REGNUM,
+   0};
+
+
+/* If defined, a C expression which determines whether, and in which direction,
+   to pad out an argument with extra space.  The value should be of type
+   `enum direction': either `upward' to pad above the argument,
+   `downward' to pad below, or `none' to inhibit padding.
+
+   Structures are stored left shifted in their argument slot.  */
+int tms9900_function_arg_padding (enum machine_mode mode,
+                                  const_tree type)
+{
+  if (type != 0 && AGGREGATE_TYPE_P (type))
+    return upward;
+
+  /* Fall back to the default.  */
+  return DEFAULT_FUNCTION_ARG_PADDING (mode, type);
+}
+
+
+/* Update the data in CUM to advance over an argument
+   of mode MODE and data type TYPE.
+   (TYPE is null for libcalls where that information may not be available.)  */
+void tms9900_function_arg_advance (CUMULATIVE_ARGS *cum, 
+                                   enum machine_mode mode,
+                                   tree type, 
+                                   int named ATTRIBUTE_UNUSED)
+{
+  int arg_bytes;
+  if(mode == BLKmode)
+  {
+     arg_bytes = int_size_in_bytes (type);
+  }
+  else
+  {
+     arg_bytes = GET_MODE_SIZE (mode);
+  }
+  cum->nregs += ((arg_bytes + 1)/ UNITS_PER_WORD) * REGS_PER_WORD;
+  return;
+}
+
+
+/* Initialize a variable CUM of type CUMULATIVE_ARGS
+   for a call to a function whose data type is FNTYPE.
+   For a library call, FNTYPE is NULL.  */
+void tms9900_init_cumulative_args (CUMULATIVE_ARGS *cum, 
+                                   tree fntype ATTRIBUTE_UNUSED,
+                                   rtx libname ATTRIBUTE_UNUSED)
+{
+  /* Varargs vectors are treated the same as long long. Using
+     named_count avoids having to change the way 'named' is handled */
+  cum->named_count = 0;
+  cum->nregs = 0;
+}
+
+
+/* Determine where to put an argument to a function.
+   Value is zero to push the argument on the stack,
+   or a hard register in which to store the argument.
+
+   MODE is the argument's machine mode.
+   TYPE is the data type of the argument (as a tree).
+      This is null for libcalls where that information may
+      not be available.
+   CUM is a variable of type CUMULATIVE_ARGS which gives info about
+      the preceding args and about the function being called.
+   NAMED is nonzero if this argument is a named parameter
+      (otherwise it is an extra parameter matching an ellipsis).  */
+rtx tms9900_function_arg (CUMULATIVE_ARGS *cum, 
+                          enum machine_mode mode,
+		          tree type,
+                          int named)
+{
+  if (mode == VOIDmode)
+    /* Pick an arbitrary value for operand 2 of the call insn.  */
+    return const0_rtx;
+  
+  if (/* Vararg argument, must live on stack */
+      !named ||
+      /* No more argument registers left */
+      cum->nregs >= TMS9900_ARG_REGS ||
+      /* Argument doesn't completely fit in arg registers */      
+      GET_MODE_SIZE(mode) + cum->nregs > TMS9900_ARG_REGS)
+    return NULL_RTX;
+
+  /* Allocate registers for argument */
+  return gen_rtx_REG (mode, cum->nregs + HARD_R1_REGNUM);
+}
+
+
+/* Output all constant addresses using hex values */
+static void tms9900_output_addr_const(FILE *file, rtx addr)
+{
+  if(CONST_INT_P(addr))
+    fprintf(file, ">%X", (int)(INTVAL(addr)) & 0xFFFF);
+  else
+    output_addr_const(file, addr);
+}
+
+
+/* Construct string expression matching an address operand */
+void print_operand_address (FILE *file,
+                            register rtx addr)
+{
+  retry:
+  switch (GET_CODE (addr))
+    {
+    case MEM:
+      addr = XEXP (addr, 0);
+      goto retry;
+
+    case REG:
+      fprintf (file, "*%s", reg_names[REGNO (addr)]);
+      break;
+
+    case POST_MODIFY:
+    case POST_INC:
+      fprintf (file, "*%s+", reg_names[REGNO (XEXP (addr, 0))]);
+      break;
+
+    case PLUS:
+      /* @xxxx(R0) */
+      if (GET_CODE (addr) == PLUS            &&
+          GET_CODE (XEXP (addr, 0)) == REG   &&
+          REG_OK_FOR_BASE_P (XEXP (addr, 0)) &&
+          CONSTANT_ADDRESS_P (XEXP (addr, 1)))
+      {
+        fprintf(file, "@");
+        tms9900_output_addr_const (file, XEXP (addr, 1));
+        fprintf(file, "(%s)", reg_names[REGNO (XEXP (addr, 0))]);
+      }
+
+      /* @(symbol+xxxx)(R0) */
+      else if(GET_CODE (addr) == PLUS )
+      {
+        rtx base   = 0;
+        rtx offset = 0;
+        int regno  = 0;
+        if(GET_CODE(XEXP(addr,0)) == MEM)
+        {
+          rtx op = XEXP(addr,0);
+          op = XEXP(op, 0);
+          if(GET_CODE (op) == PLUS             &&
+             GET_CODE (XEXP (op, 0)) == REG    &&
+             REG_OK_FOR_BASE_P (XEXP (op, 0))  &&
+             CONSTANT_ADDRESS_P(XEXP (op, 1))  &&
+             CONSTANT_ADDRESS_P(XEXP(addr, 1)))
+          {
+            base   = XEXP(addr, 1);
+            offset = XEXP(op, 1);
+            regno  = REGNO(XEXP(op, 0));
+            if(CONST_INT_P(base) && CONST_INT_P(offset))
+            {
+              fprintf(file, "@>%X(%s)", (int)(INTVAL(base) + INTVAL(offset)) & 0xFFFF, reg_names[regno]);
+            }
+            else
+            {
+              fprintf(file, "@(");
+              tms9900_output_addr_const (file, base);
+              fprintf(file, "+>%X)(%s)", ((int)INTVAL(offset)) & 0xFFFF, reg_names[regno]);
+            }
+          }
+        }
+      }
+      else
+      {
+        gcc_assert (0);
+      }
+      break;
+
+    default:
+      fprintf(file, "@");
+      tms9900_output_addr_const (file, addr);
+    }
+}
+
+
+/* Should we save this register? */ 
+int tms9900_should_save_reg(int regno)
+{
+   return(
+      /* Save non-volatile registers or r11 if used */
+      (df_regs_ever_live_p(regno) &&
+          (call_used_regs[regno] == 0 || regno == HARD_LR_REGNUM)) ||
+      /* Save r11 if this is not a leaf function */
+      (regno == HARD_LR_REGNUM && !current_function_is_leaf)
+   );
+}
+
+
+/* Get number of bytes used to save registers in the current stack frame */
+static int tms9900_get_saved_reg_size(void)
+{
+   int idx = 0;
+   int size = 0;
+   while(nvolregs[idx] != 0)
+   {      
+      int regno = nvolregs[idx];     
+      if(tms9900_should_save_reg(regno))
+      {
+         size += 2;
+      }
+      idx++;
+   }
+   return(size);
+}
+
+
+/* Define the offset between two registers, one to be eliminated, and the
+   other its replacement, at the start of a routine.  */
+int tms9900_initial_elimination_offset (int from,
+                                        int to)
+{
+  /*  
+      . <- arg pointer
+      [args]
+      . <- frame pointer
+      [saved regs]
+      [frame]
+      . <- stack pointer
+  */
+
+  if (from == ARG_POINTER_REGNUM && to == HARD_SP_REGNUM)
+  {
+    return(tms9900_get_saved_reg_size()+
+           get_frame_size ());
+  }
+  if (from == FRAME_POINTER_REGNUM && to == HARD_SP_REGNUM)
+  {
+    return(get_frame_size());
+  }
+  if (from == ARG_POINTER_REGNUM && to == FRAME_POINTER_REGNUM)
+  {
+    return(tms9900_get_saved_reg_size());
+  }
+  return(0);
+}
+
+
+/* Determine if an address is represented using a valid expression */
+int legitimate_address_p (enum machine_mode mode,
+                          rtx address)
+{
+    GO_IF_LEGITIMATE_ADDRESS(mode, address, win);   
+    return 0;
+    
+  win:
+    return 1;
+}
+
+
+/* Determine the memory operand type
+   returns : 0 - Not a memory operand
+             1 - Register indirect : *Rn
+             2 - Post increment    : *Rn+
+             3 - Indexed register  : @INDEX(Rn)
+*/
+int tms9900_address_type(rtx op,
+                         enum machine_mode mode ATTRIBUTE_UNUSED)
+{
+  rtx addr;
+
+  /* Eliminate non-memory operations */
+  if (GET_CODE (op) != MEM)
+    return 0;
+
+  /* Decode the address now.  */
+indirection:
+  addr = XEXP (op, 0);
+  switch (GET_CODE (addr))
+  {
+    case REG:
+      /* Register indirect: *Rn */
+      return 1;
+	
+    case POST_INC:
+      /* Post increment: *Rn+ */
+      return 2;
+	
+    case MEM:
+      /* Yes, we know this is a memory expression.
+         Strip this code and try again */
+      op=addr;
+      goto indirection;
+	
+    case CONST_INT:
+    case LABEL_REF:	       
+    case CONST:
+    case SYMBOL_REF:
+      /* Indexed register : @ADDRESS(R0) - extra word required */
+
+    case PLUS:
+      /* Indexed register : @INDEX(Rn) - extra word required */
+      return 3;
+
+    default:
+      break;
+  }
+    
+  /* We should never get here, but we need to return something */
+  return 0;
+}
+
+
+/* Emit a branch condtional instruction */
+const char* output_branch (const char *pos, const char *neg, int length)
+{
+    static int label_id = 0;
+    
+    static char buf[1000];
+    length -= 10;
+    if(length == 2)
+    {
+        sprintf(buf, "%s  %%l0",pos);
+    }
+    else if(length == 4)
+    {
+        if(*pos == 'L')
+            sprintf(buf, "jlt  %%l0\n"
+                         "\tjeq  %%l0");
+        else if(*pos == 'G')
+            sprintf(buf, "jgt  %%l0\n"
+                         "\tjeq  %%l0");
+        else
+            gcc_unreachable();
+    }
+    else if(length == 6)
+    {
+	sprintf(buf, "%s  JMP_%d\n"
+                     "\tb    @%%l0\n"
+                     "JMP_%d", neg, label_id, label_id);	
+	label_id++;
+    }
+    else if(length == 8)
+    {
+        if(*neg == 'L')
+            sprintf(buf, "jlt  JMP_%d\n"
+                         "\tjeq  JMP_%d\n"
+                         "\tb    @%%l0\n"
+                         "JMP_%d", label_id, label_id, label_id);
+        else if(*neg == 'G')
+            sprintf(buf, "jgt  JMP_%d\n"
+                         "\tjeq  JMP_%d\n"
+                         "\tb    @%%l0\n"
+                         "JMP_%d", label_id, label_id, label_id);
+        else
+            gcc_unreachable();
+
+	label_id++;
+    }
+    else
+    {
+	gcc_unreachable();
+    }    
+    return buf;
+}
+
+
+/* Emit a jump instrcution */
+const char* output_jump (int length)
+{
+    length -= 10;
+    switch(length)    
+    {
+        case 2: return("jmp  %l0");
+        case 4: return("b    @%l0");
+        default: gcc_unreachable();
+    }
+}
+
+
+/* Determine if an instruction will update the conditional
+   flag as a side effect. This is used to eliminate unnneded
+   comparison instructions */
+void notice_update_cc_on_set(rtx exp, rtx insn ATTRIBUTE_UNUSED)
+{
+  if (GET_CODE (SET_DEST (exp)) == CC0)
+  {
+    cc_status.flags = 0;					
+    cc_status.value1 = SET_DEST (exp);			
+    cc_status.value2 = SET_SRC (exp);			
+  }
+  else if((GET_MODE (SET_DEST(exp)) == HImode ||
+           GET_MODE (SET_DEST(exp)) == QImode)
+          &&
+          (GET_CODE(SET_SRC(exp)) == PLUS  ||
+           GET_CODE(SET_SRC(exp)) == MINUS ||
+           GET_CODE(SET_SRC(exp)) == AND   ||
+           GET_CODE(SET_SRC(exp)) == IOR   ||
+           GET_CODE(SET_SRC(exp)) == XOR   ||
+           GET_CODE(SET_SRC(exp)) == NOT   ||
+           GET_CODE(SET_SRC(exp)) == NEG   ||
+           GET_CODE(SET_SRC(exp)) == ABS   ||
+           GET_CODE(SET_SRC(exp)) == REG   ||
+           GET_CODE(SET_SRC(exp)) == MEM))
+  {
+    cc_status.flags = 0;
+    cc_status.value1 = SET_SRC (exp);
+    cc_status.value2 = SET_DEST (exp);
+  }
+  else
+  {  
+    /* This last else is a bit paranoid, but since nearly all
+       instructions play with condition codes, it's reasonable. */
+    CC_STATUS_INIT;
+  }		        
+}
+
+
+/* Determine where the return value from a function will lie */
+rtx tms9900_function_value (const_tree valtype) /*, 
+                            const_tree func ATTRIBUTE_UNUSED, 
+                            bool outgoing ATTRIBUTE_UNUSED) */
+{
+  return gen_rtx_REG (TYPE_MODE (valtype), HARD_R1_REGNUM);
+}
+
+
+/* A C statement to output to the stdio stream STREAM an assembler
+   instruction to assemble a string constant containing the LEN bytes
+   at PTR.  PTR will be a C expression of type `char *' and LEN a C
+   expression of type `int'. */
+void tms9900_output_ascii(FILE* stream, const char* ptr, int len)
+{
+   int i;
+   int in_text = 0;
+   for (i = 0; i < len; i++)
+   {
+      int c = *ptr++;
+      if (ISPRINT(c))
+      {
+         /* Start TEXT statement */
+         if(in_text == 0)
+         {
+            fprintf (stream, "\ttext '");
+            in_text = 1;
+         }
+         putc (c, stream);
+         if(c == '\'') putc (c, stream);
+      }
+      else
+      {
+         /* Close TEXT statement */
+         if(in_text == 1)
+         {
+            fprintf (stream, "'\n");
+            in_text = 0;
+         }
+
+         /* Handle non-printable characters by inlining BYTE constants*/
+         fprintf (stream, "\tbyte %d\n", (unsigned char)c);
+      }
+   }
+}
+
+
+void tms9900_expand_prologue (void)
+{
+   /* Registers to save in this frame */
+   int saveregs[5];
+   int regcount = 0;
+   int idx = 0;
+   int frame_size = get_frame_size();
+
+   /* Find non-volatile registers which need to be saved */
+   while(nvolregs[idx] != 0)
+   {      
+      int regno = nvolregs[idx];
+      saveregs[idx] = 0;
+      if(tms9900_should_save_reg(regno))
+      {
+         /* Mark this register to be saved */
+         saveregs[idx] = 1;
+         regcount++;
+      }
+      idx++;
+   }
+
+   /* Allocate stack space for saved regs */
+   if(regcount > 0)
+   {
+      /* Emit "ai sp, -regcount*2" */
+      emit_insn(gen_addhi3(stack_pointer_rtx, stack_pointer_rtx, 
+                          GEN_INT(-regcount * 2)));
+   }
+
+   /* Actually save registers */
+   if(regcount > 2)
+   {
+      /*
+      Form 1:
+      ai sp, -regs*2        4      14+8+8   = 30
+      mov sp, r0            2      14+8     = 22
+      mov r9 , *r0+         2      14+8+8+8 = 38
+      mov r13, *r0+         2      14+8+8+8 = 38
+      mov r14, *r0+         2      14+8+8+8 = 38
+      mov r15, *r0+         2      14+8+8+8 = 38
+      mov r11, *r0          2      14+8+8+8 = 34
+      ai sp, -frame         4      14+8+8   = 30
+      */
+
+      /* Emit "mov sp, r0" */
+      emit_insn(gen_movhi(gen_rtx_REG(HImode, HARD_R0_REGNUM),
+                          stack_pointer_rtx));
+
+      idx = 0;
+      while(nvolregs[idx] != 0)
+      {
+         if(saveregs[idx]!=0)
+         {
+            int regno = nvolregs[idx];
+            if(nvolregs[idx + 1] == 0)
+            {
+               /* Emit "mov Rx, *R0" */
+               emit_insn(gen_movhi(
+                  gen_rtx_MEM(HImode, gen_rtx_REG(HImode, HARD_R0_REGNUM)),
+                  gen_rtx_REG(HImode, regno)));
+            }
+            else
+            {
+               /* Emit "mov Rx, *R0+" */
+               emit_insn(gen_movhi(
+                  gen_rtx_MEM(HImode, 
+                              gen_rtx_POST_INC(HImode, 
+                                 gen_rtx_REG(HImode, HARD_R0_REGNUM))),
+                  gen_rtx_REG(HImode, regno)));
+            }
+         }
+         idx++;
+      }
+   }
+   else
+   {
+      /*
+      Form 2:
+      ai sp, -regs*2       4      14+8+8   = 30
+      mov r9, *sp          2      14+8+4+8 = 34
+      mov r13, @2(sp)      4      14+8+8+8 = 38
+      mov r14, @4(sp)      4      14+8+8+8 = 38
+      mov r15, @6(sp)      4      14+8+8+8 = 38
+      mov r11, @8(sp)      4      14+8+8+8 = 38
+      ai sp, -frame        4      14+8+8   = 30
+      */
+      int offset = 0;
+      idx = 0;
+      while(nvolregs[idx] != 0)
+      {
+         if(saveregs[idx]!=0)
+         {
+            /* Emit "mov Rn, @X(sp)" */
+            int regno = nvolregs[idx];
+            emit_insn(gen_movhi(
+               adjust_address(gen_rtx_MEM(HImode, stack_pointer_rtx), 
+                              HImode, offset),
+               gen_rtx_REG(HImode, regno)));
+            offset += 2;
+         }
+         idx++;
+      }
+   }
+
+   if(frame_size > 0)
+   {
+      /* Emit "ai sp, -framesize" */
+      emit_insn(gen_addhi3(stack_pointer_rtx, stack_pointer_rtx, 
+                          GEN_INT(-frame_size)));
+   }
+
+   /* Set frame pointer */
+   if(frame_pointer_needed)
+   {
+      emit_insn(gen_movhi(gen_rtx_REG(HImode, FRAME_POINTER_REGNUM),
+                          stack_pointer_rtx));
+   }
+}
+
+
+void tms9900_expand_epilogue (bool is_sibcall)
+{
+   /*
+   There is one only form for the epilogue.
+
+   ai sp, frame         4      14+8+8   = 30
+   mov *sp+, r9         2      14+8+8+8 = 38
+   mov *sp+, r13        2      14+8+8+8 = 38
+   mov *sp+, r14        2      14+8+8+8 = 38
+   mov *sp+, r15        2      14+8+8+8 = 38
+   mov *sp+, r11        2      14+8+8+8 = 38
+   */
+
+   int saveregs[5];
+   int restored;
+
+   /* Find frame size to restore */
+   int frame_size = get_frame_size();
+
+   if(frame_size != 0)
+   {
+      /* Emit "ai sp, frame_size" */
+      emit_insn(gen_addhi3(stack_pointer_rtx, stack_pointer_rtx, 
+                           GEN_INT(frame_size)));
+   }
+
+   /* Find non-volatile registers which need to be restored */
+   int idx = 0;
+   int regcount = 0;
+   while(nvolregs[idx] != 0)
+   {      
+      int regno = nvolregs[idx];
+      saveregs[idx] = 0;
+      if(tms9900_should_save_reg(regno))
+      {
+         /* Mark this register to be saved */
+         saveregs[idx] = 1;
+         regcount++;
+      }
+      idx++;
+   }
+
+   idx = 0;
+   restored = 0;
+   while(nvolregs[idx] != 0)
+   {      
+      int regno = nvolregs[idx];
+      if(saveregs[idx] != 0)
+      {
+         /* Restore this register */
+         int regno = nvolregs[idx];
+         restored++;
+        /* Emit "mov *SP+, Rx" */
+        emit_insn(gen_movhi(
+           gen_rtx_REG(HImode, regno),
+           gen_rtx_MEM(HImode, 
+                       gen_rtx_POST_INC(HImode, stack_pointer_rtx))));
+      }
+      idx++;
+   }
+   
+   if(!is_sibcall)
+   {
+      /* Emit the return instruction "b *R11" */
+      emit_insn(gen_rtx_UNSPEC(HImode, 
+                               gen_rtvec (1, gen_rtx_REG(HImode, HARD_R11_REGNUM)),
+                               UNSPEC_RETURN));
+   }
+}
+
+
+/* All registers may be used as a base, except R0 or 
+   pseudoregs when we are in strict mod */
+int tms9900_reg_ok_for_base(int strict, rtx reg)
+{
+  return(!strict || 
+         (REGNO(reg) !=0 && REGNO(reg) <= HARD_R15_REGNUM));
+}
+
+
+/* Determine if the specified address is a valid operand */
+int tms9900_go_if_legitimate_address(enum machine_mode mode ATTRIBUTE_UNUSED, rtx operand, int strict)
+{
+  /* Accept *R0 */
+  if (GET_CODE (operand) == REG &&
+      tms9900_reg_ok_for_base(strict, operand))
+    return 1;
+
+  /* Accept *R0+ */
+  if (GET_CODE (operand) == POST_INC      &&
+      GET_CODE (XEXP (operand, 0)) == REG &&
+      tms9900_reg_ok_for_base(strict, XEXP (operand, 0)))
+    return 1;
+
+  /* Accept @xxxx */
+  if (CONSTANT_ADDRESS_P (operand))
+    return 1;
+
+  /* Accept @xxxx(R0)*/
+  if (GET_CODE (operand) == PLUS            &&
+      GET_CODE (XEXP (operand, 0)) == REG   &&
+      tms9900_reg_ok_for_base(strict, XEXP (operand, 0)) &&
+      CONSTANT_ADDRESS_P (XEXP (operand, 1)))
+    return 1;
+
+  /* Accept @(symbol+xxxx)(R0)*/
+/*
+  if(GET_CODE (operand) == PLUS )
+  {
+    if(GET_CODE(XEXP(operand,0)) == MEM)
+    {
+      rtx op = XEXP(operand,0);
+      op = XEXP(op, 0);
+      if(GET_CODE (op) == PLUS             &&
+         GET_CODE (XEXP (op, 0)) == REG    &&
+         tms9900_reg_ok_for_base(strict, XEXP (op, 0))  &&
+         CONSTANT_ADDRESS_P (XEXP (op, 1)) &&
+         CONSTANT_ADDRESS_P(XEXP(operand, 1)))
+      {
+        return 1;
+      }
+    }
+  }
+*/
+  /* Anything else is invalid */
+  return 0;
+}
+
+
+/* All aggregate types or types larger than four bytes which are
+   to be passsed by value are silently copied to the stack and 
+   then passed by reference. */
+static bool
+tms9900_pass_by_reference (CUMULATIVE_ARGS *cum ATTRIBUTE_UNUSED,
+                       enum machine_mode mode ATTRIBUTE_UNUSED,
+                       const_tree type, bool named ATTRIBUTE_UNUSED)
+{
+  unsigned int size;
+  if (type)
+    {
+      if (AGGREGATE_TYPE_P (type))
+        return(true);
+      size = int_size_in_bytes (type);
+    }
+  else
+    size = GET_MODE_SIZE (mode);
+  return(size > 4);
+}
+
+
+/* Output a difference of two labels that will be an assembly time
+   constant if the two labels are local.  (.long lab1-lab2 will be
+   very different if lab1 is at the boundary between two sections; it
+   will be relocated according to the second section, not the first,
+   so one ends up with a difference between labels in different
+   sections, which is bad in the dwarf2 eh context for instance.)  */
+void
+tms9900_asm_output_dwarf_delta (FILE *file, int size,
+                               const char *lab1, const char *lab2)
+{
+  int islocaldiff = (lab1[0] == '*' && lab1[1] == 'L'
+                     && lab2[0] == '*' && lab2[1] == 'L');
+  const char *directive = "data";
+  islocaldiff=1;
+  if(size > 2) fprintf(file,"\n\tdata 0\n",size);
+  if (islocaldiff)
+    fprintf (file, "\t.set L$set$%d,", tms9900_dwarf_label_counter);
+  else
+    fprintf (file, "\t%s\t", directive);
+  assemble_name_raw (file, lab1);
+  fprintf (file, "-");
+  assemble_name_raw (file, lab2);
+  if (islocaldiff)
+    fprintf (file, "\n\t%s L$set$%d", directive, tms9900_dwarf_label_counter++);
+}
+
+
+/* Output an offset from a label for use in a dwarf record */
+void tms9900_asm_output_dwarf_offset (FILE *file, int size, const char * lab,
+                                section *base)
+{
+  char sname[64];
+  sprintf(sname, "%s",&base->named.name[0]);
+  tms9900_asm_output_dwarf_delta (file, size, lab, sname);
+}
+
+
+/* Output an integer value of a specified size and alignemnt */
+static bool
+tms9900_asm_integer(rtx x, unsigned int size, int aligned_p)
+{
+  if(!aligned_p)
+  {
+    if(GET_CODE(x) == CONST_INT)
+    {
+      unsigned int value = INTVAL(x);
+      int i;
+      fprintf(asm_out_file, "\tbyte\t");
+      for(i = size-1; i>=1; i--)
+      {
+        fprintf(asm_out_file, "0x%X,", (value >> (i*8)) & 0xFF);        
+      }
+      fprintf(asm_out_file, "0x%X", value & 0xFF);
+      return true;
+    }
+  }
+  return default_assemble_integer(x,size,1);
+}
+
+
+//==================================================================
+// Code for tms9900_subreg pass
+
+#include "tree-pass.h"
+#include "basic-block.h"
+#include "rtl.h"
+
+static void
+tms9900_extract_subreg(rtx insn, rtx arg, rtx* parg)
+{
+  if(BINARY_P(arg))
+  {
+    /* Recurse until we find a leaf expression */
+    tms9900_extract_subreg(insn, XEXP(arg,0), &XEXP(arg,0));
+    tms9900_extract_subreg(insn, XEXP(arg,1), &XEXP(arg,1));
+  }
+  else
+
+  {
+    if(GET_CODE(arg) == SUBREG && GET_MODE(arg) == QImode)
+    {
+      /* Found a subreg expression we need to extract.
+         Place it in a seperate instruction before this one */
+      rtx temp_reg = gen_reg_rtx(QImode);
+      rtx extract = gen_rtx_SET(QImode, temp_reg, arg);
+
+      if(dump_file)
+      {
+        fprintf(dump_file, "\nModifying insn %d, extracting subreg to new instruction %d\n",
+                INSN_UID(insn), INSN_UID(extract));
+      }
+
+      /* Replace expression in instruction with our new temp register */
+      memcpy(parg, &temp_reg, sizeof(rtx));
+      emit_insn_before(extract, insn);
+
+      if(dump_file)
+      {
+        fprintf(dump_file, "New sequence:\n");
+        print_rtl_single(dump_file, extract);
+        print_rtl_single(dump_file, insn);
+      }
+    }
+  }
+}
+
+static bool
+gate_tms9900_subreg (void)
+{
+  return true;
+}
+
+static unsigned int
+tms9900_subreg (void)
+{
+  basic_block bb;
+  rtx insn;
+
+  FOR_EACH_BB (bb)
+    FOR_BB_INSNS (bb, insn)
+    if (INSN_P (insn))
+    {
+      rtx set=single_set (insn);
+      if(set !=NULL)
+      {
+        /* We only need to handle cases where there may be
+           subreg expressions in an operation in the source
+           argument. Unary expressions are already handled
+           in the machine description. */
+        rtx src=SET_SRC(set);
+        if(BINARY_P(src))
+        {
+          tms9900_extract_subreg(insn, XEXP(src,0), &XEXP(src,0));
+          tms9900_extract_subreg(insn, XEXP(src,1), &XEXP(src,1));
+        }
+      }
+    }
+  return 0;
+}
+
+
+struct rtl_opt_pass pass_tms9900_subreg =
+{
+ {
+  RTL_PASS,
+  "tms9900_subreg",                     /* name */
+  gate_tms9900_subreg,                  /* gate */
+  tms9900_subreg,                       /* execute */
+  NULL,                                 /* sub */
+  NULL,                                 /* next */
+  0,                                    /* static_pass_number */
+  0,                                    /* tv_id */
+  0,                                    /* properties_required */
+  0,                                    /* properties_provided */
+  0,                                    /* properties_destroyed */
+  0,                                    /* todo_flags_start */
+  TODO_dump_func |
+  TODO_ggc_collect                      /* todo_flags_finish */
+ }
+};
+
+
+//==================================================================
+// Code for tms9900_postinc pass
+
+/* last instruction to use target register */
+struct reg_last_used {
+  rtx insn;
+  int regnum;
+  int is_deref;
+  int mode;
+  rtx parent;
+  int argnum;
+};
+
+static struct reg_last_used reg_last_insn[1024] = {0};
+
+
+static bool
+gate_tms9900_postinc(void)
+{
+  return true;
+}
+
+
+/* Find an instruction which uses a form like *(register+constant) we could 
+   merge via pointer postincrement in an earlier instruction.*/
+static void
+tms9900_find_merge_insn(rtx insn, rtx parent, int argnum, rtx arg)
+{
+  if(MEM_P(arg))
+  {
+    rtx expr = XEXP(arg,0);
+    if(GET_CODE(expr) == PLUS)
+    {
+      rtx val1 = XEXP(expr,0);
+      rtx val2 = XEXP(expr,1);
+      int offset;
+      int regnum = -1;
+      rtx reg;
+
+      /* Isolate regnum and offset in sum */
+      if(CONST_INT_P(val1) && REG_P(val2))
+      {
+         offset = INTVAL(val1);
+         regnum = REGNO(val2);
+         reg = val2;
+      }
+      else if(CONST_INT_P(val2) && REG_P(val1))
+      {
+         offset = INTVAL(val2);
+         regnum = REGNO(val1);
+         reg = val1;
+      }
+
+      if((regnum >= 0) && 
+         (offset == 2 || offset == 1) &&
+         (find_regno_note(insn, REG_DEAD, regnum)))
+      {
+        /* Found an indexed address with a small offset, investigate further */
+        struct reg_last_used *last = &reg_last_insn[regnum];
+        if(dump_file)
+        {
+          fprintf(dump_file,"\n\nPossible merge candidate:\n");
+          print_rtl_single(dump_file, insn);
+          fprintf(dump_file,"\nLast use of reg %d was in insn %d:\n", regnum, INSN_UID(last->insn));
+          print_rtl_single(dump_file, last->insn);
+        }
+
+        if((last->is_deref) && (GET_MODE_SIZE(last->mode) == offset))
+        {
+          /* Modify previous instruction to use postincrement */
+          rtx temp_inc = gen_rtx_POST_INC(last->mode, reg);
+          rtx temp_arg = gen_rtx_MEM(last->mode,temp_inc); 
+          memcpy(XEXP(last->parent, last->argnum), temp_arg, rtx_size(temp_arg));
+
+          /* Modify this instruction to remove index */
+          temp_arg = gen_rtx_MEM(last->mode,reg); 
+          memcpy(XEXP(parent, argnum), temp_arg, rtx_size(temp_arg));
+
+          if(dump_file) 
+          {
+            fprintf(dump_file,"\nModified instruction %d:\n",INSN_UID(last->insn));
+            print_rtl_single(dump_file,last->insn);
+          }
+        }
+        else if(dump_file) fprintf(dump_file, "\nCannot merge\n");
+        return;
+      }
+    }
+  }
+
+  if(BINARY_P(arg))
+  {
+    /* This is a binary expression, check the children */
+    tms9900_find_merge_insn(insn, arg, 0, XEXP(arg,0));
+    tms9900_find_merge_insn(insn, arg, 1, XEXP(arg,1));
+  }
+  else
+  {
+    /* This is a leaf expression. Note the register used here for later */
+    int is_deref = 0;
+    if(MEM_P(arg))
+    {
+      arg = XEXP(arg,0);
+      is_deref = 1;
+    }
+    if(REG_P(arg))
+    {
+      int index = REGNO(arg);
+      reg_last_insn[index].insn = insn;
+      reg_last_insn[index].is_deref = is_deref;
+      reg_last_insn[index].mode = GET_MODE(arg);     
+      reg_last_insn[index].regnum = REGNO(arg);
+      reg_last_insn[index].parent = parent;
+      reg_last_insn[index].argnum = argnum;
+    }
+  }
+}
+
+
+static unsigned int
+tms9900_postinc (void)
+{
+  basic_block bb;
+  rtx insn;
+  int i;
+
+  FOR_EACH_BB (bb)
+  {
+    memset(reg_last_insn, 0, sizeof(reg_last_insn));
+    FOR_BB_INSNS (bb, insn)
+    {
+      if (INSN_P (insn))
+      {
+        rtx set=single_set (insn);
+        if(set !=NULL)
+        {
+          /* Look for memory references of the form *(costant+reg) */
+          tms9900_find_merge_insn(insn, set, 0, SET_DEST(set));
+          tms9900_find_merge_insn(insn, set, 1, SET_SRC(set));
+        }
+      }
+    }
+  }
+  return 0;
+}
+
+
+struct rtl_opt_pass pass_tms9900_postinc =
+{
+ {
+  RTL_PASS,
+  "tms9900_postinc",                    /* name */
+  gate_tms9900_postinc,                 /* gate */
+  tms9900_postinc,                      /* execute */
+  NULL,                                 /* sub */
+  NULL,                                 /* next */
+  0,                                    /* static_pass_number */
+  0,                                    /* tv_id */
+  0,                                    /* properties_required */
+  0,                                    /* properties_provided */
+  0,                                    /* properties_destroyed */
+  0,                                    /* todo_flags_start */
+  TODO_dump_func |
+  TODO_ggc_collect                      /* todo_flags_finish */
+ }
+};
+
diff -ru gcc-orig/gcc/config/tms9900/tms9900.h gcc-4.4.0/gcc/config/tms9900/tms9900.h
--- gcc-orig/gcc/config/tms9900/tms9900.h	2023-11-09 19:22:22.119478695 +0000
+++ gcc-4.4.0/gcc/config/tms9900/tms9900.h	2023-11-09 19:07:20.838339158 +0000
@@ -0,0 +1,1178 @@
+/* Definitions of target machine for GNU compiler.
+   Texas Instruments TMS9900
+   Copyright (C) 2009
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 3, or (at your option)
+any later version.
+
+GCC is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with GCC; see the file COPYING3.  If not see
+<http://www.gnu.org/licenses/>.
+*/
+
+/*****************************************************************************
+**
+** Controlling the Compilation Driver, `gcc'
+**
+*****************************************************************************/
+
+#undef ENDFILE_SPEC
+
+/* Define this for front-ended changes */
+#define TMS9900
+
+/* Options to pass to the assembler */
+#ifndef ASM_SPEC
+#define ASM_SPEC ""
+#endif
+
+/* Options for the linker. 
+   We need to tell the linker the target elf format.
+   This can be overridden by -Wl option of gcc.  */
+#ifndef LINK_SPEC
+#define LINK_SPEC "-m tms9900"
+#endif
+
+/* More linker options, these are used at the beginning of the command */
+#undef STARTFILE_SPEC
+/*#define STARTFILE_SPEC "crt1%O%s"*/
+#define STARTFILE_SPEC ""
+
+/* More linker options, used at the end of the command string */
+#ifndef LIB_SPEC
+#define LIB_SPEC       ""
+#endif
+
+/* Options to pass to CC1 and other language front ends */
+#ifndef CC1_SPEC
+#define CC1_SPEC       ""
+#endif
+
+/* Options to pass to the C Preprocessor */
+#ifndef CPP_SPEC
+#define CPP_SPEC ""
+#endif
+
+/* Names to predefine in the preprocessor for this target machine.  */
+#define TARGET_CPU_CPP_BUILTINS()		\
+  do						\
+    {						\
+      builtin_define_std ("tms9900");		\
+    }						\
+  while (0)
+
+/* As an embedded target, we have no libc.  */
+#ifndef inhibit_libc
+#  define inhibit_libc
+#endif
+
+/* Forward type declaration for prototypes definitions.
+   rtx_ptr is equivalent to rtx. Can't use the same name.  */
+struct rtx_def;
+typedef struct rtx_def *rtx_ptr;
+
+union tree_node;
+typedef union tree_node *tree_ptr;
+
+/* We can't declare enum machine_mode forward nor include 'machmode.h' here.
+   Prototypes defined here will use an int instead. It's better than no
+   prototype at all.  */
+typedef int enum_machine_mode;
+
+/*****************************************************************************
+**
+** Run-time Target Specification
+**
+*****************************************************************************/
+
+/* Run-time compilation parameters selecting different hardware subsets.  */
+
+extern short *reg_renumber;	/* def in local_alloc.c */
+
+#define TARGET_OP_TIME		(optimize && optimize_size == 0)
+#define TARGET_RELAX            (TARGET_NO_DIRECT_MODE)
+
+/* Default target_flags if no switches specified.  */
+#ifndef TARGET_DEFAULT
+# define TARGET_DEFAULT		0
+#endif
+
+/* Define this macro as a C expression for the initializer of an
+   array of string to tell the driver program which options are
+   defaults for this target and thus do not need to be handled
+   specially when using `MULTILIB_OPTIONS'.  */
+#ifndef MULTILIB_DEFAULTS
+# define MULTILIB_DEFAULTS { "tms9900" }
+#endif
+
+/* Print subsidiary information on the compiler version in use.  */
+#define TARGET_VERSION	fprintf (stderr, " (TMS9900)")
+
+
+/* Target machine storage layout */
+
+/* Define this as 1 if most significant byte of a word is the lowest numbered.  */
+#define BYTES_BIG_ENDIAN 	1
+
+/* Define this as 1 if most significant bit is lowest numbered
+   in instructions that operate on numbered bit-fields.  */
+#define BITS_BIG_ENDIAN         1
+
+/* Define this as 1 if most significant word of a multiword number is lowest numbered.  */
+#define WORDS_BIG_ENDIAN 	1
+
+/* Width of a word, in units (bytes).  */
+#define UNITS_PER_WORD		2
+
+/* Definition of size_t.  This is really an unsigned short as the
+   TMS9900 only handles a 64K address space.  */
+#define SIZE_TYPE               "short unsigned int"
+
+/* A C expression for a string describing the name of the data type
+   to use for the result of subtracting two pointers.  The typedef
+   name `ptrdiff_t' is defined using the contents of the string.
+   The TMS9900 only has a 64K address space.  */
+#define PTRDIFF_TYPE            "short int"
+
+/* Allocation boundary (bits) for storing pointers in memory.  */
+#define POINTER_BOUNDARY	16
+
+/* Normal alignment required for function parameters on the stack, in bits.
+   This can't be less than BITS_PER_WORD */
+#define PARM_BOUNDARY		(BITS_PER_WORD)
+
+/* Boundary (bits) on which stack pointer should be aligned.  */
+#define STACK_BOUNDARY		16
+
+/* Allocation boundary (bits) for the code of a function.  */
+#define FUNCTION_BOUNDARY	16
+
+/* Biggest alignment which, if violated, may cause a fault */
+#define BIGGEST_ALIGNMENT	16
+
+/* Alignment of field after `int : 0' in a structure.  */
+#define EMPTY_FIELD_BOUNDARY	16
+
+/* Every structure's size must be a multiple of this.  */
+#define STRUCTURE_SIZE_BOUNDARY 16
+
+/* Define this as 1 if instructions will fail to work if given data not
+   on the nominal alignment.  If instructions will merely go slower
+   in that case, do not define this macro.  */
+#define STRICT_ALIGNMENT	1
+
+/* An integer expression for the size in bits of the largest integer
+   machine mode that should actually be used.  All integer machine modes of
+   this size or smaller can be used for structures and unions with the
+   appropriate sizes.  */
+#define MAX_FIXED_MODE_SIZE	64
+
+/* target machine storage layout */
+
+/* Size (bits) of the type "int" on target machine */
+#define INT_TYPE_SIZE           16
+
+/* Size (bits) of the type "short" on target machine */
+#define SHORT_TYPE_SIZE		16
+
+/* Size (bits) of the type "long" on target machine */
+#define LONG_TYPE_SIZE		32
+
+/* Size (bits) of the type "long long" on target machine */
+#define LONG_LONG_TYPE_SIZE     64
+
+/* A C expression for the size in bits of the type `float' on the
+   target machine. If you don't define this, the default is one word.
+   Don't use default: a word is only 16.  */
+#define FLOAT_TYPE_SIZE         32
+
+/* A C expression for the size in bits of the type double on the target
+   machine. If you don't define this, the default is two words.
+   Be IEEE compliant.  */
+#define DOUBLE_TYPE_SIZE        64
+
+#define LONG_DOUBLE_TYPE_SIZE   64
+
+/* Define this as 1 if `char' should by default be signed; else as 0.  */
+#define DEFAULT_SIGNED_CHAR	1
+
+/* A C expression for a string describing the name of the data type
+   to use for wide characters.  The typedef name `wchar_t' is defined
+   using the contents of the string.
+   
+   Define these to avoid dependence on meaning of `int'.
+   Note that WCHAR_TYPE_SIZE is used in cexp.y,
+   where TARGET_SHORT is not available.  */
+#define WCHAR_TYPE              "short int"
+#define WCHAR_TYPE_SIZE         16
+
+/* Standard register usage.  */
+
+#define HARD_REG_SIZE           (2)
+
+#define REGS_PER_WORD (UNITS_PER_WORD / HARD_REG_SIZE)
+
+/* Assign names to real TMS9900 registers. */
+#define HARD_R0_REGNUM		0
+#define HARD_R1_REGNUM		1
+#define HARD_R2_REGNUM		2
+#define HARD_R3_REGNUM		3
+#define HARD_R4_REGNUM		4
+#define HARD_R5_REGNUM		5
+#define HARD_R6_REGNUM		6
+#define HARD_R7_REGNUM		7
+#define HARD_R8_REGNUM		8
+#define HARD_R9_REGNUM		9
+#define HARD_R10_REGNUM		10
+#define HARD_R11_REGNUM		11
+#define HARD_R12_REGNUM		12
+#define HARD_R13_REGNUM		13
+#define HARD_R14_REGNUM		14
+#define HARD_R15_REGNUM		15
+
+/* Shift count register */
+#define HARD_SC_REGNUM		HARD_R0_REGNUM
+/* Stack pointer */
+#define HARD_SP_REGNUM		HARD_R10_REGNUM
+/* Old PC after BL instruction */
+#define HARD_LR_REGNUM		HARD_R11_REGNUM
+/* CRU base address */
+#define HARD_CB_REGNUM		HARD_R12_REGNUM
+/* Old workspace after BLWP instruction */
+#define HARD_LW_REGNUM		HARD_R13_REGNUM
+/* Old PC after BLWP instruction */
+#define HARD_LP_REGNUM		HARD_R14_REGNUM
+/* Old status register after BLWP instruction */
+#define HARD_LS_REGNUM		HARD_R15_REGNUM
+
+/* How to refer to registers in assembler output.  This sequence is indexed
+   by compiler's hard-register-number (see above). */
+#define REGISTER_NAMES \
+{ "r0",  "r1", "r2",  "r3",  "r4",  "r5",  "r6",  "r7",  \
+  "r8",  "r9", "r10", "r11", "r12", "r13", "r14", "r15"}
+
+/* Number of actual hardware registers. The hardware registers are assigned
+   numbers for the compiler from 0 to just below FIRST_PSEUDO_REGISTER. 
+   All registers that the compiler knows about must be given numbers, even
+   those that are not normally considered general registers.  */
+#define FIRST_PSEUDO_REGISTER	(16)
+
+/* 1 for registers that have pervasive standard uses and are not available
+   for the register allocator.  */
+#define FIXED_REGISTERS \
+  {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0}
+/* SC 1  2  3  4  5  6  7  8  9  SP LR CB LW LP LS*/
+
+/* 0 for registers which must be preserved across function call boundaries */
+#define CALL_USED_REGISTERS \
+  {1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0}
+/* SC 1  2  3  4  5  6  7  8  9  SP LR CB LW LP LS*/
+
+/* Define this macro to change register usage conditional on target flags. */
+#define CONDITIONAL_REGISTER_USAGE 
+
+/* List the order in which to allocate registers.  Each register must be
+   listed once, even those in FIXED_REGISTERS.  */
+#define REG_ALLOC_ORDER	\
+   {HARD_R1_REGNUM, HARD_R2_REGNUM, HARD_R3_REGNUM, HARD_R4_REGNUM,\
+    HARD_R5_REGNUM, HARD_R6_REGNUM, HARD_R7_REGNUM, HARD_R8_REGNUM,\
+    HARD_CB_REGNUM, HARD_SC_REGNUM, HARD_R9_REGNUM, HARD_LW_REGNUM,\
+    HARD_LP_REGNUM, HARD_LS_REGNUM, HARD_LR_REGNUM, HARD_SP_REGNUM}
+
+/* A C expression for the number of consecutive hard registers,
+   starting at register number REGNO, required to hold a value of
+   mode MODE.  */
+#define HARD_REGNO_NREGS(REGNO, MODE) \
+   ((GET_MODE_SIZE (MODE) + HARD_REG_SIZE - 1) / HARD_REG_SIZE)
+
+/* Value is 1 if hard register REGNO (or starting with REGNO) can hold a value of machine-mode MODE */
+#define HARD_REGNO_MODE_OK(REGNO, MODE) \
+   (!(MODE == SImode && REGNO==HARD_R15_REGNUM))
+  
+/* A C expression that is nonzero if hard register number REGNO2 can be
+   considered for use as a rename register for REGNO1 */
+#define HARD_REGNO_RENAME_OK(REGNO1,REGNO2) 1
+
+/* Value is 1 if it is a good idea to tie two pseudo registers when one has
+   mode MODE1 and one has mode MODE2.  If HARD_REGNO_MODE_OK could produce
+   different values for MODE1 and MODE2, for any hard reg, then this must be
+   0 for correct output. */
+#define MODES_TIEABLE_P(MODE1, MODE2) 0
+
+/* Define the classes of registers for register constraints in the
+   machine description.  Also define ranges of constants.
+
+   One of the classes must always be named ALL_REGS and include all hard regs.
+   If there is more than one class, another class must be named NO_REGS
+   and contain no registers.
+
+   The classes must be numbered in nondecreasing order; that is,
+   a larger-numbered class must never be contained completely
+   in a smaller-numbered class.
+
+   For any two classes, it is very desirable that there be another
+   class that represents their union.  */
+enum reg_class
+{
+  NO_REGS,
+  SHIFT_REGS,     /* Register used for variable shift (SC) */
+  CRU_REGS,       /* Register used for CRU access (CB) */
+  BASE_REGS,      /* Registers which may be used as a memory base */
+  ALL_REGS,       /* All registers, including fakes */
+  LIM_REG_CLASSES
+};
+
+/* The name GENERAL_REGS must be the name of a class (or an alias for
+   another name such as ALL_REGS).  This is the class of registers
+   that is allowed by "g" or "r" in a register constraint.
+   Also, registers outside this class are allocated only when
+   instructions express preferences for them. */
+#define GENERAL_REGS	ALL_REGS
+
+/* The number of distict register classes */
+#define N_REG_CLASSES	(int) LIM_REG_CLASSES
+
+/* Give names of register classes as strings for dump file.  */
+#define REG_CLASS_NAMES \
+{ "NO_REGS",       \
+  "SHIFT_REGS",    \
+  "CRU_REGS",      \
+  "BASE_REGS",     \
+  "ALL_REGS" }
+
+/* An initializer containing the contents of the register classes,
+   as integers which are bit masks.  The Nth integer specifies the
+   contents of class N.  The way the integer MASK is interpreted is
+   that register R is in the class if `MASK & (1 << R)' is 1.  */
+
+/*--------------------------------------------------------------
+   SC      0x00000001
+   R1      0x00000002
+   R2      0x00000004
+   R3      0x00000008
+   R4      0x00000010
+   R5      0x00000020
+   R6      0x00000040
+   R7      0x00000080
+   R8      0x00000100
+   R9      0x00000200
+   SP      0x00000400
+   LR      0x00000800
+   CB      0x00001000
+   LW      0x00002000
+   LP      0x00004000
+   LS      0x00008000
+--------------------------------------------------------------*/
+
+#define REG_CLASS_CONTENTS \
+/* NO_REGS       */  {{ 0x00000000 }, \
+/* SHIFT_REGS    */   { 0x00000001 }, /* SC */ \
+/* CRU_REGS      */   { 0x00001000 }, /* CB */ \
+/* BASE_REGS     */   { 0x0000FFFE }, \
+/* ALL_REGS      */   { 0x0000FFFF }}
+
+/* Set up a C expression whose value is a register class containing hard
+   register REGNO */
+#define REGNO_REG_CLASS(REGNO) \
+   (REGNO == HARD_SC_REGNUM  ? SHIFT_REGS : \
+    REGNO == HARD_CB_REGNUM  ? CRU_REGS   : \
+    REGNO <= HARD_R15_REGNUM ? ALL_REGS   : \
+    NO_REGS)
+
+/* Get register class from a letter in the machine description. */
+#define REG_CLASS_FROM_LETTER(C) \
+   ((C) == 'S' ? SHIFT_REGS : \
+    (C) == 'C' ? CRU_REGS   : \
+    (C) == 'T' ? ALL_REGS   : \
+    NO_REGS)
+
+/* A C expression that places additional restrictions of the register
+   class to use when it is necessary to copy value X into a register
+   in class CLASS. Some values may require the use of a more restrictive
+   class.*/
+#define PREFERRED_RELOAD_CLASS(X,CLASS)	CLASS
+
+/* Return the maximum number of consecutive registers needed to represent
+   mode MODE in a register of class CLASS.  */
+#define CLASS_MAX_NREGS(CLASS, MODE) \
+   ((GET_MODE_SIZE (MODE) + UNITS_PER_WORD - 1) / UNITS_PER_WORD)
+
+/* The letters I, J, K, L and M in a register constraint string
+   can be used to stand for particular ranges of immediate operands.
+   This macro defines what the ranges are.
+   C is the letter, and VALUE is a constant value.
+   Return 1 if VALUE is in the range specified by C.
+
+   'I' is for 32-bit value xxxx0000
+   'J' is for 32-bit value 0000xxxx
+   'K' is for 32-bit value xxxxxxxx
+   'L' is for 1
+   'M' is for -1
+   'N' is for 0
+   'O' is for 2 or -2
+   'P' is for 16-bit value 00ff
+*/
+#define CONST_OK_FOR_LETTER_P(VALUE, C) \
+  ((C) == 'L' ? ((VALUE) == 2 || (VALUE) == -2): \
+   (C) == 'M' ? ((VALUE) == -1): \
+   (C) == 'N' ? ((VALUE) == 1): \
+   (C) == 'O' ? ((VALUE) == 0): \
+   (C) == 'P' ? ((VALUE) == 0x00ff): \
+   (C) == 'I' ? ((VALUE) & 0xffff0000) == 0: \
+   (C) == 'J' ? ((VALUE) & 0x0000ffff) == 0: \
+   (C) == 'K' ? (((VALUE) & 0xffff0000) != 0 && \
+		 ((VALUE) & 0x0000ffff) != 0): \
+   0)
+
+/* Similar, but for floating constants, and defining letters G and H.
+
+   `G' is for 0.0.  */
+#define CONST_DOUBLE_OK_FOR_LETTER_P(VALUE, C) \
+  ((C) == 'G' ? (GET_MODE_CLASS (GET_MODE (VALUE)) == MODE_FLOAT \
+		 && VALUE == CONST0_RTX (GET_MODE (VALUE))) : 0) 
+
+/* Letters in the range `Q' through `U' may be defined in a
+   machine-dependent fashion to stand for arbitrary operand types. 
+   The machine description macro `EXTRA_CONSTRAINT' is passed the
+   operand as its first argument and the constraint letter as its
+   second operand.
+
+   This macro returns 1 if the provided CODE matches the provided OP
+
+   `Q'	is for memory references that require an extra word after the opcode.
+   `R'	is for memory references which are encoded within the opcode.  */
+#define EXTRA_CONSTRAINT(OP,CODE)					\
+  ((GET_CODE (OP) != MEM) ? 0						\
+   : !legitimate_address_p (GET_MODE (OP), XEXP (OP, 0)) ? 0		\
+   : ((CODE) == 'Q') ? (tms9900_address_type (OP, GET_MODE (OP)) == 3)  \
+   : ((CODE) == 'R') ? (tms9900_address_type (OP, GET_MODE (OP)) == 1)	\
+   : 0)
+
+/* Stack layout; function entry, exit and calling.  */
+
+/* Define this if pushing a word on the stack
+   makes the stack pointer a smaller address.  */
+#define STACK_GROWS_DOWNWARD
+
+/* Define this to nonzero if the nominal address of the stack frame
+   is at the high-address end of the local variables;
+   that is, each additional local variable allocated
+   goes at a more negative offset in the frame.
+
+   Define to 0 for TMS9900, the frame pointer is the bottom
+   of local variables.  */
+#define FRAME_GROWS_DOWNWARD 0
+
+/* Offset within stack frame to start allocating local variables at.
+   If FRAME_GROWS_DOWNWARD, this is the offset to the END of the
+   first local allocated.  Otherwise, it is the offset to the BEGINNING
+   of the first local allocated.  */
+#define STARTING_FRAME_OFFSET 0
+
+/* Offset of first parameter from the argument pointer register value.  */
+#define FIRST_PARM_OFFSET(FNDECL)	0
+
+/* After the prologue, RA is at 0(AP) in the current frame.  */
+#define RETURN_ADDR_RTX(COUNT, FRAME)					\
+  ((COUNT) == 0								\
+   ? gen_rtx_MEM (Pmode, arg_pointer_rtx)                               \
+   : 0)
+
+/* Before the prologue, the top of the frame is at 2(sp).  */
+#define INCOMING_FRAME_SP_OFFSET        0
+
+/* Register to use for pushing function arguments.  */
+#define STACK_POINTER_REGNUM		HARD_SP_REGNUM
+
+/* Base register for access to local variables of the function.  */
+#define FRAME_POINTER_REGNUM		HARD_R9_REGNUM
+
+/* Base register for access to arguments of the function.  */
+#define ARG_POINTER_REGNUM		HARD_R7_REGNUM
+
+/* Register in which static-chain is passed to a function.  */
+#define STATIC_CHAIN_REGNUM	        HARD_R9_REGNUM
+
+/* Definitions for register eliminations.
+
+   This is an array of structures.  Each structure initializes one pair
+   of eliminable registers.  The "from" register number is given first,
+   followed by "to".  Eliminations of the same "from" register are listed
+   in order of preference.
+
+   The pseudo arg pointer and pseudo frame pointer registers can always
+   be eliminated; they are replaced with either the stack or the real
+   frame pointer.  */
+#define ELIMINABLE_REGS \
+  {{ARG_POINTER_REGNUM,   STACK_POINTER_REGNUM},\
+   {ARG_POINTER_REGNUM,   FRAME_POINTER_REGNUM},\
+   {FRAME_POINTER_REGNUM, STACK_POINTER_REGNUM}}
+
+/* Value should be nonzero if functions must have frame pointers.
+   Zero means the frame pointer need not be set up (and parms may be
+   accessed via the stack pointer) in functions that seem suitable.
+   This is computed in `reload', in reload1.c.  */
+#define FRAME_POINTER_REQUIRED	0
+
+#define CAN_DEBUG_WITHOUT_FP 1
+
+/* Given FROM and TO register numbers, say whether this elimination is allowed.
+   Frame pointer elimination is automatically handled.
+
+   All other eliminations are valid.  */
+#define CAN_ELIMINATE(FROM, TO)		1
+
+/* Define the offset between two registers, one to be eliminated, and the other
+   its replacement, at the start of a routine.  */
+#define INITIAL_ELIMINATION_OFFSET(FROM, TO, OFFSET) \
+    { OFFSET = tms9900_initial_elimination_offset (FROM, TO); }
+
+/* Passing Function Arguments on the Stack.  */
+
+/* A C expression.  If nonzero, push insns will be used to pass
+   outgoing arguments.  If the target machine does not have a push
+   instruction, set it to zero.  That directs GCC to use an alternate
+   strategy: to allocate the entire argument block and then store the
+   arguments into it.  When `PUSH_ARGS' is nonzero, `PUSH_ROUNDING'
+   must be defined too. */
+#define PUSH_ARGS 0
+
+/* Value is 1 if returning from a function call automatically pops the
+   arguments described by the number-of-args field in the call. FUNTYPE is
+   the data type of the function (as a tree), or for a library call it is
+   an identifier node for the subroutine name. */
+#define RETURN_POPS_ARGS(FUNDECL,FUNTYPE,SIZE)	0
+
+/* Passing Arguments in Registers.  */
+
+
+/* The number of argument registers we can use (R1..R6) */
+#define TMS9900_ARG_REGS (HARD_R7_REGNUM - HARD_R1_REGNUM)
+
+/* Define a data type for recording info about an argument list
+   during the scan of that argument list.  This data type should
+   hold all necessary information about the function itself
+   and about the args processed so far, enough to enable macros
+   such as FUNCTION_ARG to determine where the next arg should go.  */
+typedef struct tms9900_args
+{
+  int nregs;        /* Number of registers used so far */
+  int named_count;  /* Number of named arguments (for varargs) */  
+} CUMULATIVE_ARGS;
+
+/* If defined, a C expression which determines whether, and in which direction,
+   to pad out an argument with extra space.  The value should be of type
+   `enum direction': either `upward' to pad above the argument,
+   `downward' to pad below, or `none' to inhibit padding.
+
+   Structures are stored left shifted in their argument slot.  */
+#define FUNCTION_ARG_PADDING(MODE, TYPE) \
+  tms9900_function_arg_padding ((MODE), (TYPE))
+
+#undef PAD_VARARGS_DOWN
+#define PAD_VARARGS_DOWN \
+  (tms9900_function_arg_padding (TYPE_MODE (type), type) == downward)
+
+/* Initialize a variable CUM of type CUMULATIVE_ARGS for a call to a
+   function whose data type is FNTYPE. For a library call, FNTYPE is 0.  */
+#define INIT_CUMULATIVE_ARGS(CUM, FNTYPE, LIBNAME, INDIRECT, N_NAMED_ARGS) \
+   (tms9900_init_cumulative_args (&CUM, FNTYPE, LIBNAME))
+
+/* Update the data in CUM to advance over an argument of mode MODE and data
+   type TYPE. (TYPE is null for libcalls where that information may not be
+   available.) */
+#define FUNCTION_ARG_ADVANCE(CUM, MODE, TYPE, NAMED) \
+    (tms9900_function_arg_advance (&CUM, MODE, TYPE, NAMED))
+
+/* Define where to put the arguments to a function.
+   Value is zero to push the argument on the stack,
+   or a hard register in which to store the argument.
+
+   MODE is the argument's machine mode.
+   TYPE is the data type of the argument (as a tree).
+    This is null for libcalls where that information may
+    not be available.
+   CUM is a variable of type CUMULATIVE_ARGS which gives info about
+    the preceding args and about the function being called.
+   NAMED is nonzero if this argument is a named parameter
+    (otherwise it is an extra parameter matching an ellipsis).  */
+#define FUNCTION_ARG(CUM, MODE, TYPE, NAMED) \
+  (tms9900_function_arg (&CUM, MODE, TYPE, NAMED))
+
+/* This target hook should return `true' if an argument at the
+   position indicated by CUM should be passed by reference.  This
+   predicate is queried after target independent reasons for being
+   passed by reference, such as `TREE_ADDRESSABLE (type)'.
+
+   If the hook returns true, a copy of that argument is made in
+   memory and a pointer to the argument is passed instead of the
+   argument itself.  The pointer is passed in whatever way is
+   appropriate for passing a pointer to that type. */
+/*
+#define TARGET_PASS_BY_REFERENCE(CUM,MODE,TYPE,NAMED) \
+ (TYPE && TREE_CODE (TYPE_SIZE (TYPE)) != INTEGER_CST)
+*/
+
+/* Define the profitability of saving registers around calls.
+
+   Disable this because the saving instructions generated by
+   caller-save need a reload and the way it is implemented,
+   it forbids all spill registers at that point.  Enabling
+   caller saving results in spill failure.  */
+#define CALLER_SAVE_PROFITABLE(REFS,CALLS) 0
+
+/* 1 if N is a possible register number for function argument passing. */
+#define FUNCTION_ARG_REGNO_P(N)	\
+     (((N) >= HARD_R1_REGNUM) && ((N) <= HARD_R6_REGNUM))
+
+/* 8- and 16-bit values are returned in R1, 32-bit values are
+   passed in R1+R2, The high word is in R1. */
+#define FUNCTION_VALUE(VALTYPE, FUNC) tms9900_function_value(VALTYPE)
+
+/* 8- and 16-bit values are returned in R1, 32-bit values are
+   passed in R1+R2, The high word is in R1. */
+#define LIBCALL_VALUE(MODE)						\
+     gen_rtx_REG (MODE, HARD_R1_REGNUM)
+
+/* 1 if N is a possible register number for a function value.  */
+#define FUNCTION_VALUE_REGNO_P(N) \
+     ((N) == HARD_R1_REGNUM)
+
+/* EXIT_IGNORE_STACK should be nonzero if, when returning from a function,
+   the stack pointer does not matter.  The value is tested only in functions
+   that have frame pointers. No definition is equivalent to always zero.  */
+#define EXIT_IGNORE_STACK	0
+
+/* Generating Code for Profiling.  */
+
+/* Output assembler code to FILE to increment profiler label # LABELNO
+   for profiling a function entry.  */
+#define FUNCTION_PROFILER(FILE, LABELNO)		\
+    fprintf (FILE, "\tldy\tLP%d\n\tjsr mcount\n", (LABELNO))
+
+/* Let's see whether this works as trampoline:
+     LI Rn, @STATIC	0x0200	0x0000 <- STATIC; Y = STATIC_CHAIN_REGNUM
+     B  FUNCTION	0x0820  0x0000 <- FUNCTION
+*/
+#define TRAMPOLINE_TEMPLATE(FILE)	\
+{					\
+  assemble_aligned_integer (2, GEN_INT (0x0200+STATIC_CHAIN_REGNUM));	\
+  assemble_aligned_integer (2, const0_rtx);				\
+  assemble_aligned_integer (2, GEN_INT(0x0820));			\
+  assemble_aligned_integer (2, const0_rtx);				\
+}
+
+#define TRAMPOLINE_SIZE 8
+#define TRAMPOLINE_ALIGNMENT 16
+
+/* Emit RTL insns to initialize the variable parts of a trampoline.
+   FNADDR is an RTX for the address of the function's pure code.
+   CXT is an RTX for the static chain value for the function.  */
+#define INITIALIZE_TRAMPOLINE(TRAMP,FNADDR,CXT)	\
+{					\
+  emit_move_insn (gen_rtx_MEM (HImode, plus_constant (TRAMP, 2)), CXT); \
+  emit_move_insn (gen_rtx_MEM (HImode, plus_constant (TRAMP, 6)), FNADDR); \
+}
+
+/* The TMS9900 can only do post increment */
+#define HAVE_POST_INCREMENT  (1)
+#define HAVE_PRE_INCREMENT   (0)
+#define HAVE_POST_DECREMENT  (0)
+#define HAVE_PRE_DECREMENT   (0)
+#define HAVE_POST_MODIFY_REG (1)
+
+/* The name of the class to which a valid base register must belong.
+   A base register is one used in an address which is the register
+   value plus a displacement. */
+#define BASE_REG_CLASS	BASE_REGS
+
+/* The class value for index registers. */
+#define INDEX_REG_CLASS	NO_REGS
+
+/* A C expression which is nonzero if register number NUM is suitable
+   for use as a base register in operand addresses.  It may be either
+   a suitable hard register or a pseudo register that has been
+   allocated such a hard register. 
+   Any hard register except R0 is a valid base */
+#define REGNO_OK_FOR_BASE_P(NUM) \
+   ((NUM) >= HARD_R1_REGNUM && (NUM) <= HARD_R15_REGNUM)
+
+/* A C expression which is nonzero if register number NUM is suitable
+   for use as an index register in operand addresses.  It may be
+   either a suitable hard register or a pseudo register that has been
+   allocated such a hard register. The difference between an index
+   register and a base register is that the index register may be scaled. */
+#define REGNO_OK_FOR_INDEX_P(NUM) 0
+
+/* 1 if X is an rtx for a constant that is a valid address.  */
+/*
+#define CONSTANT_ADDRESS_P(X)	\
+  (GET_CODE (X) == LABEL_REF || GET_CODE (X) == SYMBOL_REF \
+          || CONST_INT_P (X) || GET_CODE (X) == CONST      \
+          || GET_CODE (X) == HIGH)
+*/
+#define CONSTANT_ADDRESS_P(X)  CONSTANT_P(X)
+
+/* Maximum number of registers that can appear in a valid memory address */
+#define MAX_REGS_PER_ADDRESS	1
+
+/* The behavior of several macros depend on whether or not we are in 
+   strict mode. Define a constant for this */
+#ifdef REG_OK_STRICT
+#define IS_STRICT_P 1
+#else
+#define IS_STRICT_P 0
+#endif
+
+/* GO_IF_LEGITIMATE_ADDRESS recognizes an RTL expression that is a
+   valid memory address for an instruction. The MODE argument is the
+   machine mode for the MEM expression that wants to use this address.  */
+
+/*--------------------------------------------------------------
+   Valid addresses are either direct or indirect (MEM) versions
+   of the following forms:
+	constant		N
+	register		X
+	indexed			N,X
+--------------------------------------------------------------*/
+
+/* GO_IF_LEGITIMATE_ADDRESS recognizes an RTL expression
+   that is a valid memory address for an instruction.
+   The MODE argument is the machine mode for the MEM expression
+   that wants to use this address. */
+#define GO_IF_LEGITIMATE_ADDRESS(mode, operand, ADDR) \
+  { \
+  if(tms9900_go_if_legitimate_address(mode, operand, IS_STRICT_P)) \
+    { \
+    goto ADDR; \
+    } \
+  fail: ;\
+  }
+
+/* The macros REG_OK_FOR..._P assume that the arg is a REG rtx and check its
+   validity for a certain class.  We have two alternate definitions for each
+   of them.  The usual definition accepts all pseudo regs; the other rejects
+   them unless they have been allocated suitable hard regs.  The symbol
+   REG_OK_STRICT causes the latter definition to be used.
+  
+   Most source files want to accept pseudo regs in the hope that they will
+   get allocated to the class that the insn wants them to be in. Source files
+   for reload pass need to be strict. After reload, it makes no difference,
+   since pseudo regs have been eliminated by then.  */
+#define REG_OK_FOR_BASE_P(X) (tms9900_reg_ok_for_base(IS_STRICT_P, X)) 
+
+/* Nonzero if X is a hard reg that can be used as an index.  */
+#define REG_OK_FOR_INDEX_P(X) (0)
+
+
+/* Try machine-dependent ways of modifying an illegitimate address
+   to be legitimate.  If we find one, return the new, valid address.
+   This macro is used in only one place: `memory_address' in explow.c.
+  
+   OLDX is the address as it was before break_out_memory_refs was called.
+   In some cases it is useful to look at this to decide what needs to be done.
+  
+   MODE and WIN are passed so that this macro can use
+   GO_IF_LEGITIMATE_ADDRESS.
+  
+   It is always safe for this macro to do nothing.
+   It exists to recognize opportunities to optimize the output.  */
+#define LEGITIMIZE_ADDRESS(X,OLDX,MODE,WIN)
+  
+/* Go to LABEL if ADDR (a legitimate address expression)
+   has an effect that depends on the machine mode it is used for.  */
+#define GO_IF_MODE_DEPENDENT_ADDRESS(ADDR,LABEL)
+
+/* Nonzero if the constant value X is a legitimate general operand.
+   It is given that X satisfies CONSTANT_P or is a CONST_DOUBLE.  */
+#define LEGITIMATE_CONSTANT_P(X)	1
+
+/* Tell final.c how to eliminate redundant test instructions.  */
+#define NOTICE_UPDATE_CC(EXP, INSN) \
+{ if (GET_CODE (EXP) == SET)					\
+    {								\
+      notice_update_cc_on_set(EXP, INSN);			\
+    }								\
+  else if (GET_CODE (EXP) == PARALLEL				\
+	   && GET_CODE (XVECEXP (EXP, 0, 0)) == SET)		\
+    {								\
+      notice_update_cc_on_set(XVECEXP (EXP, 0, 0), INSN);	\
+    }								\
+  else if (GET_CODE (EXP) == CALL)				\
+    { /* all bets are off */ CC_STATUS_INIT; }			\
+  if (cc_status.value1 && GET_CODE (cc_status.value1) == REG	\
+      && cc_status.value2					\
+      && reg_overlap_mentioned_p (cc_status.value1, cc_status.value2)) \
+    { 								\
+      cc_status.value2 = 0;					\
+    }								\
+}
+
+/*   A C expression for the cost of moving data of mode MODE from a
+     register in class FROM to one in class TO.  The classes are
+     expressed using the enumeration values such as `GENERAL_REGS'.  A
+     value of 2 is the default; other values are interpreted relative to
+     that.
+
+     It is not required that the cost always equal 2 when FROM is the
+     same as TO; on some machines it is expensive to move between
+     registers if they are not general registers.
+
+     If reload sees an insn consisting of a single `set' between two
+     hard registers, and if `REGISTER_MOVE_COST' applied to their
+     classes returns a value of 2, reload does not check to ensure that
+     the constraints of the insn are met.  Setting a cost of other than
+     2 will allow reload to verify that the constraints are met.  You
+     should do this if the `movM' pattern's constraints do not allow
+     such copying. */
+#define REGISTER_MOVE_COST(MODE, FROM, TO) 4
+
+/* A C expression for the cost of moving data of mode MODE between a
+   register of class CLASS and memory; IN is zero if the value is to
+   be written to memory, nonzero if it is to be read in.  This cost
+   is relative to those in `REGISTER_MOVE_COST'.  If moving between
+   registers and memory is more expensive than between two registers,
+   you should define this macro to express the relative cost
+
+   For the TMS9900, memory access is four times slower than registers */
+#define MEMORY_MOVE_COST(MODE,CLASS,IN)	16
+
+/* A C expression for the cost of a branch instruction.  A value of 1
+   is the default; other values are interpreted relative to that.
+
+   Pretend branches are cheap because GCC generates sub-optimal code
+   for the default value.  */
+#define BRANCH_COST(speed_p, predictable_p) 0
+
+/* Nonzero if access to memory by bytes is slow and undesirable.  */
+#define SLOW_BYTE_ACCESS 0
+
+/* Defining the Output Assembler Language.  */
+
+/* A default list of other sections which we might be "in" at any given
+   time.  For targets that use additional sections (e.g. .tdesc) you
+   should override this definition in the target-specific file which
+   includes this file.  */
+
+/* Output before read-only data.  */
+#define TEXT_SECTION_ASM_OP	("\tpseg")
+
+/* Output before writable data.  */
+#define DATA_SECTION_ASM_OP	("\tdseg")
+
+/* Output before uninitialized data.  */
+#define BSS_SECTION_ASM_OP 	("\tcseg")
+
+/* Define this macro to be an expression with a nonzero value if jump tables
+   (for tablejump insns) should be output in the text section, along with the
+   assembler instructions. Otherwise, the readonly data section is used. */
+#define JUMP_TABLES_IN_TEXT_SECTION 1
+
+
+/* Define the pseudo-ops used to switch to the .ctors and .dtors sections.
+
+   Same as config/elfos.h but don't mark these section SHF_WRITE since
+   there is no shared library problem.  */
+/*EMW - Neglect C++ for now...
+#undef CTORS_SECTION_ASM_OP
+#define CTORS_SECTION_ASM_OP	"\t.section\t.ctors,\"a\""
+
+#undef DTORS_SECTION_ASM_OP
+#define DTORS_SECTION_ASM_OP	"\t.section\t.dtors,\"a\""
+
+#define TARGET_ASM_CONSTRUCTOR  tms9900_asm_out_constructor
+#define TARGET_ASM_DESTRUCTOR   tms9900_asm_out_destructor
+EMW*/
+
+/* Comment character */
+#define ASM_COMMENT_START	"*"
+
+/* Output to assembler file text saying following lines
+   may contain character constants, extra white space, comments, etc.  */
+#define ASM_APP_ON 		"* Begin inline assembler code\n"
+
+/* Output to assembler file text saying following lines
+   no longer contain unusual constructs.  */
+#define ASM_APP_OFF 		"* End of inline assembler code\n"
+
+/* output external reference */
+#undef ASM_OUTPUT_EXTERNAL
+#define ASM_OUTPUT_EXTERNAL(FILE,DECL,NAME) \
+  {fputs ("\n\tref\t", FILE); \
+  assemble_name (FILE, NAME); \
+  fputs ("\n", FILE);}
+
+#define ASM_OUTPUT_LABEL(FILE,NAME) \
+  {							\
+    assemble_name ((FILE), (NAME));			\
+    fputc ('\n', (FILE));				\
+  }
+
+#define ASM_OUTPUT_INTERNAL_LABEL(FILE,NAME) \
+  {							\
+    assemble_name ((FILE), (NAME));			\
+    fputc ('\n', (FILE));				\
+  }
+
+/* Print operand X (an rtx) in assembler syntax to file FILE.
+   CODE is a letter or dot (`z' in `%z0') or 0 if no letter was specified.
+   For `%' followed by punctuation, CODE is the punctuation and X is null. */
+#define PRINT_OPERAND(FILE, X, CODE)  		\
+{ if (CODE == '#') fprintf (FILE, "#");		\
+  else if (GET_CODE (X) == REG)			\
+    fprintf (FILE, "%s", reg_names[REGNO (X)]);	\
+  else if (GET_CODE (X) == MEM)			\
+    output_address (XEXP (X, 0));		\
+  else if (GET_CODE (X) == PC)			\
+    fprintf (FILE, "$");			\
+  else if (GET_CODE (X) == CONST_INT)		\
+    fprintf (FILE, ">%X", (unsigned short)(INTVAL(X) & 0xFFFF));	\
+  else output_addr_const (FILE, X);}
+
+/* Print a memory operand whose address is ADDR, on file FILE.  */
+#define PRINT_OPERAND_ADDRESS(FILE, ADDR) \
+   print_operand_address (FILE, ADDR)
+
+/* This is how to output an insn to push/pop a register on the stack.
+   It need not be very fast code.  
+
+   Don't define because we don't know how to handle that with
+   the STATIC_CHAIN_REGNUM (soft register).  Saving the static
+   chain must be made inside FUNCTION_PROFILER.  */
+#undef ASM_OUTPUT_REG_PUSH
+#undef ASM_OUTPUT_REG_POP
+
+/* This is how to output an element of a case-vector that is relative.  */
+#define ASM_OUTPUT_ADDR_DIFF_ELT(FILE, BODY, VALUE, REL) \
+  fprintf (FILE, "\t%s\tL%d-L%d\n", integer_asm_op (2, TRUE), VALUE, REL)
+
+/* This is how to output an element of a case-vector that is absolute.  */
+#define ASM_OUTPUT_ADDR_VEC_ELT(FILE, VALUE) \
+  fprintf (FILE, "\t%s\tL%d\n", integer_asm_op (2, TRUE), VALUE)
+
+/* Advance to the next word boundary */
+#undef ALIGN_ASM_OP
+#define ALIGN_ASM_OP "\teven\t"
+
+/* This is how to output an assembler line that says to advance the
+   location counter to a multiple of 2**LOG bytes.  */
+#define ASM_OUTPUT_ALIGN(FILE,LOG)      \
+  switch (LOG)                          \
+    {                                   \
+      case 0:                           \
+        break;                          \
+      case 1:                           \
+        fprintf (FILE, "\teven\n");     \
+        break;                          \
+      default:                          \
+        gcc_unreachable ();             \
+    }
+
+/* Assembler Commands for Exception Regions.  */
+
+/* Default values provided by GCC should be ok. Assuming that DWARF-2
+   frame unwind info is ok for this platform.  */
+#define DWARF2_DEBUGGING_INFO 1
+
+/* Prefer dwarf format for debugging info */
+#undef PREFERRED_DEBUGGING_TYPE
+#define PREFERRED_DEBUGGING_TYPE DWARF2_DEBUG
+
+/* Use 16-bit values for dwarf address pointers */
+#define DWARF2_ADDR_SIZE 2
+
+/* Enable support for source line debugging in emitted assembly code */
+#define HAVE_AS_DWARF2_DEBUG_LINE 1
+
+/* Only emit ".file" and ".loc" directives if debugging is enabled */
+#define DWARF2_ASM_LINE_DEBUG_INFO (write_symbols != NO_DEBUG)
+
+/* This flag is true if the target supports `TARGET_ASM_NAMED_SECTION'. */
+#define TARGET_HAVE_NAMED_SECTIONS 1
+
+/* Output assembly directives to switch to section NAME.  The section
+   should have attributes as specified by FLAGS, which is a bit mask
+   of the `SECTION_*' flags defined in `output.h'.  If ALIGN is
+   nonzero, it contains an alignment in bytes to be used for the
+   section, otherwise some target default should be used.  Only
+   targets that must specify an alignment within the section
+   directive need pay attention to ALIGN - we will still use
+   `ASM_OUTPUT_ALIGN'. */
+#define TARGET_ASM_NAMED_SECTION  default_elf_asm_named_section
+
+/* The prefix for local labels.  You should be able to define this as
+   an empty string, or any arbitrary string (such as ".", ".L%", etc)
+   without having to make any other changes to account for the specific
+   definition.  Note it is a string literal, not interpreted by printf
+   and friends.  */
+/*#define LOCAL_LABEL_PREFIX "."*/
+
+/* Directive to give a symbol global scope */
+#define GLOBAL_ASM_OP   "\n\tdef\t"
+
+/* Miscellaneous Parameters.  */
+
+/* Specify the machine mode that this machine uses
+   for the index in the tablejump instruction.  */
+#define CASE_VECTOR_MODE	Pmode
+
+/* This flag, if defined, says the same insns that convert to a signed fixnum
+   also convert validly to an unsigned one.  */
+#define FIXUNS_TRUNC_LIKE_FIX_TRUNC
+
+/* Max number of bytes we can move from memory to memory in one
+   reasonably fast instruction.  */
+#define MOVE_MAX 		2
+
+/* MOVE_RATIO is the number of move instructions that is better than a
+   block move.  Make this small, since the code size grows very
+   large with each move.  */
+#define MOVE_RATIO(speed)	3
+
+/* Define if shifts truncate the shift count which implies one can omit
+   a sign-extension or zero-extension of a shift count.  */
+#define SHIFT_COUNT_TRUNCATED	1
+
+/* Value is 1 if truncating an integer of INPREC bits to OUTPREC bits
+   is done just by pretending it is already truncated.  */
+#define TRULY_NOOP_TRUNCATION(OUTPREC, INPREC)	0
+
+/* Specify the machine mode that pointers have. After generation of rtl, the
+   compiler makes no further distinction between pointers and any other
+   objects of this machine mode.  */
+#define Pmode			HImode
+
+/* An alias for the machine mode used for memory references to
+   functions being called, in `call' RTL expressions.  On most CISC
+   machines, where an instruction can begin at any byte address, this
+   should be `QImode'.  On most RISC machines, where all instructions
+   have fixed size and alignment, this should be a mode with the same
+   size and alignment as the machine instruction words - typically
+   `SImode' or `HImode'. */
+#define FUNCTION_MODE		HImode
+
+/* A C statement (sans semicolon) to output a reference to
+   `SYMBOL_REF' SYM.  If not defined, `assemble_name' will be used to
+   output the name of the symbol.  This macro may be used to modify
+   the way a symbol is referenced depending on information encoded by
+   `TARGET_ENCODE_SECTION_INFO'. */
+#define ASM_GENERATE_INTERNAL_LABEL(STRING, PREFIX, NUM) \
+  sprintf (STRING, "*%s%ld", PREFIX, (long)(NUM))
+
+/* A C statement to output to the stdio stream STREAM an assembler
+   instruction to advance the location counter by NBYTES bytes.
+   Those bytes should be zero when loaded.  NBYTES will be a C
+   expression of type `unsigned HOST_WIDE_INT'. */
+#define ASM_OUTPUT_SKIP(STREAM, NBYTES) \
+   fprintf(STREAM, "\tbss %lu\n", NBYTES);
+
+/* A C statement (sans semicolon) to output to the stdio stream
+   STREAM the assembler definition of uninitialized global DECL named
+   NAME whose size is SIZE bytes.  The variable ROUNDED is the size
+   rounded up to whatever alignment the caller wants. */
+#define ASM_OUTPUT_ALIGNED_BSS(STREAM, DECL, NAME, SIZE, ALIGNMENT)     \
+  if(ALIGNMENT > 1) fprintf ((STREAM), "\n\teven\n");                   \
+  asm_output_aligned_bss ((STREAM), (DECL), (NAME), (SIZE), (ALIGNMENT));
+
+/* A C statement (sans semicolon) to output to the stdio stream
+   STREAM the assembler definition of a common-label named NAME whose
+   size is SIZE bytes.  The variable ROUNDED is the size rounded up
+   to whatever alignment the caller wants. */
+#define ASM_OUTPUT_ALIGNED_COMMON(STREAM, NAME, SIZE, ALIGNMENT)           \
+do {                                                                       \
+     switch_to_section (bss_section);                                      \
+     if(ALIGNMENT > 1) fprintf ((STREAM), "\n\teven");                     \
+     fprintf ((STREAM), "\n\tdef %s\n", (NAME));                           \
+     assemble_name ((STREAM), (NAME));                                     \
+     fprintf ((STREAM), "\n\tbss %u\n", (int)(SIZE));                      \
+} while (0)
+
+/* A C statement (sans semicolon) to output to the stdio stream
+   STREAM the assembler definition of a local-common-label named NAME
+   whose size is SIZE bytes.  The variable ROUNDED is the size
+   rounded up to whatever alignment the caller wants. */
+#define ASM_OUTPUT_ALIGNED_LOCAL(STREAM, NAME, SIZE, ALIGNMENT)            \
+do {                                                                       \
+     switch_to_section (bss_section);                                      \
+     if(ALIGNMENT > 1) fprintf ((STREAM), "\n\teven\n");                   \
+     assemble_name ((STREAM), (NAME));                                     \
+     fprintf ((STREAM), "\n\tbss %u\n", (int)(SIZE));                      \
+} while (0)
+
+/* A C statement to output to the stdio stream STREAM an assembler
+   instruction to assemble a string constant containing the LEN bytes
+   at PTR.  PTR will be a C expression of type `char *' and LEN a C
+   expression of type `int'. */
+#define ASM_OUTPUT_ASCII(STREAM, PTR, LEN) \
+   tms9900_output_ascii(STREAM, PTR, LEN)
+
+#define ASM_OUTPUT_DWARF_DELTA(FILE,SIZE,LABEL1,LABEL2)  \
+   tms9900_asm_output_dwarf_delta (FILE, SIZE, LABEL1, LABEL2)
+
+#define ASM_OUTPUT_DWARF_OFFSET(FILE,SIZE,LABEL,BASE)  \
+   tms9900_asm_output_dwarf_offset (FILE, SIZE, LABEL, BASE)
+
+/* Put references to global constructors in a .init section. The crt0 code
+   will invoke these constructors at startup, before calling main. */
+#define INIT_SECTION_ASM_OP
+
+#undef  SIZE_ASM_OP
+#undef  TYPE_ASM_OP
+#define SIZE_ASM_OP     "\t.size\t"
+#define TYPE_ASM_OP     "\t.type\t"
+
+#undef TYPE_OPERAND_FMT
+#define TYPE_OPERAND_FMT        "@%s"
+
+#define ASM_DECLARE_FUNCTION_SIZE(FILE, FNAME, DECL)                    \
+  do {                                                                  \
+     if (!flag_inhibit_size_directive)                                  \
+      ASM_OUTPUT_MEASURED_SIZE (FILE, FNAME);                           \
+  } while (0)
+
+#define ASM_DECLARE_OBJECT_NAME(FILE, NAME, DECL)                       \
+do {                                                                    \
+  ASM_OUTPUT_TYPE_DIRECTIVE (FILE, NAME, "object");                     \
+  size_directive_output = 0;                                            \
+  if (!flag_inhibit_size_directive && DECL_SIZE (DECL))                 \
+    {                                                                   \
+      size_directive_output = 1;                                        \
+      ASM_OUTPUT_SIZE_DIRECTIVE (FILE, NAME,                            \
+                                 int_size_in_bytes (TREE_TYPE (DECL))); \
+    }                                                                   \
+  ASM_OUTPUT_LABEL(FILE, NAME);                                         \
+} while (0)
+
+
+#undef ASM_FINISH_DECLARE_OBJECT
+#define ASM_FINISH_DECLARE_OBJECT(FILE, DECL, TOP_LEVEL, AT_END)        \
+  do {                                                                  \
+    const char *name = XSTR (XEXP (DECL_RTL (DECL), 0), 0);             \
+    HOST_WIDE_INT size;                                                 \
+    if (!flag_inhibit_size_directive                                    \
+        && DECL_SIZE (DECL)                                             \
+        && ! AT_END && TOP_LEVEL                                        \
+        && DECL_INITIAL (DECL) == error_mark_node                       \
+        && !size_directive_output                                       \
+        && (size = int_size_in_bytes (TREE_TYPE (DECL))) > 0)           \
+      {                                                                 \
+        size_directive_output = 1;                                      \
+        ASM_OUTPUT_SIZE_DIRECTIVE (FILE, name, size);                   \
+      }                                                                 \
+  } while (0)
+
+
+#ifdef FILE
+void tms9900_asm_output_dwarf_delta (FILE *file, int size,
+                               const char *lab1, const char *lab2);
+#endif
+
diff -ru gcc-orig/gcc/config/tms9900/tms9900.md gcc-4.4.0/gcc/config/tms9900/tms9900.md
--- gcc-orig/gcc/config/tms9900/tms9900.md	2023-11-09 19:22:23.903473031 +0000
+++ gcc-4.4.0/gcc/config/tms9900/tms9900.md	2023-11-09 19:08:05.302198885 +0000
@@ -0,0 +1,2954 @@
+;; This file is part of GCC.
+
+;; GCC is free software; you can redistribute it and/or modify
+;; it under the terms of the GNU General Public License as published by
+;; the Free Software Foundation; either version 3, or (at your option)
+;; any later version.
+
+;; GCC is distributed in the hope that it will be useful,
+;; but WITHOUT ANY WARRANTY; without even the implied warranty of
+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+;; GNU General Public License for more details.
+
+;; You should have received a copy of the GNU General Public License
+;; along with GCC; see the file COPYING3.  If not see
+;; <http://www.gnu.org/licenses/>.
+
+;; SI is 32 bit
+;; HI is 16 bit
+;; QI is 8 bit 
+
+;; Description of class IDs
+;;   'C  is for CRU register
+;;   'I' is for 32-bit value xxxx0000
+;;   'J' is for 32-bit value 0000xxxx
+;;   'K' is for 32-bit value xxxxxxxx
+;;   'L' is for 2 or -2
+;;   'M' is for -1
+;;   'N' is for 1
+;;   'O' is for 0
+;;   'P' is for 00FF
+;;   'Q' is for memory references that need an extra word after the opcode.
+;;   'R' is for memory references which are encoded within the opcode.
+;;   'S' is for shift register
+;;   'T' Class of all registers
+;;    U?
+;;    W?
+
+;;- See file "rtl.def" for documentation on define_insn, match_*, et. al.
+
+;;- cpp macro #define NOTICE_UPDATE_CC in file tm.h handles condition code
+;;- updates for most instructions.
+
+;;- Operand classes for the register allocator:
+
+;; Compare instructions.
+
+
+;; define attributes
+;; currently type is only fpu or arith or unknown, maybe branch later ?
+;; default is arith
+(define_attr "type" "unknown,arith,fp" (const_string "arith"))
+
+;; length default is 1 word each
+(define_attr "length" "" (const_int 1))
+
+;; a user's asm statement
+(define_asm_attributes
+  [(set_attr "type" "unknown")
+; all bets are off how long it is - make it 256, forces long jumps 
+; whenever jumping around it !!!
+   (set_attr "length" "256")])
+
+;;-------------------------------------------------------------------
+;;  UNSPEC Definitions
+;;-------------------------------------------------------------------
+(define_constants
+  [(UNSPEC_RETURN  0)])
+
+
+;;-------------------------------------------------------------------
+;;  Predicate Definitions
+;;-------------------------------------------------------------------
+
+(define_predicate "shift_count_operand"
+  (ior (match_code "const_int")
+       (match_code "reg")))
+
+
+;;-------------------------------------------------------------------
+;;  Function Calls
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------------------------------------
+;; Jump to a subroutine which returns a value
+(define_insn "call"
+  [(call (match_operand:HI 0 "general_operand" "rR,Q")
+         (match_operand:HI 1 "general_operand" "g,g"))
+  ]
+  ""
+  {
+    if(SIBLING_CALL_P(insn))
+      output_asm_insn("b    %0", operands);
+    else
+      output_asm_insn("bl   %0", operands);
+    return("");
+  }
+  [(set_attr "length" "2,4")]
+)
+
+
+;-------------------------------------------------------------------
+; Jump to a subroutine which returns a value
+(define_insn "call_value"
+  [(set (match_operand 0 "" "")
+        (call (match_operand:HI 1 "general_operand" "rR,Q")
+	      (match_operand:HI 2 "general_operand" "g,g")))
+  ]
+  ""
+  {
+    if(SIBLING_CALL_P(insn))
+      output_asm_insn("b    %1", operands);
+    else
+      output_asm_insn("bl   %1", operands);
+    return("");
+  }
+  [(set_attr "length" "2,4")]
+)
+
+
+;;-------------------------------------------------------------------
+;; Define function prologue
+(define_expand "prologue"
+  [(const_int 0)]
+  ""
+{
+  tms9900_expand_prologue();
+  DONE;
+})
+
+
+;;-------------------------------------------------------------------
+;; Define function epilogue
+(define_expand "epilogue"
+  [(return)]
+  ""
+{
+  tms9900_expand_epilogue(false);
+  DONE;
+})
+
+(define_expand "sibcall_epilogue"
+  [(return)]
+  ""
+{
+  tms9900_expand_epilogue(true);
+  DONE;
+})
+
+
+;;-------------------------------------------------------------------
+;; Define function return
+(define_insn "*rt"
+  [(unspec [(match_operand:HI 0 "general_operand" "")] UNSPEC_RETURN)]
+  ""
+  "b    *r11"
+  [(set_attr "length" "2")])
+
+
+;;-------------------------------------------------------------------
+;;  Comparison Instructions
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------
+(define_insn "tsthi"
+  [(set (cc0)
+	(match_operand:HI 0 "register_operand" "r"))]
+  ""
+  {
+    return("ci   %0, 0");
+  }
+  [(set_attr "length" "4")])
+
+
+;;-------------------------------------
+; TODO temporarily removed.  Causes a compiler assert
+;;-------------------------------------
+; (define_insn "tstqi"
+;   [(set (cc0)
+; 	(match_operand:QI 0 "nonimmediate_operand" "rR,Q"))]
+;   ""
+;   {
+;     output_asm_insn("jeq  0",       operands);  /* +0: No-op instruction with zero at +1 */
+;     output_asm_insn("cb  %0, @$-1", operands);  /* +2: Compare value against the zero at +1 */
+;     return("");
+;   }
+;   [(set_attr "length" "4,6")])
+
+
+;;-------------------------------------
+(define_insn "cmphi"
+  [(set (cc0)
+	(compare (match_operand:HI 0 "nonimmediate_operand" "rR,rR,Q,Q,r")
+		 (match_operand:HI 1 "general_operand" "rR,Q,rR,Q,i")))]
+  ""
+  {
+    if (which_alternative == 4)
+    {
+       return("ci   %0, %1");
+    }
+    return("c    %0, %1");
+  }
+  [(set_attr "length" "2,4,4,6,4")])
+
+
+;;-------------------------------------
+(define_insn "cmpqi"
+  [(set (cc0)
+	(compare (match_operand:QI 0 "nonimmediate_operand" "rR,rR,Q,Q")
+		 (match_operand:QI 1 "nonimmediate_operand" "rR,Q,rR,Q")))]
+  ""
+  "cb   %0, %1"
+  [(set_attr "length" "2,4,4,6")])
+
+
+;;-------------------------------------------------------------------
+;;  Branch Instructions
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------------------------------------
+;; Jump if equal
+(define_insn "beq"
+  [(set (pc)
+	(if_then_else (eq (cc0)
+			  (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+  {
+    return(output_branch("jeq", "jne", get_attr_length(insn)));
+  }
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------
+;; Jump if equal, reversed comparison operands
+(define_insn "*beq_reversed"
+  [(set (pc)
+	(if_then_else (eq (cc0)
+			  (const_int 0))
+		      (pc)
+		      (label_ref (match_operand 0 "" ""))))]
+  ""
+  {
+    return(output_branch("jne", "jeq", get_attr_length(insn)));
+  }
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------------------------------------
+;; Jump if not equal
+(define_insn "bne"
+  [(set (pc)
+	(if_then_else (ne (cc0)
+			  (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+  "* return output_branch(\"jne\", \"jeq\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------
+;; Jump if not equal, reversed comparison operands
+(define_insn "*bne_reversed"
+  [(set (pc)
+	(if_then_else (ne (cc0)
+			  (const_int 0))
+		      (pc)
+		      (label_ref (match_operand 0 "" ""))))]
+  ""
+  "* return output_branch(\"jeq\", \"jne\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------------------------------------
+;; Jump if unsigned less than
+(define_insn "bltu"
+  [(set (pc)
+	(if_then_else (ltu (cc0)
+			   (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+  "* return output_branch(\"jl\", \"jhe\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------
+;; Jump if unsigned less than, reversed comparison operands
+(define_insn "*bltu_reversed"
+  [(set (pc)
+	(if_then_else (ltu (cc0)
+			   (const_int 0))
+		      (pc)
+		      (label_ref (match_operand 0 "" ""))))]
+  ""
+  "* return output_branch(\"jhe\", \"jl\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------------------------------------
+;; Jump if unsigned less than or equal
+(define_insn "bleu"
+  [(set (pc)
+	(if_then_else (leu (cc0)
+			   (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+  "* return output_branch(\"jle\", \"jh\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------
+;; Jump if unsigned less than or equal, reversed comparison operands
+(define_insn "*bleu_reversed"
+  [(set (pc)
+	(if_then_else (leu (cc0)
+			   (const_int 0))
+		      (pc)
+		      (label_ref (match_operand 0 "" ""))))]
+  ""
+  "* return output_branch(\"jh\", \"jle\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------------------------------------
+;; Jump if unsigned greater than
+(define_insn "bgtu"
+  [(set (pc)
+	(if_then_else (gtu (cc0)
+			   (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+  "* return output_branch(\"jh\", \"jle\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------
+;; Jump if unsigned greater than, reversed comparison operands
+(define_insn "*bgtu_reversed"
+  [(set (pc)
+	(if_then_else (gtu (cc0)
+			   (const_int 0))
+		      (pc)
+		      (label_ref (match_operand 0 "" ""))))]
+  ""
+  "* return output_branch(\"jle\", \"jh\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------------------------------------
+;; Jump if unsigned greater than or equal
+(define_insn "bgeu"
+  [(set (pc)
+	(if_then_else (geu (cc0)
+			   (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+  "* return output_branch(\"jhe\", \"jl\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------
+;; Jump if unsigned greater than or equal, reversed comparison operands
+(define_insn "*bgeu_reversed"
+  [(set (pc)
+	(if_then_else (geu (cc0)
+			   (const_int 0))
+		      (pc)
+		      (label_ref (match_operand 0 "" ""))))]
+  ""
+  "* return output_branch(\"jl\", \"jhe\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 12)))])
+
+
+;;-------------------------------------------------------------------
+;; Jump if less than
+(define_insn "blt"
+  [(set (pc)
+	(if_then_else (lt (cc0)
+			  (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+  "* return output_branch(\"jlt\", \"GE\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 18)
+				      (const_int 12)))])
+
+
+;;-------------------------------------
+;; Jump if less than, reversed comparison operands
+; Was commented out
+(define_insn "*blt_reversed"
+  [(set (pc)
+	(if_then_else (lt (cc0)
+			  (const_int 0))
+		      (pc)
+		      (label_ref (match_operand 0 "" ""))))]
+  ""
+  "* return output_branch(\"GE\", \"jlt\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 14)))])
+
+
+;;-------------------------------------------------------------------
+;; Jump if less than or equal
+(define_insn "ble"
+  [(set (pc)
+	(if_then_else (le (cc0)
+			  (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+  "* return output_branch(\"LE\", \"jgt\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 14)))])
+
+
+;;-------------------------------------
+;; Jump if less than or equal, reversed comparison operands
+(define_insn "*ble_reversed"
+  [(set (pc)
+	(if_then_else (le (cc0)
+			  (const_int 0))
+		      (pc)
+		      (label_ref (match_operand 0 "" ""))))]
+  ""
+  "* return output_branch(\"jgt\", \"LE\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 18)
+				      (const_int 12)))])
+
+
+;;-------------------------------------------------------------------
+;; Jump if greater than
+(define_insn "bgt"
+  [(set (pc)
+	(if_then_else (gt (cc0)
+			  (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+  "* return output_branch(\"jgt\", \"LE\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 18)
+				      (const_int 12)))])
+
+
+;;-------------------------------------
+;; Jump if greater than, reversed comparison operands
+; Was commented out
+(define_insn "*bgt_reversed"
+  [(set (pc)
+	(if_then_else (gt (cc0)
+			  (const_int 0))
+		      (pc)
+		      (label_ref (match_operand 0 "" ""))))]
+  ""
+  "* return output_branch(\"LE\", \"jgt\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 14)))])
+
+
+;;-------------------------------------------------------------------
+;; Jump if greater than or equal
+; Was commented out
+(define_insn "bge"
+  [(set (pc)
+	(if_then_else (ge (cc0)
+			  (const_int 0))
+		      (label_ref (match_operand 0 "" ""))
+		      (pc)))]
+  ""
+  "* return output_branch(\"GE\", \"jlt\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 16)
+				      (const_int 14)))])
+
+
+;;-------------------------------------
+;; Jump if greater than or equal, reversed comparison operands
+(define_insn "*bge_reversed"
+  [(set (pc)
+	(if_then_else (ge (cc0)
+			  (const_int 0))
+		      (pc)
+		      (label_ref (match_operand 0 "" ""))))]
+  ""
+  "* return output_branch(\"jlt\", \"GE\", get_attr_length(insn));"
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 18)
+				      (const_int 12)))])
+
+
+;;-------------------------------------------------------------------
+;;  Jump Operations
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------------------------------------
+;; Unconditional jump to label
+(define_insn "jump"
+  [(set (pc)
+	(label_ref (match_operand 0 "" "")))]
+  ""
+  "*
+  return output_jump(get_attr_length(insn));"
+
+  [(set (attr "length") (if_then_else (ior (le (minus (match_dup 0)
+						      (pc))
+					       (const_int -252))
+					   (ge (minus (match_dup 0)
+						      (pc))
+					       (const_int 256)))
+				      (const_int 14)
+				      (const_int 12)))])
+
+
+;;-------------------------------------------------------------------
+;; Unconditional jump using pointer
+(define_insn "indirect_jump"
+  [(set (pc) (match_operand:HI 0 "nonimmediate_operand" "r,Q"))]
+  ""
+  "b    %0"
+  [(set_attr "length" "2,4")])
+
+
+;;-------------------------------------------------------------------
+;; Unconditional jump using jump table
+(define_insn "tablejump"
+  [(clobber (match_scratch:HI 2 "=r,r"))
+   (set (pc) (match_operand:HI 0 "nonimmediate_operand" "rR,Q"))
+   (use (label_ref (match_operand 1 "" "")))]
+  ""
+  {
+    output_asm_insn("mov  %0, %2", operands);
+    output_asm_insn("b    *%2",    operands);
+    return(""); 
+  }
+  [(set_attr "length" "4,6")])
+
+
+;;-------------------------------------------------------------------
+;;  Bit Shift Operations
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------------------------------------
+;; Arithmetic shift left
+
+
+;;-------------------------------------
+(define_insn "ashlsi3"
+  [(set (match_operand:SI 0 "register_operand" "=r,r")
+	(ashift:SI (match_operand:SI 1 "register_operand" "0,0")
+		   (match_operand:HI 2 "shift_count_operand" "S,i")))
+   (clobber (match_scratch:HI 3 "=&r,&r"))]
+     ""
+  {
+    rtx ops[7];
+    ops[0] = operands[0];  /* Destination */
+    ops[1] = operands[1];  /* Source */
+    ops[2] = operands[2];  /* Shift count */
+    ops[3] = operands[3];  /* Scratch reg */
+    ops[4] = gen_rtx_REG (HImode, REGNO (operands[0]) + REGS_PER_WORD);  /* Low word of source */
+    if(which_alternative == 0)
+    {
+      /* Variable shift */
+      output_asm_insn("ci   %2, 16",  ops);  /* +0: Compare shift to 16 */
+      output_asm_insn("jlt  $+12",    ops);  /* +4: If shift was < 16, goto lt_16 */
+      output_asm_insn("jeq  $+4",     ops);  /* +6: If shift was 16, goto eq_16 */
+     
+      /* Shift count greater than 16 */
+      output_asm_insn("sla  %4, %2",  ops);  /* +8: Shift low word */
+
+      /* eq_16: Shift count equals 16 */
+      output_asm_insn("mov  %4, %1",  ops);  /* +10: Copy low word to high word */ 
+      output_asm_insn("clr  %4",      ops);  /* +12: Clear low word */
+      output_asm_insn("jmp  $+20",    ops);  /* +14: Goto end */
+
+      /* lt_16: Shift count less than 16 */
+      output_asm_insn("abs  %2",      ops);  /* +16: Test shift count */
+      output_asm_insn("jeq  $+16",    ops);  /* +18: If shift==0, goto end */
+      output_asm_insn("mov  %4, %3",  ops);  /* +20: Save low word to temp */
+      output_asm_insn("sla  %1, %2",  ops);  /* +22: Shift high word */
+      output_asm_insn("sla  %4, %2",  ops);  /* +24: Shift low word */
+      output_asm_insn("neg  %2",      ops);  /* +26: Get complement of shift count */
+      output_asm_insn("srl  %3, %2",  ops);  /* +28: Shift low word bits into high word position */
+      output_asm_insn("soc  %3, %1",  ops);  /* +30: Merge shifted low word bits into high word */
+      output_asm_insn("neg  %2",      ops);  /* +32: Restore shift count */
+      /* +34: End */
+    }
+    else
+    {
+      /* Constant shift */
+      int offset = INTVAL(operands[2]);
+      ops[5] = GEN_INT(16-offset);  /* Complement of shift count */
+      ops[6] = GEN_INT(offset%16);  /* Modulo of shift count */
+  
+      if(offset < 16)
+      {
+        if(offset == 8)
+        {
+          output_asm_insn("movb %4, %1",  ops);  /* Move MSB of high word */
+          output_asm_insn("sb   %4, %4",  ops);  /* Clear MSB of high word */
+          output_asm_insn("swpb %1",      ops);  /* Swap bytes in low word */
+          output_asm_insn("swpb %4",      ops);  /* Swap bytes in high word */
+        }
+        else
+        {
+          output_asm_insn("mov  %4, %3", ops);  /* Save low word to temp */
+          output_asm_insn("sla  %1, %2", ops);  /* Shift high word */
+          output_asm_insn("sla  %4, %2", ops);  /* Shift low word */
+          output_asm_insn("srl  %3, %5", ops);  /* Shift low word bits into high word position */
+          output_asm_insn("soc  %3, %1", ops);  /* Merge low word bits into high word */
+        }
+      } 
+      else
+      {
+        if(offset > 16)
+        {
+          output_asm_insn("sla  %4, %6", ops);  /* Shift low word */
+        }
+        output_asm_insn("mov  %4, %1", ops);  /* Move low word into high word */
+        output_asm_insn("clr  %4",     ops);  /* Clear low word */
+      }
+    }
+    return "";
+  }
+  [(set_attr "length" "34, 10")]
+)
+
+
+;;-------------------------------------
+(define_insn "ashlhi3"
+  [(set (match_operand:HI 0 "register_operand" "=r,r")
+	(ashift:HI (match_operand:HI 1 "register_operand" "0,0")
+		   (match_operand:HI 2 "shift_count_operand" "S,i")))]
+  ""
+  {
+    if(which_alternative == 0)
+    {
+      output_asm_insn("abs  r0",     operands);
+      output_asm_insn("jeq  $+4",    operands);
+      output_asm_insn("sla  %0, 0",  operands);
+    }
+    else if(INTVAL(operands[2]) > 0)
+    {
+      output_asm_insn("sla  %0, %2", operands);
+    }
+    return(""); 
+  }
+  [(set_attr "length" "6,2")])
+
+
+;;-------------------------------------
+(define_insn "ashlqi3"
+  [(set (match_operand:QI 0 "register_operand" "=r,r")
+	(ashift:QI (match_operand:QI 1 "register_operand" "0,0")
+		   (match_operand:HI 2 "shift_count_operand" "S,i")))]
+  ""
+  {
+    if(which_alternative == 0)
+    {
+      output_asm_insn("abs  r0",        operands);
+      output_asm_insn("jeq  $+8",       operands);  /* If shift count is zero, do nothing */
+      output_asm_insn("andi %0, >FF00", operands);
+      output_asm_insn("sla  %0, 0",     operands);
+    }
+    else if(INTVAL(operands[2]) > 0)
+    {
+      output_asm_insn("andi %0, >FF00", operands);
+      output_asm_insn("sla  %0, %2",    operands);
+    }
+    return(""); 
+  }
+  [(set_attr "length" "10,6")])
+
+
+;;-------------------------------------------------------------------
+;; Arithmetic shift left (for QI mode)
+
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "=r,r")
+	(sign_extend:HI(match_operand:QI 1 "register_operand" "r,r")))
+   (set (match_operand:HI 2 "register_operand" "=r,r")
+	(ashift:HI (match_dup 0)
+                   (plus:HI (match_operand:HI 3 "const_int_operand" "i,i")
+                            (match_operand:HI 4 "const_int_operand" "i,i"))))]
+  ""
+  [(set (match_dup 2)
+        (match_dup 1))
+   (set (match_dup 2)
+        (ashift:QI (match_dup 2)
+                   (match_dup 3)))]
+  "")
+
+
+;;-------------------------------------------------------------------
+;; Arithmetic shift right
+
+(define_insn "ashrsi3"
+  [(set (match_operand:SI 0 "register_operand" "=r,r")
+	(ashiftrt:SI (match_operand:SI 1 "register_operand" "0,0")
+		     (match_operand:HI 2 "shift_count_operand" "S,i")))
+   (clobber (match_scratch:HI 3 "=&r,&r"))]
+     ""
+  {
+    rtx ops[7];
+    ops[0] = operands[0];  /* Destination */
+    ops[1] = operands[1];  /* Source */
+    ops[2] = operands[2];  /* Shift count */
+    ops[3] = operands[3];  /* Scratch reg */
+    ops[4] = gen_rtx_REG (HImode, REGNO (operands[0]) + REGS_PER_WORD);  /* Low word of source */
+    if(which_alternative == 0)
+    {
+      /* Variable shift */
+      output_asm_insn("ci   %2, 16",  ops);  /* +0: Compare shift to 16 */
+      output_asm_insn("jlt  $+16",    ops);  /* +4: If shift was < 16, goto lt_16 */
+      output_asm_insn("jeq  $+4",     ops);  /* +6: If shift was 16, goto eq_16 */
+
+      /* Shift count greater than 16 */
+      output_asm_insn("sra  %1, %2",  ops);  /* +8: Shift high word */
+
+      /* eq_16: Shift count equals 16 */
+      output_asm_insn("mov  %1, %4",  ops);  /* +10: Copy high word to low word */ 
+      output_asm_insn("seto %1",      ops);  /* +12: Assume negative value, set high word */
+      output_asm_insn("jlt  $+4",     ops);  /* +14: If value was negative, skip next instruction */
+      output_asm_insn("clr  %1",      ops);  /* +16: Clear high word */
+      output_asm_insn("jmp  $+20",    ops);  /* +18: Goto end */
+
+      /* lt_16: Shift count less than 16 */
+      output_asm_insn("abs  %2",      ops);  /* +20: Test shift count */
+      output_asm_insn("jeq  $+16",    ops);  /* +22: If shift==0, goto end */
+      output_asm_insn("mov  %4, %3",  ops);  /* +24: Save high word to temp */
+      output_asm_insn("sra  %1, %2",  ops);  /* +26: Shift high word */
+      output_asm_insn("srl  %4, %2",  ops);  /* +28: Shift low word */
+      output_asm_insn("neg  %2",      ops);  /* +30: Get complement of shift count */
+      output_asm_insn("sla  %3, %2",  ops);  /* +32: Shift high word bits into low word position */
+      output_asm_insn("soc  %3, %4",  ops);  /* +34: Merge shifted high word bits into low word */
+      output_asm_insn("neg  %2",      ops);  /* +36: Restore shift count */
+      /* +38: End */
+    }
+    else
+    {
+      /* Constant shift */
+      int offset = INTVAL(operands[2]);
+      ops[5] = GEN_INT(16-offset);  /* Complement of shift count */
+      ops[6] = GEN_INT(offset%16);  /* Modulo of shift count */
+  
+      if(offset < 16)
+      {
+        output_asm_insn("mov  %1, %3",  ops);  /* Save high word to temp */
+        output_asm_insn("sra  %1, %6",  ops);  /* Shift high word */
+        output_asm_insn("srl  %4, %6",  ops);  /* Shift low word */
+        output_asm_insn("sla  %3, %5",  ops);  /* Shift high word bits into low word position */
+        output_asm_insn("soc  %3, %4",  ops);  /* Merge shifted high word bits into low word */
+      } 
+      else
+      {
+        if(offset > 16)
+        {
+          output_asm_insn("sra  %1, %6", ops);  /* Shift high word */
+        }
+        output_asm_insn("mov  %1, %4",  ops);  /* Copy high word to low word */ 
+        output_asm_insn("seto %1",      ops);  /* Assume negative value, set high word */
+        output_asm_insn("jlt  $+4",     ops);  /* If value was negative, skip next instruction */
+        output_asm_insn("clr  %1",      ops);  /* Clear high word */
+      }
+    }
+    return "";
+  }
+  [(set_attr "length" "38, 10")]
+)
+
+
+;;-------------------------------------
+(define_insn "ashrhi3"
+  [(set (match_operand:HI 0 "register_operand" "=r,r")
+	(ashiftrt:HI (match_operand:HI 1 "register_operand" "0,0")
+		     (match_operand:HI 2 "shift_count_operand" "S,i")))]
+  ""
+  {
+    if(which_alternative == 0)
+    {
+      output_asm_insn("abs  r0",     operands);
+      output_asm_insn("jeq  $+4",    operands);
+      output_asm_insn("sra  %0, 0",  operands);
+    }
+    else if(INTVAL(operands[2]) > 0)
+    {
+      output_asm_insn("sra  %0, %2", operands);
+    }
+    return(""); 
+  }
+  [(set_attr "length" "6,2")])
+
+
+;;-------------------------------------
+(define_insn "ashrqi3"
+  [(set (match_operand:QI 0 "register_operand" "=r,r")
+	(ashiftrt:QI (match_operand:QI 1 "register_operand" "0,0")
+		     (match_operand:HI 2 "shift_count_operand" "S,i")))]
+  ""
+  {
+    if(which_alternative == 0)
+    {
+      output_asm_insn("abs  r0",        operands);
+      output_asm_insn("jeq  $+4",       operands);
+      output_asm_insn("sra  %0, 0",     operands);
+    }
+    else if(INTVAL(operands[2]) > 0)
+    {
+      output_asm_insn("sra  %0, %2",    operands);
+    }
+    return(""); 
+  }
+  [(set_attr "length" "6,2")])
+
+
+;;-------------------------------------
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "r,r")
+	(sign_extend:HI(match_operand:QI 1 "register_operand" "r,r")))
+   (set (match_operand:HI 3 "register_operand" "r,r")
+	(ashiftrt:HI (match_operand:HI 4 "register_operand" "0,0")
+		     (match_operand:HI 5 "shift_count_operand" "S,i")))
+   (set (match_operand:QI 6 "register_operand" "r,r")
+        (subreg:QI (match_operand:HI 7 "register_operand" "3,3") 1))]
+  ""
+  [(set (match_dup 6)
+        (match_dup 1))
+   (set (match_dup 6)
+        (ashiftrt:QI (match_dup 6)
+                     (match_dup 5)))]
+  "")
+
+
+;;-------------------------------------------------------------------
+;; Logical shift right
+
+
+;;-------------------------------------
+(define_insn "lshrsi3"
+  [(set (match_operand:SI 0 "register_operand" "=r,r")
+	(lshiftrt:SI (match_operand:SI 1 "register_operand" "0,0")
+		     (match_operand:HI 2 "shift_count_operand" "S,i")))
+   (clobber (match_scratch:HI 3 "=&r,&r"))]
+     ""
+  {
+    rtx ops[7];
+    ops[0] = operands[0];  /* Destination */
+    ops[1] = operands[1];  /* Source */
+    ops[2] = operands[2];  /* Shift count */
+    ops[3] = operands[3];  /* Scratch reg */
+    ops[4] = gen_rtx_REG (HImode, REGNO (operands[0]) + REGS_PER_WORD);  /* Low word of source */
+    if(which_alternative == 0)
+    {
+      /* Variable shift */
+      output_asm_insn("ci   %2, 16",  ops);  /* +0: Compare shift to 16 */
+      output_asm_insn("jlt  $+12",    ops);  /* +4: If shift was < 16, goto lt_16 */
+      output_asm_insn("jeq  $+4",     ops);  /* +6: If shift was 16, goto eq_16 */
+
+      /* Shift count greater than 16 */
+      output_asm_insn("srl  %1, %2",  ops);  /* +8: Shift high word */
+
+      /* eq_16: Shift count equals 16 */
+      output_asm_insn("mov  %1, %4",  ops);  /* +10: Copy high word to low word */ 
+      output_asm_insn("clr  %1",      ops);  /* +12: Clear high word */
+      output_asm_insn("jmp  $+20",    ops);  /* +14: Goto end */
+
+      /* lt_16: Shift count less than 16 */
+      output_asm_insn("abs  %2",      ops);  /* +16: Test shift count */
+      output_asm_insn("jeq  $+16",    ops);  /* +18: If shift==0, goto end */
+      output_asm_insn("mov  %1, %3",  ops);  /* +20: Save high word to temp */
+      output_asm_insn("srl  %1, %2",  ops);  /* +22: Shift high word */
+      output_asm_insn("srl  %4, %2",  ops);  /* +24: Shift low word */
+      output_asm_insn("neg  %2",      ops);  /* +26: Get complement of shift count */
+      output_asm_insn("sla  %3, %2",  ops);  /* +28: Shift high word bits into low word position */
+      output_asm_insn("soc  %3, %4",  ops);  /* +30: Merge shifted high word bits into low word */
+      output_asm_insn("neg  %2",      ops);  /* +32: Restore shift count */
+      /* +34: End */
+    }
+    else
+    {
+      /* Constant shift */
+      int offset = INTVAL(operands[2]);
+      ops[5] = GEN_INT(16-offset);  /* Complement of shift count */
+      ops[6] = GEN_INT(offset%16);  /* Modulo of shift count */
+  
+      if(offset < 16)
+      {
+        if(offset == 8)
+        {
+          output_asm_insn("swpb %1",      ops);  /* Swap bytes in low word */
+          output_asm_insn("swpb %4",      ops);  /* Swap bytes in high word */
+          output_asm_insn("movb %1, %4",  ops);  /* Move MSB of high word */
+          output_asm_insn("sb   %1, %1",  ops);  /* Clear MSB of high word */
+        }
+        else
+        {
+          output_asm_insn("mov  %1, %3",  ops);  /* Save high word to temp */
+          output_asm_insn("srl  %1, %6",  ops);  /* Shift high word */
+          output_asm_insn("srl  %4, %6",  ops);  /* Shift low word */
+          output_asm_insn("sla  %3, %5",  ops);  /* Shift high word bits into low word position */
+          output_asm_insn("soc  %3, %4",  ops);  /* Merge shifted high word bits into low word */
+        }
+      } 
+      else
+      {
+        if(offset > 16)
+        {
+          output_asm_insn("srl  %1, %6", ops);  /* Shift high word */
+        }
+        output_asm_insn("mov  %1, %4",  ops);  /* Copy high word to low word */ 
+        output_asm_insn("clr  %1",      ops);  /* Clear high word */
+      }
+    }
+    return "";
+  }
+  [(set_attr "length" "34, 10")]
+)
+
+
+;;-------------------------------------
+(define_insn "lshrhi3"
+  [(set (match_operand:HI 0 "register_operand" "=r,r")
+	(lshiftrt:HI (match_operand:HI 1 "register_operand" "0,0")
+		     (match_operand:HI 2 "shift_count_operand" "S,i")))]
+  ""
+  {
+    if(which_alternative == 0)
+    {
+      output_asm_insn("abs  r0",     operands);
+      output_asm_insn("jeq  $+4",    operands);
+      output_asm_insn("srl  %0, 0",  operands);
+    }
+    else if(INTVAL(operands[2]) > 0)
+    {
+      output_asm_insn("srl  %0, %2", operands);
+    }
+    return(""); 
+  }
+  [(set_attr "length" "6,2")])
+
+
+;;-------------------------------------
+(define_insn "lshrqi3"
+  [(set (match_operand:QI 0 "register_operand" "=r,r")
+	(lshiftrt:QI (match_operand:QI 1 "register_operand" "0,0")
+		     (match_operand:HI 2 "shift_count_operand" "S,i")))]
+  ""
+  {
+    if(which_alternative == 0)
+    {
+      output_asm_insn("abs  r0",        operands);
+      output_asm_insn("jeq  $+4",       operands);
+      output_asm_insn("srl  %0, 0",     operands);
+    }
+    else if(INTVAL(operands[2]) > 0)
+    {
+      output_asm_insn("srl  %0, %2",    operands);
+    }
+    return(""); 
+  }
+  [(set_attr "length" "6,2")])
+
+
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "r,r")
+	(sign_extend:HI(match_operand:QI 1 "register_operand" "r,r")))
+   (set (match_operand:HI 3 "register_operand" "r,r")
+	(lshiftrt:HI (match_operand:HI 4 "register_operand" "0,0")
+		     (match_operand:HI 5 "shift_count_operand" "S,i")))
+   (set (match_operand:QI 6 "register_operand" "r,r")
+        (subreg:QI (match_operand:HI 7 "register_operand" "3,3") 1))]
+  ""
+  [(set (match_dup 6)
+        (match_dup 1))
+   (set (match_dup 6)
+        (lshiftrt:QI (match_dup 6)
+                     (match_dup 5)))]
+  "")
+      
+
+
+;;-------------------------------------------------------------------
+;; Rotate 
+
+
+;;-------------------------------------
+(define_expand "rotlhi3"
+  [(set (match_operand:HI 0 "register_operand" "=r,r")
+        (rotatert:HI (match_operand:HI 1 "register_operand" "0,0")
+                     (match_operand:HI 2 "shift_count_operand" "S,i")))]
+  ""
+  {
+    if (GET_CODE (operands[2]) == CONST_INT)
+      operands[2] = GEN_INT ((16 - INTVAL (operands[2])) % 16);
+    else
+      {
+        rtx reg = gen_reg_rtx (HImode);
+        emit_insn (gen_subhi3 (reg, GEN_INT (16), operands[2]));
+        operands[2] = reg;
+      }
+  })
+
+
+;;-------------------------------------
+(define_insn "rotrhi3"
+  [(set (match_operand:HI 0 "register_operand" "=r,r")
+        (rotatert:HI (match_operand:HI 1 "register_operand" "0,0")
+                     (match_operand:HI 2 "shift_count_operand" "S,i")))]
+  ""
+  "@
+  src  %0, 0
+  src  %0, %2" 
+ [(set_attr "length" "2,2")])
+
+
+;;-------------------------------------------------------------------
+;;  Bitwise Operations
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------------------------------------
+;; And
+
+
+;;-------------------------------------
+(define_insn "andhi3"
+  [(clobber (match_scratch:HI 3 "=r,r,r,r,r,r,r"))
+   (set (match_operand:HI 0 "nonimmediate_operand" "=rR>,rR>,Q,Q,r,R>,Q")
+	(and:HI (match_operand:HI 1 "nonimmediate_operand" "0,0,0,0,0,0,0")
+		(match_operand:HI 2 "general_operand" "rR>,Q,rR>,Q,i,i,i")))]
+  ""
+  {
+    if(which_alternative >= 4)
+    {
+      int val = INTVAL(operands[2]) & 0xFFFF;
+      if(val == 0)
+      {
+        /* Result will be zero */
+        output_asm_insn("clr  %0", operands);
+      }
+      else if(val == 0xFFFF)
+      {
+        /* No operation required */
+        return("");
+      }
+      else if(which_alternative == 4)
+      {
+        /* AND const value and register */
+        output_asm_insn("andi %0, %2", operands);
+      }
+      else if(which_alternative >= 5)
+      {
+        /* AND const value and memory */
+        operands[2] = GEN_INT(~val);
+        output_asm_insn("li   %3, %2", operands);
+        output_asm_insn("szc  %3, %0", operands);
+      }
+    }
+    else
+    {
+      /* AND against non-const value */
+      if(!rtx_equal_p(operands[2], operands[3]))
+      {
+        output_asm_insn("mov  %2, %3", operands);
+      }
+      output_asm_insn("inv  %3",     operands);
+      output_asm_insn("szc  %3, %0", operands);
+    }
+    return(""); 
+  }
+  [(set_attr "length" "6,8,8,10,4,6,8")])
+
+
+(define_insn "*andnothi"
+  [(set (match_operand:HI 0 "nonimmediate_operand" "=rR>,rR>,Q,Q")
+	(and:HI (match_operand:HI 1 "nonimmediate_operand" "0,0,0,0")
+		(not:HI (match_operand:HI 2 "nonimmediate_operand" "rR>,Q,rR>,Q"))))]
+  ""
+  "szc  %2, %0"
+  [(set_attr "length" "2,4,4,6")])
+
+
+; This handles reverse-order not-and combinations
+(define_insn "*not_andhi"
+  [(set (match_operand:HI 0 "nonimmediate_operand" "=rR>,rR>,Q,Q")
+	(and:HI (not:HI (match_operand:HI 1 "nonimmediate_operand" "rR>,Q,rR>,Q"))
+                (match_operand:HI 2 "nonimmediate_operand" "0,0,0,0")))]
+  ""
+  "szc  %1, %0"
+  [(set_attr "length" "2,4,4,6")])
+
+
+;;-------------------------------------
+(define_insn "andqi3"
+  [(clobber (match_scratch:QI 3 "=r,r,r,r,r,r,r"))
+   (set (match_operand:QI 0 "nonimmediate_operand" "=rR>,rR>,Q,Q,r,R>,Q")
+	(and:QI (match_operand:QI 1 "nonimmediate_operand" "0,0,0,0,0,0,0")
+		(match_operand:QI 2 "general_operand" "rR>,Q,rR>,Q,i,i,i")))]
+  ""
+  {
+    if(which_alternative >= 4)
+    {
+      int val = INTVAL(operands[2]) & 0xFF;
+      if(which_alternative == 4)
+      {
+        /* AND const value and register */
+        if(val == 0)
+          output_asm_insn("clr  %0", operands);
+        else if(val == 0xff)
+          return("");
+        else
+        {
+          operands[2] = GEN_INT(val*256);
+          output_asm_insn("andi %0, %2", operands);
+        }
+      }
+      else if(which_alternative >= 5)
+      {
+        /* AND const value and memory */
+        if(val == 0)
+          output_asm_insn("sb %0 %0", operands);
+        else if(val == 0xff)
+          return("");
+        else
+        {
+          operands[2] = GEN_INT((~val)*256);
+          output_asm_insn("li   %3, %2", operands);
+          output_asm_insn("szc  %3, %0", operands);
+        }
+      }
+    }
+    else
+    {
+      /* AND against non-const value */
+      if(!rtx_equal_p(operands[2], operands[3]))
+      {
+        output_asm_insn("movb %2, %3", operands);
+      }
+      output_asm_insn("inv  %3",     operands);
+      output_asm_insn("szcb %3, %0", operands);
+    }
+    return(""); 
+  }
+  [(set_attr "length" "6,8,8,10,4,6,8")])
+
+
+(define_insn "*andnotqi"
+  [(set (match_operand:QI 0 "nonimmediate_operand" "=rR>,rR>,Q,Q")
+	(and:QI (match_operand:QI 1 "nonimmediate_operand" "0,0,0,0")
+		(not:QI (match_operand:QI 2 "nonimmediate_operand" "rR>,Q,rR>,Q"))))]
+  ""
+  "szcb %2, %0"
+  [(set_attr "length" "2,4,4,6")])
+
+
+; This handles reverse-order not-and combinations
+(define_insn "*not_andqi"
+  [(set (match_operand:QI 0 "nonimmediate_operand" "=rR>,rR>,Q,Q")
+	(and:QI (not:QI (match_operand:QI 1 "nonimmediate_operand" "rR>,Q,rR>,Q"))
+                (match_operand:QI 2 "nonimmediate_operand" "0,0,0,0")))]
+  ""
+  "szcb %1, %0"
+  [(set_attr "length" "2,4,4,6")])
+
+
+;;-------------------------------------------------------------------
+;; Or
+
+
+;;-------------------------------------
+(define_insn "iorhi3"
+  [(set (match_operand:HI 0 "nonimmediate_operand" "=rR>,rR>,Q,Q,r,r")
+	(ior:HI (match_operand:HI 1 "nonimmediate_operand" "%0,0,0,0,0,0")
+		(match_operand:HI 2 "general_operand" "rR>,Q,rR>,Q,i,M")))]
+  ""
+  {
+    if (GET_CODE (operands[2]) == CONST_INT)
+      {
+        int val = INTVAL(operands[2]) & 0xFFFF;
+        if(val == 0xFFFF)
+          return "seto %0";
+        else if(val == 0)
+          return "";
+        else
+          return "ori  %0, %2";
+      }
+    return "soc  %2, %0";
+  }
+  [(set_attr "length" "2,4,4,6,4,2")])
+
+
+;;-------------------------------------
+(define_insn "iorqi3"
+  [(set (match_operand:QI 0 "nonimmediate_operand" "=rR>,rR>,Q,Q,r")
+	(ior:QI (match_operand:QI 1 "nonimmediate_operand" "%0,0,0,0,0")
+		(match_operand:QI 2 "general_operand" "rR>,Q,rR>,Q,i")))]
+  ""
+  {
+    if (GET_CODE (operands[2]) == CONST_INT)
+    {
+      int val = INTVAL(operands[2]) & 0xFF;
+      operands[2] = GEN_INT(val * 256);
+      if(val == 0xFF)
+        return "seto %0";
+      else if(val == 0)
+        return "";
+      else
+        return("ori  %0, %2");
+    }
+    return("socb %2, %0");
+  }
+  [(set_attr "length" "2,4,4,6,4")])
+
+
+;;-------------------------------------------------------------------
+;; Xor
+
+
+;;-------------------------------------
+(define_insn "xorhi3"
+  [(set (match_operand:HI 0 "register_operand" "=r,r")
+	(xor:HI (match_operand:HI 1 "register_operand" "%0,0")
+		(match_operand:HI 2 "nonimmediate_operand" "rR>,Q")))]
+  ""
+  "xor  %2, %0"
+  [(set_attr "length" "2,4")])
+
+
+;;-------------------------------------
+(define_insn "xorqi3"
+  [(set (match_operand:QI 0 "register_operand" "=r,r")
+	(xor:QI (match_operand:QI 1 "register_operand" "%0,0")
+		(match_operand:QI 2 "nonimmediate_operand" "rR>,Q")))]
+  ""
+  "xor  %2, %0"
+  [(set_attr "length" "2,4")])
+
+
+;;-------------------------------------------------------------------
+;; Not
+
+
+;;-------------------------------------
+(define_insn "one_cmplhi2"
+  [(set (match_operand:HI 0 "nonimmediate_operand" "=rR>,Q")
+        (not:HI (match_operand:HI 1 "nonimmediate_operand" "0,0")))]
+  ""
+  "inv  %0"
+  [(set_attr "length" "2,4")])
+
+
+;;-------------------------------------
+(define_insn "one_cmplqi2"
+  [(set (match_operand:QI 0 "nonimmediate_operand" "=rR>,Q")
+        (not:QI (match_operand:QI 1 "nonimmediate_operand" "0,0")))]
+  ""
+  "inv  %0"
+  [(set_attr "length" "2,4")])
+
+
+;;-------------------------------------------------------------------
+;;  Arithmetic Operations
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------------------------------------
+;; Add
+
+;;-------------------------------------
+(define_insn "addsi3"
+  [(set (match_operand:SI 0 "nonimmediate_operand"          "=r,r,r,r,r,r, R,R,R,R,R,R, Q,Q,Q,Q,Q,Q")
+	(plus:SI (match_operand:SI 1 "nonimmediate_operand" "%0,0,0,0,0,0, 0,0,0,0,0,0, 0,0,0,0,0,0")
+		 (match_operand:SI 2 "general_operand"       "r,R,Q,I,J,K, r,R,Q,I,J,K, r,R,Q,I,J,K")))
+   (clobber (match_scratch:HI 3                             "=r,r,r,r,r,r, r,r,r,r,r,r, r,r,r,r,r,r"))]
+  ""
+  { 
+    rtx low_words[4];
+    rtx offset[3];
+    low_words[3] = operands[3];
+
+    if(REG_P (operands[0]))
+      low_words[0] = gen_rtx_REG (HImode, REGNO (operands[0]) + REGS_PER_WORD);
+    else
+      low_words[0] = adjust_address (operands[0], HImode, 2);
+
+    if(which_alternative >= 12)
+      offset[0] = GEN_INT(6);
+    else
+      offset[0] = GEN_INT(4);
+  
+    if(! CONSTANT_P(operands[2]))
+    {
+      /* Adding two variables */
+      if(REG_P (operands[2]))
+        low_words[2] = gen_rtx_REG (HImode, REGNO (operands[2]) + REGS_PER_WORD);
+      else
+        low_words[2] = adjust_address (operands[2], HImode, 2);
+
+      output_asm_insn("a    %2, %0", operands);
+      output_asm_insn("a    %2, %0", low_words);
+      output_asm_insn("jnc  $+%0",   offset);
+      output_asm_insn("inc  %0",     operands);
+      return("");
+    }
+    else
+    {
+      /* Adding a constant */
+      int low_const  =  INTVAL(operands[2])        & 0xffff;
+      int high_const = (INTVAL(operands[2]) >> 16) & 0xffff;
+      low_words[2] = GEN_INT(low_const);
+      operands[2]  = GEN_INT(high_const);
+
+      if(low_const != 0)
+      {
+        switch(low_const)
+        {
+          case 0xFFFE: output_asm_insn("dect %0",     low_words); break;
+          case 0xFFFF: output_asm_insn("dec  %0",     low_words); break;
+          case      1: output_asm_insn("inc  %0",     low_words); break;
+          case      2: output_asm_insn("inct %0",     low_words); break;
+          default:
+            if(REG_P(operands[0]))
+              output_asm_insn("ai   %0, %2", low_words);
+            else
+            {
+              output_asm_insn("li   %3, %2", low_words);              
+              output_asm_insn("a    %3, %0", low_words);              
+            }
+        }
+        /* DEC and DECT use inverted carry flags */
+        /*
+        if(low_const == 0xFFFF || low_const == 0xFFFE)
+          output_asm_insn("joc  $+%0",   offset);
+        else
+        */
+          output_asm_insn("jnc  $+%0",   offset);
+
+        /* Handle carry to high word */
+        output_asm_insn("inc  %0",     operands);
+      }
+      if(high_const != 0)
+      {
+        switch(high_const)
+        {
+          case 0xFFFE: output_asm_insn("dect %0",     operands); break;
+          case 0xFFFF: output_asm_insn("dec  %0",     operands); break;
+          case      1: output_asm_insn("inc  %0",     operands); break;
+          case      2: output_asm_insn("inct %0",     operands); break;
+          default:
+            if(REG_P(operands[0]))
+              output_asm_insn("ai   %0, %2", operands);
+            else
+            {
+              output_asm_insn("li   %3, %2", operands);              
+              output_asm_insn("a    %3, %0", operands);              
+            }
+        }
+      }
+    }
+
+    return("");
+  }
+  [(set_attr "length" "8,10,14,4,8,12, 10,12,16,6,12,16,  14,16,18,8,16,20")])
+
+
+;;-------------------------------------
+(define_insn "addhi3"
+  [(set (match_operand:HI 0 "nonimmediate_operand" "=rR>,Q,r,rR>,Q")
+	(plus:HI (match_operand:HI 1 "nonimmediate_operand" "%0,0,0,0,0")
+		 (match_operand:HI 2 "general_operand" "rR>LMNO,rR>LNMO,i,Q,Q")))]
+  ""
+  {
+    switch(GET_CODE(operands[2]))
+    {
+      case CONST_INT:
+      {
+        if (INTVAL(operands[2]) == 1)
+	  return("inc  %0");
+        else if (INTVAL(operands[2]) == -1)
+          return("dec  %0");
+        else if (INTVAL(operands[2]) == 2)
+          return("inct %0");
+        else if (INTVAL(operands[2]) == -2)
+          return("dect %0");
+        else
+          return("ai   %0, %2");
+      }
+
+      case MEM:
+      case REG:
+        return ("a    %2, %0");
+
+      default:
+          return("ai   %0, %2");
+    }
+  }
+  [(set_attr "length" "2,4,4,4,6")])
+
+
+;;-------------------------------------
+(define_insn "addqi3"
+  [(set (match_operand:QI 0 "nonimmediate_operand" "=rR>,rR>,Q,Q,r")
+	(plus:QI (match_operand:QI 1 "nonimmediate_operand" "%0,0,0,0,0")
+		 (match_operand:QI 2 "general_operand" "rR>,Q,rR>,Q,i")))]
+  ""
+  {
+  if (GET_CODE (operands[2]) == CONST_INT)
+    {
+      operands[2] = GEN_INT(INTVAL(operands[2]) * 256);
+      return("ai   %0, %2");
+    }
+  return("ab   %2, %0");
+  }
+  [(set_attr "length" "2,4,4,6,4")])
+
+
+;;-------------------------------------------------------------------
+;; Subtract
+
+
+;;-------------------------------------
+(define_insn "subsi3"
+  [(set (match_operand:SI 0 "nonimmediate_operand"          "=r,r,r,r,r,r,R,R,R,R,R,R,Q,Q,Q,Q,Q,Q")
+	(minus:SI (match_operand:SI 1 "nonimmediate_operand" "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0")
+		  (match_operand:SI 2 "general_operand"      "r,R,Q,I,J,K,r,R,Q,I,J,K,r,R,Q,I,J,K")))]
+  ""
+  {
+    rtx lateoperands[3];
+    rtx offset[3];
+
+    lateoperands[0] = operands[0];
+    if(REG_P(operands[0]))
+    {
+      operands[0] = gen_rtx_REG(HImode, REGNO (operands[0]) + REGS_PER_WORD);
+      offset[0] = GEN_INT(4);
+    }
+    else
+    {
+      operands[0] = adjust_address(operands[0], HImode, 2);
+      offset[0] = GEN_INT(6);
+    }
+  
+    if(! CONSTANT_P(operands[2]))
+    {
+      lateoperands[2] = operands[2];
+
+      if(REG_P(operands[2]))
+        operands[2] = gen_rtx_REG(HImode, REGNO (operands[2]) + REGS_PER_WORD);
+      else
+        operands[2] = adjust_address(operands[2], HImode, 2);
+
+      output_asm_insn("s    %2, %0", lateoperands);
+      output_asm_insn("s    %2, %0", operands);
+      output_asm_insn("joc  $+%0", offset);
+      output_asm_insn("dec  %0", lateoperands);
+      return("");
+    }
+    /* EMW - This never seems to be called... */
+    lateoperands[2] = GEN_INT((INTVAL(operands[2]) >> 16) & 0xffff);
+    operands[2] = GEN_INT(INTVAL(operands[2]) & 0xffff);
+  
+    if(INTVAL(operands[2]))
+    { 
+      output_asm_insn("ai   %0, %2", operands);
+      output_asm_insn("jnc  $+%0", offset);
+      output_asm_insn("dec  %0", lateoperands);
+    }
+    if(INTVAL(lateoperands[2]))
+    {
+      operands[2] = GEN_INT(-INTVAL(operands[2]));
+      output_asm_insn("ai   %0, %2", lateoperands);
+    }
+    return("");
+  }
+  [(set_attr "length" "8,10,12,4,8,12, 12,14,16,4,12,16,  16,18,18,6,12,18")])
+
+
+;;-------------------------------------
+(define_insn "subhi3"
+  [(set (match_operand:HI 0 "nonimmediate_operand" "=rR>,Q,rR>,Q,rR>,Q,rR>,Q")
+	(minus:HI (match_operand:HI 1 "nonimmediate_operand" "0,0,0,0,rR>,rR>,Q,Q")
+		  (match_operand:HI 2 "nonimmediate_operand" "rR>,rR>,Q,Q,0,0,0,0")))]
+  ""
+  {
+    if(which_alternative < 4)
+    {
+      output_asm_insn("s    %2, %0",operands);
+    }
+    else
+    {
+      output_asm_insn("s    %1, %0",operands);
+      output_asm_insn("neg  %0",operands);
+    }
+    return("");
+  }
+  [(set_attr "length" "2,4,4,6, 4,6,8,10")])
+
+
+;;-------------------------------------
+(define_insn "*rsubihi"
+  [(set (match_operand:HI 0 "register_operand" "=r")
+	(minus:HI (match_operand:HI 1 "immediate_operand" "i")
+		  (match_operand:HI 2 "register_operand" "0")))]
+  ""
+  {
+    if (INTVAL(operands[1]) == -1)
+      output_asm_insn("inc  %0",operands);
+    else if (INTVAL(operands[1]) == 1)
+      output_asm_insn("dec  %0",operands);
+    else if (INTVAL(operands[1]) == -2)
+      output_asm_insn("inct %0",operands);
+    else if (INTVAL(operands[1]) == 2)
+      output_asm_insn("dect %0",operands);
+    else
+    {
+      operands[1] = GEN_INT(-INTVAL(operands[1]));
+      output_asm_insn("ai   %0, %1",operands);
+    }
+    output_asm_insn("neg  %0",operands);
+    return "";
+  }
+  [(set_attr "length" "6")])
+
+
+;;-------------------------------------
+(define_insn "subqi3"
+  [(set (match_operand:QI 0 "nonimmediate_operand" "=rR>,Q,rR>,Q,rR>,Q,rR>,Q")
+	(minus:QI (match_operand:QI 1 "nonimmediate_operand" "0,0,0,0,rR>,rR>,Q,Q")
+		  (match_operand:QI 2 "nonimmediate_operand" "rR>,rR>,Q,Q,0,0,0,0")))]
+  ""
+  {
+    if(which_alternative < 4)
+    {
+      output_asm_insn("sb   %2, %0",operands);
+    }
+    else
+    {
+      output_asm_insn("sb   %1, %0",operands);
+      output_asm_insn("neg  %0",operands);
+    }
+    return("");
+  }
+  [(set_attr "length" "2,4,4,6, 4,6,8,10")])
+
+
+;;-------------------------------------------------------------------
+;; Multiply
+
+
+;;-------------------------------------
+(define_insn "mulsi3"
+  [(set (match_operand:SI 0 "register_operand" "=r,r,r")
+        (mult:SI (match_operand:SI 1 "register_operand" "0,0,0")
+                 (match_operand:SI 2 "nonimmediate_operand"  "r,R,Q")))
+   (clobber (match_scratch:HI 3 "=r,r,r"))
+   (clobber (match_scratch:HI 4 "=r,r,r"))]
+  ""
+  {
+    rtx args[6];
+
+    args[0] = operands[0];  // Destination R
+    args[1] = gen_lowpart_SUBREG(HImode, operands[0]);
+
+    args[2] = operands[2];  // Source G
+    if(REG_P(operands[2]))
+    {
+      args[3] = gen_lowpart_SUBREG(HImode, operands[2]);
+    }
+    else
+    {
+      args[3] = adjust_address(operands[2], HImode, 2);
+    }
+
+    args[4] = operands[3];  // Temp
+    args[5] = operands[4];  // Hold
+
+    /*
+    Since we only have a 16-bit multiply, we need to expand
+    this math.
+
+    (R0*N+R1)*(G0*N+G1) = R0*G0*N*N + R0*G1*N + R1*G0*N + R1*G1
+
+    We can omit the R0*G0 term since it won't fit into 32 bits
+    */
+
+    output_asm_insn("mov  %1, %5",args);  // H = R1
+    output_asm_insn("mpy  %3, %0",args);  // [R0,R1] = R0*G1
+    output_asm_insn("mov  %1, %4",args);  // T = LSW(R0*G1)
+    output_asm_insn("mov  %5, %0",args);  // R0 = H
+    output_asm_insn("mpy  %2, %0",args);  // [R0,R1] = R1*G0
+    output_asm_insn("a    %1, %4",args);  // T += LSW(R1*G0)
+    output_asm_insn("mov  %5, %0",args);  // R0 = H
+    output_asm_insn("mpy  %3, %0",args);  // [R0,R1] = R1*G1
+    output_asm_insn("a    %4, %0",args);  // R0 += T
+    return("");
+  }
+  [(set_attr "length" "18,22,26")])
+
+
+;;-------------------------------------
+(define_insn "umulhisi3"
+  [(set (match_operand:SI 0 "register_operand" "=r,r")
+	(mult:SI (match_operand:HI 1 "register_operand" "r,r")
+		 (match_operand:HI 2 "nonimmediate_operand" "rR>,Q")))]
+  ""
+  {
+    if(REG_P(operands[1]) && (REGNO(operands[1]) == REGNO(operands[0])))
+    {
+      /* op[1] == op[0], arguments in proper location */
+      output_asm_insn("mpy  %2, %0", operands);
+    }
+    else
+    {
+      /* Arguments need to move */
+      if(!REG_P(operands[2]) || (REGNO(operands[2]) != REGNO(operands[0])))
+      {
+        /* op[2] != op[0], fix that */
+        output_asm_insn("mov  %2, %0", operands);
+      }
+      output_asm_insn("mpy  %1, %0", operands);
+    }
+    return("");
+  }
+  [(set_attr "length" "4,6")])
+
+
+(define_expand "mulhi3"
+  [(set (match_dup 3)
+        (mult:SI (match_operand:HI 1 "register_operand" "r,r")
+                 (match_operand:HI 2 "nonimmediate_operand" "rR>,Q")))
+   (set (match_operand:HI 0 "register_operand" "=r,r")
+        (subreg:HI (match_dup 3) 2))]
+   ""
+   "operands[3] = force_reg(SImode, GEN_INT(0));"
+)
+
+
+;;-------------------------------------
+(define_insn "*mulqisi3"
+  [
+   (set (match_operand:SI 0 "register_operand" "=r")
+        (mult:SI (match_operand:QI 1 "register_operand" "0")
+                 (match_operand:QI 2 "register_operand" "r")))
+  ]
+  ""
+  {
+    rtx ops[4];
+    ops[0] = operands[0];  /* Destination */
+    ops[1] = operands[1];  /* Source 1 */
+    ops[2] = operands[2];  /* Source 2 */
+    ops[3] = gen_rtx_REG (HImode, REGNO (operands[0]) + REGS_PER_WORD);  /* Low word of source */
+
+    // Sometimes the source operands can get swapped, fix that here
+    if(REGNO(operands[2]) != REGNO(operands[0]))
+    {
+      /* ops[2] != ops[0], fix that */
+      output_asm_insn("mov  %2, %0", ops);
+    }
+    output_asm_insn("mpy  %1, %0", ops);
+    output_asm_insn("mov  %0, %3", ops);
+    return("");
+  }
+  [(set_attr "length" "6")])
+
+
+(define_expand "mulqi3"
+  [
+   (set (match_dup 3)
+        (mult:SI (match_operand:QI 1 "register_operand" "3")
+                 (match_operand:QI 2 "register_operand" "r")))
+   (set (match_operand:QI 0 "register_operand" "=r")
+        (subreg:QI (match_dup 3) 3))
+  ]
+  ""
+  "operands[3] = force_reg(SImode, GEN_INT(0));"
+)
+
+
+;;-------------------------------------------------------------------
+;; Divide and Modulus
+
+
+;;-------------------------------------
+(define_insn "divmodsihi3"
+  [(set (match_operand:SI 0 "register_operand" "=r,r")
+        (ior:SI
+          (ashift:SI
+            (zero_extend:SI
+              (div:HI (match_operand:SI 1 "register_operand" "0,0")
+                      (match_operand:HI 2 "nonimmediate_operand" "rR>,Q")))
+            (const_int 16))
+          (zero_extend:SI 
+            (mod:HI (match_dup 1)
+                    (match_dup 2)))))]
+  ""
+  "div  %2, %0"
+  [(set_attr "length" "2,4")])
+
+
+(define_expand "udivmodhi4"
+  [(parallel [
+     (set (match_operand:HI 0 "register_operand" "=r,r")
+          (div:HI (match_operand:SI 1 "register_operand" "+0,0")
+                  (match_operand:HI 2 "nonimmediate_operand" "+rR>,Q")))
+     (set (match_operand:HI 3 "register_operand" "=r,r")
+          (mod:HI (match_dup 1) 
+                  (match_dup 2)))])]
+  ""
+  {
+    rtx insn, div_equal, mod_equal, equal;
+    div_equal = gen_rtx_DIV (HImode, operands[1], operands[2]);
+    mod_equal = gen_rtx_MOD (HImode, operands[1], operands[2]);
+    equal = gen_rtx_IOR (SImode,
+                         gen_rtx_ASHIFT (SImode,
+                                         gen_rtx_ZERO_EXTEND (SImode, div_equal),
+                                         GEN_INT (16)),
+                         gen_rtx_ZERO_EXTEND (SImode, mod_equal));
+
+    insn = emit_insn (gen_divmodsihi3 (operands[1], operands[1], operands[2]));
+    set_unique_reg_note (insn, REG_EQUAL, equal);
+
+    insn = emit_move_insn (operands[0], gen_highpart (HImode, operands[1]));
+    set_unique_reg_note (insn, REG_EQUAL, mod_equal);
+
+    insn = emit_move_insn (operands[3], gen_lowpart (HImode, operands[1]));
+    set_unique_reg_note (insn, REG_EQUAL, div_equal);
+
+    DONE;
+  })
+
+
+;;-------------------------------------
+(define_expand "divmodhi4"
+  [(parallel [
+     (clobber (match_scratch:HI 4 "+r,r"))
+     (clobber (match_scratch:HI 5 "+r,r"))
+     (clobber (match_scratch:SI 6 "+r,r"))
+     (clobber (match_scratch:HI 7 "+r,r"))
+     (clobber (match_scratch:HI 8 "+r,r"))
+     (set (match_operand:HI 0 "register_operand" "=r,r")
+          (div:HI (match_operand:HI 1 "register_operand" "0,0")
+                  (match_operand:HI 2 "nonimmediate_operand" "rR>,Q")))
+     (set (match_operand:HI 3 "register_operand" "=r,r")
+          (mod:HI (match_dup 1) 
+                  (match_dup 2)))
+])]
+  ""
+  {
+    operands[4] = gen_reg_rtx(HImode);
+    operands[5] = gen_reg_rtx(HImode);
+    operands[6] = gen_reg_rtx(SImode);
+    operands[7] = gen_reg_rtx(HImode);
+    operands[8] = gen_reg_rtx(HImode);
+
+    /* Use temp for operands */
+    emit_move_insn(operands[7], operands[1]);
+    emit_move_insn(operands[8], operands[2]);
+
+    /* Find quotient sign */
+    emit_move_insn(operands[4], operands[1]);
+    emit_insn(gen_xorhi3(operands[4], operands[4], operands[8]));
+  
+    /* Find modulus sign */
+    emit_move_insn(operands[5], operands[1]);
+
+    /* Convert operands to absolute value */
+    emit_insn(gen_abshi2(operands[7], operands[7]));
+    emit_insn(gen_abshi2(operands[8], operands[8]));
+
+    /* Perform division and modulus */
+    emit_move_insn(operands[6],gen_rtx_ZERO_EXTEND(SImode, operands[7]));
+    emit_insn(gen_udivmodhi4(operands[0], operands[6], operands[8], operands[3]));
+
+    /* Correct sign of results */
+    emit_insn(gen_divfixuphi2(operands[0], operands[4]));  /* Correct quotient sign */
+    emit_insn(gen_divfixuphi2(operands[3], operands[5]));  /* Correct modulus sign */
+
+    DONE;
+  }
+)
+
+
+(define_insn "divfixuphi2"
+  [(set (match_operand:HI 1 "register_operand" "=r")
+        (not:HI (match_dup 1)))
+   (set (match_operand:HI 0 "register_operand" "=r")
+        (if_then_else:HI (lt:HI (match_dup 1) (const_int 0))
+           (neg:HI (match_dup 0)) (match_dup 0)))]
+  ""
+  {
+    output_asm_insn("inv  %1", operands);
+    output_asm_insn("jlt  $+4", operands);
+    output_asm_insn("neg  %0", operands);
+    return("");
+  }
+  [(set_attr "length" "6")])
+
+
+;;-------------------------------------------------------------------
+;; Absolute Value
+
+
+;;-------------------------------------
+(define_insn "abshi2"
+  [(set (match_operand:HI 0 "nonimmediate_operand" "=rR>,Q")
+	(abs:HI (match_operand:HI 1 "nonimmediate_operand" "0,0")))]
+  ""
+  "abs  %0"
+  [(set_attr "length" "2,4")])
+
+
+;;-------------------------------------
+(define_insn "absqi2"
+  [(set (match_operand:QI 0 "register_operand" "=r")
+	(abs:QI (match_operand:QI 1 "register_operand" "0")))]
+  ""
+  "abs  %0"
+  [(set_attr "length" "2")])
+
+
+;;-------------------------------------------------------------------
+;; Negate
+
+
+;;-------------------------------------
+(define_insn "negsi2"
+  [(set (match_operand:SI 0 "nonimmediate_operand" "=rR,Q")
+	(neg:SI (match_operand:SI 1 "nonimmediate_operand" "0,0")))]
+  ""
+  {
+    rtx word[2];
+    rtx offset[1];
+
+    /* word 0 is most significant */
+    word[0] = operands[0];
+    if (REG_P (operands[0]))
+    {
+      word[1] = gen_rtx_REG(HImode, REGNO(operands[0]) + REGS_PER_WORD);
+      offset[0] = GEN_INT(4);
+    }
+    else
+    {
+      word[1] = adjust_address(operands[0], HImode, 2);
+      offset[0] = GEN_INT(6);
+    }
+    output_asm_insn("inv  %0", word);
+    output_asm_insn("neg  %1", word);
+    output_asm_insn("jnc  $+%0", offset);
+    output_asm_insn("inc  %0", word);
+    return("");
+  }
+  [(set_attr "length" "8,14")])
+
+
+;;-------------------------------------
+(define_insn "neghi2"
+  [(set (match_operand:HI 0 "nonimmediate_operand" "=rR>,Q")
+	(neg:HI (match_operand:HI 1 "nonimmediate_operand" "0,0")))]
+  ""
+  "neg  %0"
+  [(set_attr "length" "2,4")])
+
+
+;;-------------------------------------
+(define_insn "negqi2"
+  [(set (match_operand:QI 0 "register_operand" "=r")
+	(neg:QI (match_operand:QI 1 "register_operand" "0")))]
+  ""
+  {
+    output_asm_insn("andi %0, 0xFF00", operands);
+    output_asm_insn("neg  %0", operands);
+    return("");
+  }
+  [(set_attr "length" "6")])
+
+
+;;-------------------------------------------------------------------
+;;  Move Operations
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------------------------------------
+;; Move byte value
+(define_insn "movqi"
+  [(set (match_operand:QI 0 "nonimmediate_operand" "=rR>,rR>,Q,  Q,r, r,W,r")
+        (match_operand:QI 1 "general_operand"       "rR>,Q,  rR>,Q,MO,i,r,W"))]
+  ""
+  {
+    if (GET_CODE (operands[1]) == CONST_INT)
+    {
+      if(GET_CODE (operands[0]) == REG)
+      {
+        if (INTVAL(operands[1]) == 0)
+          return("clr  %0");
+        else if (INTVAL(operands[1]) == -1)
+          return("seto %0");
+        else
+        {
+          operands[1] = GEN_INT(INTVAL(operands[1]) * 256);
+          return("li   %0, %1");
+        }
+      }
+    }
+    else if(GET_CODE (operands[1]) == SUBREG ||
+            GET_CODE (operands[1]) == TRUNCATE)
+    {
+      /* Mode change required, HI to QI */
+      rtx suboperands[2];
+      suboperands[0] = operands[0];
+      suboperands[1] = SUBREG_REG(operands[1]);
+      if(GET_CODE(operands[0]) == REG)
+      {
+        /* Reg-to-reg copy */ 
+        if(REGNO(suboperands[0]) == REGNO(suboperands[1]))
+        {
+          /* Convert within the register */
+          output_asm_insn ("swpb %0", suboperands);
+        }
+        else
+        {
+          /* Copy to other register, then convert */
+          output_asm_insn ("mov  %1, %0", suboperands);
+          output_asm_insn ("swpb %0", suboperands);            
+        }
+      }
+      else
+      {
+        /* Reg-to-mem copy */
+        if(find_regno_note(insn, REG_DEAD, REGNO(suboperands[1])))
+        {
+          output_asm_insn ("swpb %1", suboperands);                       
+          output_asm_insn ("movb %1, %0", suboperands);
+          /* Operand 1 dies here, no need to restore it */
+        }
+        else
+        {
+          output_asm_insn ("swpb %1", suboperands);                       
+          output_asm_insn ("movb %1, %0", suboperands);
+          output_asm_insn ("swpb %1", suboperands);                       
+        }
+      }
+      return("");
+    }
+    return("movb %1, %0");
+  }
+  [(set_attr "length" "4,8,4,6,2,4,4,4")])
+
+
+
+;;-------------------------------------------------------------------
+;; Move two-byte value
+(define_insn "movhi"
+  [(set (match_operand:HI 0 "nonimmediate_operand" "=UrR>,rR>,Q,Q,r,W,r")
+	(match_operand:HI 1 "general_operand" "rROM>,Q,rROM>,Q,i,r,W"))]
+  ""
+  {
+    switch(GET_CODE(operands[1]))
+    {
+      case CONST_INT:
+        if (INTVAL(operands[1]) == 0)
+          return("clr  %0");
+        else if (INTVAL(operands[1]) == -1)
+          return("seto %0");
+        else
+          return("li   %0, %1");
+
+      case REG:
+      case MEM:
+        return("mov  %1, %0");
+
+      default:
+        return("li   %0, %1");
+    }
+  }
+  [(set_attr "length" "2,4,4,6,4,2,2")])
+
+
+;;-------------------------------------------------------------------
+;; Type Conversions
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------------------------------------
+;; Zero Extend
+
+
+;;-------------------------------------
+(define_insn "zero_extendqihi2"
+  [(set (match_operand:HI 0 "register_operand" "=r")
+	(zero_extend:HI (match_operand:QI 1 "register_operand" "0")))]
+  ""
+  "srl  %0, 8"
+  [(set_attr "length" "2")])
+
+
+;;-------------------------------------
+(define_insn "zero_extendhisi2"
+  [(set (match_operand:SI 0 "nonimmediate_operand" "=r,R,Q")
+	(zero_extend:SI (match_operand:HI 1 "general_operand" "g,g,g")))]
+  ""
+  {
+    rtx lateoperands[2];
+
+    lateoperands[0] = operands[0];
+    if (REG_P (operands[0]))
+      operands[0] = gen_rtx_REG(HImode, REGNO(operands[0]) + REGS_PER_WORD);
+    else
+      operands[0] = adjust_address(operands[0], HImode, 2);
+
+    output_asm_insn("mov  %1, %0", operands);
+    output_asm_insn("clr  %0", lateoperands);
+    return("");
+  }
+  [(set_attr "length" "4,8,10")])
+
+
+;;-------------------------------------------------------------------
+;; Sign Extend
+(define_insn "extendqihi2"
+  [(set (match_operand:HI 0 "register_operand" "=r")
+	(sign_extend:HI (match_operand:QI 1 "register_operand" "0")))]
+  ""
+  "sra  %0, 8"
+  [(set_attr "length" "2")])
+			 
+
+;;-------------------------------------
+(define_insn "extendhisi2"
+  [(set (match_operand:SI 0 "nonimmediate_operand" "=r,R,Q")
+	(sign_extend:SI (match_operand:HI 1 "general_operand" "g,g,g")))]
+  ""
+  {
+    rtx latehalf[2];
+    rtx offset[2];
+
+    latehalf[0] = operands[0];
+    if (REG_P (operands[0]))
+      operands[0] = gen_rtx_REG(HImode, REGNO(operands[0]) + REGS_PER_WORD);
+    else
+      operands[0] = adjust_address(operands[0], HImode, 2);
+
+    if(which_alternative == 2)
+      offset[0] = GEN_INT(6);
+    else
+      offset[0] = GEN_INT(4);
+
+    output_asm_insn("mov  %1, %0", operands);
+    output_asm_insn("seto %0", latehalf);
+    output_asm_insn("jlt  $+%0", offset);
+    output_asm_insn("clr  %0", latehalf);
+    return("");
+  }
+  [(set_attr "length" "8,12,14")])
+
+
+;;-------------------------------------------------------------------
+;; Other Instructions
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------------------------------------
+;; No-op
+(define_insn "nop"
+  [(const_int 0)]
+  ""
+  "nop"
+  [(set_attr "length" "2")])
+
+
+
+;;-------------------------------------------------------------------
+;;  Optimizations For Comparisons
+;;-------------------------------------------------------------------
+
+;;-------------------------------------------------------------------
+;; Optimization for X == {-2,-1,1,2}
+(define_peephole2
+  [(set (cc0)
+	(compare (match_operand:HI 0 "register_operand" "r")
+		 (match_operand:HI 1 "immediate_operand" "LMNO")))
+   (set (pc) (if_then_else (eq (cc0) (const_int 0))
+                           (label_ref (match_operand 2 "" ""))
+                           (pc)))]
+  "peep2_reg_dead_p(2, operands[0])"
+  [(set (match_operand:HI 0 "register_operand" "")
+	(plus:HI (match_dup 0) (neg:HI (match_dup 1))))
+   (set (cc0) (match_dup 0))
+   (set (pc) (if_then_else (eq (cc0) (const_int 0))
+                           (label_ref (match_dup 2))
+                           (pc)))]
+  )
+
+
+(define_insn "*sub_const_hi"
+  [(set (match_operand:HI 0 "register_operand" "=r,r")
+        (plus:HI (match_operand:HI 1 "register_operand" "0,0")
+                 (neg:HI (match_operand:HI 2 "immediate_operand" "LMNO, i"))))]
+  ""
+  {
+    operands[2] = GEN_INT(-INTVAL(operands[2]));
+    switch(INTVAL(operands[2]))
+    {
+      case -2: output_asm_insn("dect %0",     operands); break;
+      case -1: output_asm_insn("dec  %0",     operands); break;
+      case  1: output_asm_insn("inc  %0",     operands); break;
+      case  2: output_asm_insn("inct %0",     operands); break;
+      default: output_asm_insn("ai   %0, %2", operands); break;
+    }
+    return("");
+  }
+  [(set_attr "length" "2,4")])
+
+
+;;-------------------------------------------------------------------
+;; Optimization for X != {-2,-1,1,2}
+(define_peephole2
+  [(set (cc0)
+	(compare (match_operand:HI 0 "register_operand" "r")
+		 (match_operand:HI 1 "immediate_operand" "LMNO")))
+   (set (pc) (if_then_else (ne (cc0) (const_int 0))
+                           (label_ref (match_operand 2 "" ""))
+                           (pc)))]
+  "peep2_reg_dead_p(2, operands[0])"
+  [(set (match_operand:HI 0 "register_operand" "")
+	(plus:HI (match_dup 0) (neg:HI (match_dup 1))))
+   (set (cc0) (match_dup 0))
+   (set (pc) (if_then_else (ne (cc0) (const_int 0))
+                           (label_ref (match_dup 2))
+                           (pc)))]
+  )
+
+
+;;-------------------------------------------------------------------
+;;  Optimizations For Byte Compares
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (unsigned char)X > N
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "=r")
+        (match_operand:QI 1 "const_int_operand" "i"))
+   (set (cc0)
+        (compare (match_operand:QI 2 "register_operand" "r")
+                 (match_dup 0)))
+   (set (pc) (if_then_else (gtu (cc0) (const_int 0))
+                           (label_ref (match_operand 3 "" ""))
+                           (pc)))]
+  "peep2_reg_dead_p(3, operands[0])"
+  [(set (cc0)
+        (compare (match_dup 2)
+                 (plus:HI (const_int 255)
+                          (mult:HI (match_dup 1)
+                                   (const_int 256)))))
+   (set (pc) (if_then_else (gtu (cc0) (const_int 0))
+                           (label_ref (match_dup 3))
+                           (pc)))]
+  )
+
+
+(define_insn "*cmpqi_as_hi"
+  [(set (cc0)
+      (compare (match_operand:QI 0 "register_operand" "r")
+         (plus:HI (match_operand:HI 1 "const_int_operand" "i")
+            (mult:HI (match_operand:HI 2 "const_int_operand" "i")
+               (match_operand:HI 3 "const_int_operand" "i")))))]
+  "INTVAL(operands[3]) == 256 && (INTVAL(operands[1]) == 0 || INTVAL(operands[1]) == 255)"
+  {
+    operands[1] = GEN_INT(INTVAL(operands[2]) * 256 + INTVAL(operands[1]));
+    return("ci   %0, %1");
+  }
+  [(set_attr "length" "4")])
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (unsigned char)X < N
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "=r")
+        (match_operand:QI 1 "const_int_operand" "i"))
+   (set (cc0)
+        (compare (match_operand:QI 2 "register_operand" "r")
+                 (match_dup 0)))
+   (set (pc) (if_then_else (ltu (cc0) (const_int 0))
+                           (label_ref (match_operand 3 "" ""))
+                           (pc)))]
+  "peep2_reg_dead_p(3, operands[0])"
+  [(set (cc0)
+        (compare (match_dup 2)
+                 (plus:HI (const_int 0)
+                          (mult:HI (match_dup 1)
+                                   (const_int 256)))))
+   (set (pc) (if_then_else (ltu (cc0) (const_int 0))
+                           (label_ref (match_dup 3))
+                           (pc)))]
+  )
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (unsigned char)X >= N
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "=r")
+        (match_operand:QI 1 "const_int_operand" "i"))
+   (set (cc0)
+        (compare (match_operand:QI 2 "register_operand" "r")
+                 (match_dup 0)))
+   (set (pc) (if_then_else (geu (cc0) (const_int 0))
+                           (label_ref (match_operand 3 "" ""))
+                           (pc)))]
+  "peep2_reg_dead_p(3, operands[0])"
+  [(set (cc0)
+        (compare (match_dup 2)
+                 (plus:HI (const_int 0)
+                          (mult:HI (match_dup 1)
+                                   (const_int 256)))))
+   (set (pc) (if_then_else (geu (cc0) (const_int 0))
+                           (label_ref (match_dup 3))
+                           (pc)))]
+  )
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (unsigned char)X <= N
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "=r")
+        (match_operand:QI 1 "const_int_operand" "i"))
+   (set (cc0)
+        (compare (match_operand:QI 2 "register_operand" "r")
+                 (match_dup 0)))
+   (set (pc) (if_then_else (leu (cc0) (const_int 0))
+                           (label_ref (match_operand 3 "" ""))
+                           (pc)))]
+  "peep2_reg_dead_p(3, operands[0])"
+  [(set (cc0)
+        (compare (match_dup 2)
+                 (plus:HI (const_int 255)
+                          (mult:HI (match_dup 1)
+                                   (const_int 256)))))
+   (set (pc) (if_then_else (leu (cc0) (const_int 0))
+                           (label_ref (match_dup 3))
+                           (pc)))]
+  )
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (char)X > N
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "=r")
+        (match_operand:QI 1 "const_int_operand" "i"))
+   (set (cc0)
+        (compare (match_operand:QI 2 "register_operand" "r")
+                 (match_dup 0)))
+   (set (pc) (if_then_else (gt (cc0) (const_int 0))
+                           (label_ref (match_operand 3 "" ""))
+                           (pc)))]
+  "peep2_reg_dead_p(3, operands[0])"
+  [(set (cc0)
+        (compare (match_dup 2)
+                 (plus:HI (const_int 255)
+                          (mult:HI (match_dup 1)
+                                  (const_int 256)))))
+   (set (pc) (if_then_else (gt (cc0) (const_int 0))
+                           (label_ref (match_dup 3))
+                           (pc)))]
+  )
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (char)X < N
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "=r")
+        (match_operand:QI 1 "const_int_operand" "i"))
+   (set (cc0)
+        (compare (match_operand:QI 2 "register_operand" "r")
+                 (match_dup 0)))
+   (set (pc) (if_then_else (lt (cc0) (const_int 0))
+                           (label_ref (match_operand 3 "" ""))
+                           (pc)))]
+  "peep2_reg_dead_p(3, operands[0])"
+  [(set (cc0)
+        (compare (match_dup 2)
+                 (plus:HI (const_int 0)
+                          (mult:HI (match_dup 1)
+                                   (const_int 256)))))
+   (set (pc) (if_then_else (lt (cc0) (const_int 0))
+                           (label_ref (match_dup 3))
+                           (pc)))]
+  )
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (char)X >= N
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "=r")
+        (match_operand:QI 1 "const_int_operand" "i"))
+   (set (cc0)
+        (compare (match_operand:QI 2 "register_operand" "r")
+                 (match_dup 0)))
+   (set (pc) (if_then_else (ge (cc0) (const_int 0))
+                           (label_ref (match_operand 3 "" ""))
+                           (pc)))]
+  "peep2_reg_dead_p(3, operands[0])"
+  [(set (cc0)
+        (compare (match_dup 2)
+                 (plus:HI (const_int 0)
+                          (mult:HI (match_dup 1)
+                                   (const_int 256)))))
+   (set (pc) (if_then_else (ge (cc0) (const_int 0))
+                           (label_ref (match_dup 3))
+                           (pc)))]
+  )
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (char)X <= N
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "=r")
+        (match_operand:QI 1 "const_int_operand" "i"))
+   (set (cc0)
+        (compare (match_operand:QI 2 "register_operand" "r")
+                 (match_dup 0)))
+   (set (pc) (if_then_else (le (cc0) (const_int 0))
+                           (label_ref (match_operand 3 "" ""))
+                           (pc)))]
+  "peep2_reg_dead_p(3, operands[0])"
+  [(set (cc0)
+        (compare (match_dup 2)
+                 (plus:HI (const_int 255)
+                          (mult:HI (match_dup 1)
+                                   (const_int 256)))))
+   (set (pc) (if_then_else (le (cc0) (const_int 0))
+                           (label_ref (match_dup 3))
+                           (pc)))]
+  )
+
+
+;;-------------------------------------------------------------------
+;;  Optimizations For Bit Shift And Cast
+;;-------------------------------------------------------------------
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (char)X = (int X) >> N
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (ashiftrt:HI (match_dup 0)
+            (match_operand:HI 1 "const_int_operand" "i")))
+   (set (match_operand:QI 2 "register_operand" "=r")
+        (subreg:QI (match_dup 0) 1))]
+  "REGNO(operands[0]) == REGNO(operands[2])"
+  [(set (match_dup 0)
+        (ashiftrt:HI (match_dup 0)
+            (minus:HI (match_dup 1) 
+                      (const_int 8))))]
+  )
+
+(define_insn "*ashiftrt_hi_to_qi"
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (ashiftrt:HI (match_dup 0)
+            (minus:HI (match_operand:HI 1 "const_int_operand" "i") 
+                      (match_operand:HI 2 "const_int_operand" "i"))))]
+  ""
+  {
+    int shift = INTVAL (operands[1]);
+    if(shift < 8)
+    {
+      operands[1] = GEN_INT(8 - shift);
+      output_asm_insn("sla  %0, %1", operands);
+    }
+    else if(shift > 8)
+    {
+      operands[1] = GEN_INT(shift - 8);
+      output_asm_insn("sra  %0, %1", operands);
+    }
+    return "";
+  }
+  [(set_attr "length" "2")])
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (unsigned char)X = (unsigned int X) >> N
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (lshiftrt:HI (match_dup 0)
+            (match_operand:HI 1 "const_int_operand" "i")))
+   (set (match_operand:QI 2 "register_operand" "=r")
+        (subreg:QI (match_dup 0) 1))]
+  "REGNO(operands[0]) == REGNO(operands[2])"
+  [(set (match_dup 0)
+        (lshiftrt:HI (match_dup 0)
+            (minus:HI (match_dup 1) 
+                      (const_int 8))))]
+  )
+
+
+(define_insn "*lshiftrt_hi_to_qi"
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (lshiftrt:HI (match_dup 0)
+            (minus:HI (match_operand:HI 1 "const_int_operand" "i") 
+                      (match_operand:HI 2 "const_int_operand" "i"))))]
+  ""
+  {
+    int shift = INTVAL (operands[1]);
+    if(shift < 8)
+    {
+      operands[1] = GEN_INT(8 - shift);
+      output_asm_insn("sla  %0, %1", operands);
+    }
+    else if(shift > 8)
+    {
+      operands[1] = GEN_INT(shift - 8);
+      output_asm_insn("srl  %0, %1", operands);
+    }
+    return "";
+  }
+  [(set_attr "length" "2")])
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (char)X = (int X) << N
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (ashift:HI (match_dup 0)
+            (match_operand:HI 1 "const_int_operand" "i")))
+   (set (match_operand:QI 2 "register_operand" "=r")
+        (subreg:QI (match_dup 0) 1))]
+  "REGNO(operands[0]) == REGNO(operands[2])"
+  [(set (match_dup 0)
+        (ashift:HI (match_dup 0)
+            (plus:HI (match_dup 1) 
+                      (const_int 8))))]
+  )
+
+
+(define_insn "*ashift_hi_to_qi"
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (ashift:HI (match_dup 0)
+            (plus:HI (match_operand:HI 1 "const_int_operand" "i") 
+                      (match_operand:HI 2 "const_int_operand" "i"))))]
+  ""
+  {
+    operands[1] = GEN_INT(8 + INTVAL (operands[1]));
+    output_asm_insn("sla  %0, %1", operands);
+    return("");
+  }
+  [(set_attr "length" "2")])
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (int)X = (char X) >> N
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "=r")
+        (ashiftrt:QI (match_dup 0)
+            (match_operand:HI 1 "const_int_operand" "i")))
+   (set (match_operand:HI 2 "register_operand" "=r")
+        (sign_extend:HI (match_dup 0)))]
+  "REGNO(operands[0]) == REGNO(operands[2])"
+  [(set (match_dup 2)
+        (ashiftrt:HI (match_dup 2)
+            (plus:HI (match_dup 1) 
+                      (const_int 8))))]
+  )
+
+
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "=r")
+	(sign_extend:HI (match_operand:QI 1 "register_operand" "0")))
+   (set (match_operand:HI 2 "register_operand" "=r")
+        (ashiftrt:HI (match_dup 2)
+            (match_operand:HI 3 "const_int_operand" "i")))]
+  "REGNO(operands[0]) == REGNO(operands[2])"
+  [(set (match_dup 2)
+        (ashiftrt:HI (match_dup 2)
+            (plus:HI (match_dup 3) 
+                      (const_int 8))))]
+  )
+
+
+(define_insn "*ashiftrt_qi_to_hi"
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (ashiftrt:HI (match_dup 0)
+            (plus:HI (match_operand:HI 1 "const_int_operand" "i") 
+                      (match_operand:HI 2 "const_int_operand" "i"))))]
+  ""
+  {
+    int shift = INTVAL (operands[1]) + 8;
+    if(shift > 15) shift = 15;
+    operands[1] = GEN_INT(shift);
+    output_asm_insn("sra  %0, %1", operands);
+    return("");
+  }
+  [(set_attr "length" "2")])
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (int)X = (unsigned char X) >> N
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (lshiftrt:HI (match_operand:HI 1 "register_operand" "0")
+            (match_operand:HI 2 "const_int_operand" "i")))
+   (set (match_operand:HI 3 "register_operand" "=r")
+        (and:HI (match_operand:HI 4 "const_int_operand" "2")
+                (match_operand:HI 5 "const_int_operand" "i")))]
+  "(REGNO(operands[0]) == REGNO(operands[3])) && (INTVAL(operands[5]) == (1<<(8-INTVAL(operands[2])))-1)"
+  [(set (match_dup 0)
+        (lshiftrt:HI (match_dup 0)
+            (plus:HI (match_dup 2) 
+                      (const_int 8))))]
+  )
+
+
+(define_insn "*lshiftrt_qi_to_hi"
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (lshiftrt:HI (match_dup 0)
+            (plus:HI (match_operand:HI 1 "const_int_operand" "i") 
+                      (match_operand:HI 2 "const_int_operand" "i"))))]
+  ""
+  {
+    int shift = INTVAL (operands[1]) + 8;
+    if(shift > 15) shift = 15;
+    operands[1] = GEN_INT(shift);
+    output_asm_insn("srl  %0, %1", operands);
+    return("");
+  }
+  [(set_attr "length" "2")])
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (int)X = ((int)(char X)) << N
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (sign_extend:HI (match_operand:QI 1 "register_operand" "0")))
+   (set (match_operand:HI 3 "register_operand" "=r")
+        (ashift:HI (match_operand:HI 4 "register_operand" "3")
+                   (match_operand:HI 5 "const_int_operand" "i")))]
+  "(REGNO(operands[0]) == REGNO(operands[3]))"
+  [(set (match_dup 0)
+        (ashiftrt:HI (const_int 8)
+            (ashift:HI (match_dup 0) 
+                       (match_dup 5))))]
+  )
+
+(define_insn "*qi_hi_shift"
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (ashiftrt:HI (match_operand:HI 1 "const_int_operand" "i")
+            (ashift:HI (match_operand:HI 2 "register_operand" "0") 
+                       (match_operand:HI 3 "const_int_operand" "i"))))]
+  ""
+  {
+    int shift = INTVAL(operands[3]);
+    if(shift == 0) {
+      output_asm_insn("swpb %0", operands);
+      }
+    else if(shift >= 1 && shift <= 7) { 
+      operands[3] = GEN_INT(8-shift);
+      output_asm_insn("sra  %0, %3", operands);
+      }
+    else if(shift >= 9 && shift <= 15) {
+      operands[3] = GEN_INT(shift-8);
+      output_asm_insn("sla  %0, %3", operands);
+      }
+
+    operands[3] = GEN_INT(0x00FF << shift);
+    output_asm_insn("andi %0, %3", operands);
+   
+    return("");
+  }
+  [(set_attr "length" "6")])
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (unsigned int)X = ((unsigned int)(unsigned char X)) << N
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (zero_extend:HI (match_operand:QI 1 "register_operand" "0")))
+   (set (match_operand:HI 3 "register_operand" "=r")
+        (ashift:HI (match_operand:HI 4 "register_operand" "3")
+                   (match_operand:HI 5 "const_int_operand" "i")))]
+  "(REGNO(operands[0]) == REGNO(operands[3]))"
+  [(set (match_dup 0)
+        (lshiftrt:HI (const_int 8)
+            (ashift:HI (match_dup 0) 
+                       (match_dup 5))))]
+  )
+
+
+(define_insn "*unsigned_qi_hi_shift"
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (lshiftrt:HI (match_operand:HI 1 "const_int_operand" "i")
+            (ashift:HI (match_operand:HI 2 "register_operand" "0") 
+                       (match_operand:HI 3 "const_int_operand" "i"))))]
+  ""
+  {
+    int shift = INTVAL(operands[3]);
+    if(shift >= 0 && shift <= 7) { 
+      operands[3] = GEN_INT(8-shift);
+      output_asm_insn("srl  %0, %3", operands);
+      }
+    else if(shift >= 9 && shift <= 15) {
+      operands[3] = GEN_INT(shift-8);
+      output_asm_insn("sla  %0, %3", operands);
+      }
+
+    operands[3] = GEN_INT(0xFFFF << shift);
+    output_asm_insn("andi %0, %3", operands);
+   
+    return("");
+  }
+  [(set_attr "length" "6")])
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (unsigned long)X = (unsigned long Y) >> 16
+;;   Original code:
+;;     mov  r3, r6
+;;     mov  r4, r7
+;;     mov  r6, r7
+;;     clr  r6
+;;
+;;   Optimized:
+;;     mov r3, r7
+;;     clr r6
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (match_operand:HI 1 "register_operand" "r"))
+   (set (match_operand:HI 2 "register_operand" "=r")
+        (match_operand:HI 3 "register_operand" "r"))
+   (parallel[
+    (clobber (match_operand:HI 4 "register_operand" "r"))
+    (set (match_operand:SI 5 "register_operand" "=r")
+         (lshiftrt:SI (match_operand:SI 6 "register_operand" "5")
+                      (match_operand:HI 7 "const_int_operand" "i")))
+   ])]
+  "((REGNO(operands[0]) == REGNO(operands[5])) &&
+    (REGNO(operands[2]) == (REGNO(operands[0])+1)) &&
+    (INTVAL(operands[7]) == 16)
+   )"
+  [(set (match_dup 2) (match_dup 1))
+   (set (match_dup 0) (const_int 0))]
+)
+
+
+(define_insn "*set_consthi2"
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (match_operand:HI 1 "const_int_operand" "i"))]
+  ""
+  {
+    if(INTVAL(operands[1]) == 0) {
+      output_asm_insn("clr  %0", operands);
+    } else if((INTVAL(operands[1]) & 0xFFFF) == 0xFFFF) {
+      output_asm_insn("seto  %0", operands);
+    } else {
+      output_asm_insn("li   %0, %1", operands);
+    }
+    return("");
+  }
+  [(set_attr "length" "4")])
+
+
+;;-------------------------------------------------------------------
+;; Optimization for X = Y << 16
+;;   Original code:
+;;     mov  r4, r6
+;;     mov  r5, r7
+;;     mov  r7, r6
+;;     clr  r7
+;;
+;;   Optimized:
+;;     mov r5, r6
+;;     clr r7
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "=r")
+        (match_operand:HI 1 "register_operand" "r"))
+   (set (match_operand:HI 2 "register_operand" "=r")
+        (match_operand:HI 3 "register_operand" "r"))
+   (parallel[
+    (clobber (match_operand:HI 4 "register_operand" "r"))
+    (set (match_operand:SI 5 "register_operand" "=r")
+         (ashift:SI (match_operand:SI 6 "register_operand" "5")
+                      (match_operand:HI 7 "const_int_operand" "i")))
+   ])]
+  "((REGNO(operands[0]) == REGNO(operands[5])) &&
+    (REGNO(operands[2]) == (REGNO(operands[0])+1)) &&
+    (INTVAL(operands[7]) == 16)
+   )"
+  [(set (match_dup 0) (match_dup 3))
+   (set (match_dup 2) (const_int 0))]
+)
+
+
+;-------------------------------------------------------------------
+;; Optimization for byte array initializations
+; This handles sequences like:
+;   li   r1, >1200
+;   movb r1, *r2
+;   li   r1, >3400
+;   movb r1, @1(r2)
+;
+; and converts to:
+;   li   r1, >1234
+;   movb r1, *r2
+;   swpb r1
+;   movb r1, @1(r2)
+;
+; This saves two bytes and is slightly faster
+(define_peephole2
+  [(match_scratch:HI 6 "r,r")
+   (set (match_operand:QI 0 "register_operand" "=r,r")
+        (match_operand:QI 1 "const_int_operand" "i,i"))
+   (set (match_operand:QI 2 "nonimmediate_operand" "=R>,Q")
+        (match_dup 0))
+   (set (match_operand:QI 3 "register_operand" "=r,r")
+        (match_operand:QI 4 "const_int_operand" "i,i"))
+   (set (match_operand:QI 5 "nonimmediate_operand" "=R>,Q")
+        (match_dup 3))]
+  "peep2_reg_dead_p(4, operands[0]) && peep2_reg_dead_p(4, operands[3])"
+  [(set (match_dup 6)
+        (ior:HI (ashift:HI (match_dup 1) 
+                     (const_int 8))
+             (match_dup 4)))
+   (set (match_dup 2)
+        (subreg:QI (ashiftrt:HI (match_dup 6) (const_int 8)) 1))
+   (set (match_dup 5)
+        (subreg:QI (ashiftrt:HI (match_dup 6) (const_int 0)) 1))]
+)
+
+
+(define_insn "*movhi_combine_consts"
+  [(set (match_operand:HI 0 "register_operand" "")
+        (ior:HI (ashift:HI (match_operand:QI 1 "const_int_operand" "")
+                           (match_operand:QI 2 "const_int_operand" ""))
+                (match_operand:QI 3 "const_int_operand" "")))]
+  ""
+  {
+    operands[1] = GEN_INT(((INTVAL(operands[1]) & 0xFF) << 8) |
+                           (INTVAL(operands[3]) & 0xFF));
+    return "li   %0, %1";
+  }
+  [(set_attr "length" "4")])
+
+
+(define_insn "*movqi_for_initializer"
+  [(set (match_operand:QI 0 "memory_operand" "=rR>,Q")
+        (subreg:QI (ashiftrt:HI (match_operand:HI 1 "register_operand" "r,r")
+                              (match_operand:HI 2 "const_int_operand" "i,i")) 1))]
+  ""
+  {
+    if(INTVAL(operands[2]) == 8)
+    {
+      output_asm_insn("movb %1, %0", operands);
+    }
+    else if(INTVAL(operands[2]) == 0)
+    {
+      output_asm_insn("swpb %1", operands);
+      output_asm_insn("movb %1, %0", operands);
+    }
+   return("");
+  }
+  [(set_attr "length" "2,4")])
+
+
+;;-------------------------------------------------------------------
+;; Optimization for memory-to-memory copies
+;; Combine a mem-reg-mem copy into a mem-mem copy
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "")
+        (match_operand:HI 1 "memory_operand" ""))
+   (set (match_operand:HI 2 "memory_operand" "")
+        (match_dup 0))]
+  "peep2_reg_dead_p(2, operands[0])"
+  [(set (match_operand:HI 2 "memory_operand" "")
+        (match_operand:HI 1 "memory_operand" ""))]
+)
+
+   
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "")
+        (match_operand:QI 1 "memory_operand" ""))
+   (set (match_operand:QI 2 "memory_operand" "")
+        (match_dup 0))]
+  "peep2_reg_dead_p(2, operands[0])"
+  [(set (match_operand:QI 2 "memory_operand" "")
+        (match_operand:QI 1 "memory_operand" ""))]
+)
+
+
+;;-------------------------------------------------------------------
+;; Optimization for (int)X = (unsigned char)((int)X)
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "")
+        (subreg:QI (match_operand:HI 1 "register_operand") 1))
+   (set (match_operand:HI 2 "register_operand" "")
+        (zero_extend:HI (match_dup 0)))]
+  "REGNO(operands[0]) == REGNO(operands[2])"
+  [(set (match_dup 2)
+        (match_dup 1))
+   (set (match_dup 2)
+        (and:HI (match_dup 2) (const_int 255)))]
+)
+
+(define_insn "*andi_const"
+  [(set (match_operand:HI 0 "register_operand" "")
+        (and:HI (match_dup 0)
+                (match_operand:HI 1 "const_int_operand" "")))]
+  ""
+  {
+    int val = INTVAL(operands[1]) & 0xFFFF;
+    if(val == 0)
+      return "clr  %0";
+    else if(val == 0xFFFF)
+      return "";
+    else
+      return "andi %0, %1";
+  }
+  [(set_attr "length" "4")])
+
diff -ru gcc-orig/gcc/config/tms9900/tms9900-protos.h gcc-4.4.0/gcc/config/tms9900/tms9900-protos.h
--- gcc-orig/gcc/config/tms9900/tms9900-protos.h	2023-11-09 19:22:29.099456535 +0000
+++ gcc-4.4.0/gcc/config/tms9900/tms9900-protos.h	2023-11-09 19:07:20.838339158 +0000
@@ -0,0 +1,55 @@
+/* Definitions of target machine for GNU compiler, for the TMS9900
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 3, or (at your option)
+any later version.
+
+GCC is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with GCC; see the file COPYING3.  If not see
+<http://www.gnu.org/licenses/>.  */
+
+/* declarations */
+#ifdef RTX_CODE
+extern int simple_memory_operand (rtx, enum machine_mode);
+extern void print_operand_address (FILE *, rtx);
+extern int legitimate_address_p (enum machine_mode, rtx);
+extern void notice_update_cc_on_set (rtx, rtx);
+#endif /* RTX_CODE */
+
+extern const char *output_branch (const char *, const char *, int);
+extern const char *output_jump (int);
+
+extern int tms9900_function_arg_padding (enum machine_mode mode, 
+                                         const_tree type);
+
+extern void tms9900_function_arg_advance (CUMULATIVE_ARGS *cum, 
+                                          enum machine_mode mode,
+                                          tree type,
+                                          int named ATTRIBUTE_UNUSED);
+
+extern void tms9900_init_cumulative_args (CUMULATIVE_ARGS *cum,
+                                          tree fntype ATTRIBUTE_UNUSED,
+                                          rtx libname ATTRIBUTE_UNUSED);
+
+extern rtx tms9900_function_arg (CUMULATIVE_ARGS *cum, 
+                                 enum machine_mode mode,
+                                 tree type ATTRIBUTE_UNUSED,
+                                 int named);
+
+extern int tms9900_initial_elimination_offset (int from, int to);
+extern rtx tms9900_function_value (const_tree valtype);
+extern void tms9900_output_ascii(FILE* stream, const char* ptr, int len);
+extern void tms9900_expand_prologue (void);
+extern void tms9900_expand_epilogue (bool is_sibcall);
+extern int tms9900_starting_frame_offset(void);
+extern int tms9900_reg_ok_for_base(int strict, rtx reg);
+extern int tms9900_go_if_legitimate_address(enum machine_mode mode ATTRIBUTE_UNUSED, rtx operand, int strict);
+
diff -ru gcc-orig/gcc/config.gcc gcc-4.4.0/gcc/config.gcc
--- gcc-orig/gcc/config.gcc	2023-11-09 10:22:30.187989687 +0000
+++ gcc-4.4.0/gcc/config.gcc	2023-11-09 13:41:40.823744304 +0000
@@ -2314,6 +2314,8 @@
 	c_target_objs="${c_target_objs} spu-c.o"
 	cxx_target_objs="${cxx_target_objs} spu-c.o"
 	;;
+tms9900-*-*)
+	;;
 v850e1-*-*)
 	target_cpu_default="TARGET_CPU_v850e1"
 	tm_file="dbxelf.h elfos.h svr4.h v850/v850.h"
diff -ru gcc-orig/gcc/cp/cfns.h gcc-4.4.0/gcc/cp/cfns.h
--- gcc-orig/gcc/cp/cfns.h	2023-11-09 10:22:30.187989687 +0000
+++ gcc-4.4.0/gcc/cp/cfns.h	2023-11-09 13:41:40.823744304 +0000
@@ -1,4 +1,4 @@
-/* ANSI-C code produced by gperf version 3.0.1 */
+/* ANSI-C code produced by gperf version 3.0.4 */
 /* Command-line: gperf -o -C -E -k '1-6,$' -j1 -D -N libc_name_p -L ANSI-C ../../gcc/cp/cfns.gperf  */
 
 #if !((' ' == 32) && ('!' == 33) && ('"' == 34) && ('#' == 35) \
@@ -36,6 +36,7 @@
 static unsigned int hash (const char *, unsigned int);
 #ifdef __GNUC__
 __inline
+__attribute__ ((__gnu_inline__))
 #endif
 const char * libc_name_p (const char *, unsigned int);
 /* maximum key range = 391, duplicates = 0 */
@@ -57,13 +58,13 @@
       400, 400, 400, 400, 400, 400, 400, 400, 400, 400,
       400, 400, 400, 400, 400, 400, 400, 400, 400, 400,
       400, 400, 400, 400, 400, 400, 400, 400,   0,   0,
-	1, 400, 400, 400, 400, 400, 400, 400, 400, 400,
+        1, 400, 400, 400, 400, 400, 400, 400, 400, 400,
       400, 400, 400, 400, 400, 400, 400, 400, 400, 400,
       400, 400, 400, 400, 400, 400, 400, 400, 400, 400,
       400, 400, 400, 400, 400, 400, 400, 400, 400, 400,
       400, 400, 400, 400, 400, 400, 400,  28,  90,   0,
        95,   0,  51,  93, 114,  26, 109, 124,   5,   1,
-	6,  13,  37, 128,   3,   0,   0,  49,  38,   0,
+        6,  13,  37, 128,   3,   0,   0,  49,  38,   0,
       104,  45,   0, 400, 400, 400, 400, 400, 400, 400,
       400, 400, 400, 400, 400, 400, 400, 400, 400, 400,
       400, 400, 400, 400, 400, 400, 400, 400, 400, 400,
@@ -84,29 +85,32 @@
   switch (hval)
     {
       default:
-	hval += asso_values[(unsigned char)str[5]+1];
+        hval += asso_values[(unsigned char)str[5]+1];
       /*FALLTHROUGH*/
       case 5:
-	hval += asso_values[(unsigned char)str[4]];
+        hval += asso_values[(unsigned char)str[4]];
       /*FALLTHROUGH*/
       case 4:
-	hval += asso_values[(unsigned char)str[3]];
+        hval += asso_values[(unsigned char)str[3]];
       /*FALLTHROUGH*/
       case 3:
-	hval += asso_values[(unsigned char)str[2]];
+        hval += asso_values[(unsigned char)str[2]];
       /*FALLTHROUGH*/
       case 2:
-	hval += asso_values[(unsigned char)str[1]];
+        hval += asso_values[(unsigned char)str[1]];
       /*FALLTHROUGH*/
       case 1:
-	hval += asso_values[(unsigned char)str[0]];
-	break;
+        hval += asso_values[(unsigned char)str[0]];
+        break;
     }
   return hval + asso_values[(unsigned char)str[len - 1]];
 }
 
 #ifdef __GNUC__
 __inline
+#if defined __GNUC_STDC_INLINE__ || defined __GNUC_GNU_INLINE__
+__attribute__ ((__gnu_inline__))
+#endif
 #endif
 const char *
 libc_name_p (register const char *str, register unsigned int len)
@@ -329,17 +333,17 @@
       register int key = hash (str, len);
 
       if (key <= MAX_HASH_VALUE && key >= 0)
-	{
-	  register int index = lookup[key];
+        {
+          register int index = lookup[key];
 
-	  if (index >= 0)
-	    {
-	      register const char *s = wordlist[index];
-
-	      if (*str == *s && !strcmp (str + 1, s + 1))
-		return s;
-	    }
-	}
+          if (index >= 0)
+            {
+              register const char *s = wordlist[index];
+
+              if (*str == *s && !strcmp (str + 1, s + 1))
+                return s;
+            }
+        }
     }
   return 0;
 }
diff -ru gcc-orig/gcc/cp/except.c gcc-4.4.0/gcc/cp/except.c
--- gcc-orig/gcc/cp/except.c	2023-11-09 10:22:30.187989687 +0000
+++ gcc-4.4.0/gcc/cp/except.c	2023-11-09 13:41:40.823744304 +0000
@@ -926,7 +926,6 @@
    Standard C library shall report an error by throwing an
    exception, unless it calls a program-supplied function that
    throws an exception.  */
-
 #include "cfns.h"
 
 int
diff -ru gcc-orig/gcc/DEV-PHASE gcc-4.4.0/gcc/DEV-PHASE
--- gcc-orig/gcc/DEV-PHASE	2023-11-09 10:22:30.183989619 +0000
+++ gcc-4.4.0/gcc/DEV-PHASE	2023-11-09 13:41:40.819744320 +0000
@@ -0,0 +1 @@
+TMS9900 patch 1.19
diff -ru gcc-orig/gcc/final.c gcc-4.4.0/gcc/final.c
--- gcc-orig/gcc/final.c	2023-11-09 10:22:30.187989687 +0000
+++ gcc-4.4.0/gcc/final.c	2023-11-09 19:07:20.838339158 +0000
@@ -2772,6 +2772,11 @@
       else if (REG_P (y))
 	{
 	  /* Simplify_subreg can't handle some REG cases, but we have to.  */
+#ifdef TMS9900
+          if(!((GET_MODE(x) == QImode && GET_MODE(y) != QImode) ||
+               (GET_MODE(x) != QImode && GET_MODE(y) == QImode)))
+          {
+#endif
 	  unsigned int regno;
 	  HOST_WIDE_INT offset;
 
@@ -2781,6 +2786,9 @@
 	  else
 	    offset = SUBREG_BYTE (x);
 	  *xp = gen_rtx_REG_offset (y, GET_MODE (x), regno, offset);
+#ifdef TMS9900
+          }
+#endif
 	}
     }
 
diff -ru gcc-orig/gcc/passes.c gcc-4.4.0/gcc/passes.c
--- gcc-orig/gcc/passes.c	2023-11-09 10:22:30.187989687 +0000
+++ gcc-4.4.0/gcc/passes.c	2023-11-09 19:07:20.838339158 +0000
@@ -102,6 +102,11 @@
 				   declarations for e.g. AIX 4.x.  */
 #endif
 
+#ifdef TMS9900
+extern struct rtl_opt_pass pass_tms9900_subreg;
+extern struct rtl_opt_pass pass_tms9900_postinc;
+#endif
+
 /* This is used for debugging.  It allows the current pass to printed
    from anywhere in compilation.  */
 struct opt_pass *current_pass;
@@ -767,6 +772,10 @@
       NEXT_PASS (pass_match_asm_constraints);
       NEXT_PASS (pass_sms);
       NEXT_PASS (pass_sched);
+#ifdef TMS9900
+      NEXT_PASS (pass_tms9900_subreg);
+      NEXT_PASS (pass_tms9900_postinc);
+#endif
       NEXT_PASS (pass_subregs_of_mode_init);
       NEXT_PASS (pass_ira);
       NEXT_PASS (pass_subregs_of_mode_finish);
diff -ru gcc-orig/gcc/reload.c gcc-4.4.0/gcc/reload.c
--- gcc-orig/gcc/reload.c	2023-11-09 10:22:30.187989687 +0000
+++ gcc-4.4.0/gcc/reload.c	2023-11-09 19:07:20.838339158 +0000
@@ -2166,6 +2166,14 @@
 
   if (x == y)
     return 1;
+
+#ifdef TMS9900
+  /* We cannot match register subregs for the TMS9900 */
+  if((GET_MODE(x)==QImode && GET_CODE(x)==SUBREG && REG_P(SUBREG_REG(x))) ||
+     (GET_MODE(y)==QImode && GET_CODE(y)==SUBREG && REG_P(SUBREG_REG(y))))
+    return 0;
+#endif
+
   if ((code == REG || (code == SUBREG && REG_P (SUBREG_REG (x))))
       && (REG_P (y) || (GET_CODE (y) == SUBREG
 				  && REG_P (SUBREG_REG (y)))))
@@ -2995,6 +3003,12 @@
 	      if (REG_P (SUBREG_REG (operand))
 		  && REGNO (SUBREG_REG (operand)) < FIRST_PSEUDO_REGISTER)
 		{
+#ifdef TMS9900
+                  /* Added for TMS9900, do not attempt reloads of
+                     registers if byte values are involved */
+                  if(GET_MODE (operand) != QImode && 
+                     GET_MODE (SUBREG_REG (operand)) != QImode)
+#endif
 		  if (simplify_subreg_regno (REGNO (SUBREG_REG (operand)),
 					     GET_MODE (SUBREG_REG (operand)),
 					     SUBREG_BYTE (operand),
diff -ru gcc-orig/gcc/rtl-error.c gcc-4.4.0/gcc/rtl-error.c
--- gcc-orig/gcc/rtl-error.c	2023-11-09 10:22:30.187989687 +0000
+++ gcc-4.4.0/gcc/rtl-error.c	2023-11-09 19:07:20.838339158 +0000
@@ -102,12 +102,14 @@
 _fatal_insn (const char *msgid, const_rtx insn, const char *file, int line,
 	     const char *function)
 {
+#if 0
   error ("%s", _(msgid));
 
   /* The above incremented error_count, but isn't an error that we want to
      count, so reset it here.  */
   errorcount--;
-
+#endif
+  printf("%s\n", msgid);
   debug_rtx (insn);
   fancy_abort (file, line, function);
 }
diff -ru gcc-orig/gcc/rtlhooks.c gcc-4.4.0/gcc/rtlhooks.c
--- gcc-orig/gcc/rtlhooks.c	2023-11-09 10:22:30.187989687 +0000
+++ gcc-4.4.0/gcc/rtlhooks.c	2023-11-09 19:07:20.838339158 +0000
@@ -55,6 +55,15 @@
     {
       int offset = 0;
 
+#ifdef TMS9900
+      /* Added for TMS9900
+         If the location is not known yet, take no action now. Return
+         the original subreg expression until the location is known */
+      if(!(MEM_P (x)))
+        {
+          return gen_lowpart_general (mode, force_reg (GET_MODE (x), x));
+        }
+#endif
       /* The only additional case we can do is MEM.  */
       gcc_assert (MEM_P (x));
 
diff -ru gcc-orig/gcc/simplify-rtx.c gcc-4.4.0/gcc/simplify-rtx.c
--- gcc-orig/gcc/simplify-rtx.c	2023-11-09 10:22:30.191989755 +0000
+++ gcc-4.4.0/gcc/simplify-rtx.c	2023-11-09 13:41:40.827744289 +0000
@@ -5094,6 +5094,19 @@
 		final_offset += difference % UNITS_PER_WORD;
 	    }
 
+#ifdef TMS9900
+          /* Modification for TMS9900
+             Do not assume QI quantities are in low part of register */
+          if(outermode == QImode)
+          {
+              /* The code above has determined which register and offset
+                 are needed for this simplification, just use that to
+                 specify a subreg of a full HImode register */
+              x = gen_rtx_SUBREG(outermode, gen_rtx_REG (HImode, final_regno), final_offset % GET_MODE_SIZE(HImode));
+              return x;
+          }
+#endif
+
 	  x = gen_rtx_REG_offset (op, outermode, final_regno, final_offset);
 
 	  /* Propagate original regno.  We don't have any way to specify
diff -ru gcc-orig/gcc/toplev.h gcc-4.4.0/gcc/toplev.h
--- gcc-orig/gcc/toplev.h	2023-11-09 10:22:30.191989755 +0000
+++ gcc-4.4.0/gcc/toplev.h	2023-11-09 13:41:40.827744289 +0000
@@ -186,6 +186,7 @@
 #  define CTZ_HWI __builtin_ctz
 # endif
 
+#ifdef __cplusplus
 extern inline int
 floor_log2 (unsigned HOST_WIDE_INT x)
 {
@@ -197,6 +198,7 @@
 {
   return x == (x & -x) && x ? (int) CTZ_HWI (x) : -1;
 }
+#endif /* __cplusplus */
 #endif /* GCC_VERSION >= 3004 */
 
 /* Functions used to get and set GCC's notion of in what directory
diff -ru gcc-orig/libgcc/config/tms9900/t-tms9900 gcc-4.4.0/libgcc/config/tms9900/t-tms9900
--- gcc-orig/libgcc/config/tms9900/t-tms9900	2023-11-09 19:23:27.395213662 +0000
+++ gcc-4.4.0/libgcc/config/tms9900/t-tms9900	2023-11-09 13:41:40.827744289 +0000
@@ -0,0 +1,27 @@
+# Extra 16-bit integer functions.
+intfuncs16 = _absvXX2 _addvXX3 _subvXX3 _mulvXX3 _negvXX2
+hiintfuncs16 = $(subst XX,hi,$(intfuncs16))
+siintfuncs16 = $(subst XX,si,$(intfuncs16))
+
+iter-items := $(hiintfuncs16)
+iter-labels := $(siintfuncs16)
+iter-sizes := $(patsubst %,2,$(siintfuncs16)) $(patsubst %,2,$(hiintfuncs16))
+
+LIB1ASMSRC = tms9900/lib1funcs.asm
+LIB1ASMFUNCS = _clzqi2 _clzhi2 _clzsi2 _clz\
+               _ctzqi2 _ctzhi2 _ctzsi2 _ctz\
+               _ffsqi2 _ffshi2 _ffssi2\
+               _parityqi2 _parityhi2 _paritysi2 _parity\
+               _popcountqi2 _popcounthi2 _popcountsi2 _popcount\
+               _udivmodsi3 _udivsi3 _umodsi3\
+               _divmodsi3 _modsi3 _divsi3 _divmod_common
+
+
+include $(srcdir)/empty.mk $(patsubst %,$(srcdir)/siditi-object.mk,$(iter-items))
+libgcc-objects += $(patsubst %,%$(objext),$(hiintfuncs16))
+
+
+ifeq ($(enable_shared),yes)
+libgcc-s-objects += $(patsubst %,%_s$(objext),$(hiintfuncs16))
+endif
+
diff -ru gcc-orig/libgcc/config.host gcc-4.4.0/libgcc/config.host
--- gcc-orig/libgcc/config.host	2023-11-09 10:22:30.191989755 +0000
+++ gcc-4.4.0/libgcc/config.host	2023-11-09 13:41:40.827744289 +0000
@@ -127,6 +127,9 @@
 sh[123456789lbe]*-*-*)
 	cpu_type=sh
 	;;
+tms9900-*-*)
+	cpu_type=tms9900
+	;;
 esac
 
 # Common parts for widely ported systems.
@@ -551,6 +554,10 @@
 	;;
 spu-*-elf*)
 	;;
+tms9900-*-*)
+	# Make SI mode functions for TMS9900
+	tmake_file=${cpu_type}/t-tms9900
+	;;
 v850e1-*-*)
 	;;
 v850e-*-*)
